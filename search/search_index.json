{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"napari-ndev (neuralDev)","text":"<p>A collection of widgets intended to serve any person seeking to process microscopy images from start to finish. The wide breadth of this plugin's scope is only made possible by the amazing libraries and plugins from the napari community, especially Robert Haase. Currently, the plugin supports the following goals:</p> <ol> <li>Image Utilities: Intended for high-throuput image-labeling and management, while passing down important metadata. Allows opening image files (preferably with <code>napari-bioimageio</code> see Installation) and displaying in napari. Also reads metadata and allows customization prior to saving images and labels layers. Allows concatenation of image files and image layers for saving new images. Speeds up annotation by saving corresponding images and labels in designated folders. Also allows saving of shapes layers as labels in case shapes are being used as a region of interest.</li> <li>Workflow Widget: Batch pre-processing/processing images using napari-workflows.</li> <li>APOC Widget: Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting.<ul> <li>Custom Feature Set Widget: Generate a featureset to be used with the APOC widget. Also allows quick application in the napari viewer to an image layer to see all the features.</li> </ul> </li> <li>Measure Widget: Batch measurement of a label with optional corresponding image, label, and regions (ROIs) that can be used as an intensity image. Currently passed to <code>scikit-image.measure.regionprops</code>.</li> </ol>"},{"location":"#further-info","title":"Further Info","text":""},{"location":"#1-image-utilities","title":"1. Image Utilities","text":"<p>A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders. Best if the images are opened with napari-bioio--which can be as simple as drag and drop opening by setting the appropriate default reader for each file type in Preferences -&gt; Plugins--in order to utilize the metadata present for saving the image-label pairs.</p> <p>Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. To be added: alternative projection types, slicing in T, and compatibility with non TCZYX images (but this is not a priority since bioio currently always extracts images as TCZYX even if a dim is only length 1.</p>"},{"location":"#2-workflow-widget","title":"2. Workflow Widget","text":"<p>Batch pre-processing/processing images using napari-workflows.  Images are processed outside the napari-viewer using bioio as both reader and writer. Prior to passing the images to napari-workflows, the user selects the correct images as the roots (inputs) and thus napari-workflows matches the processing to create the outputs. The advantage of using napari-workflows for batch processing is that it provides an incredibly flexible processing interface without writing a novel widget for small changes to processing steps like specific filters, segmentation, or measurements. Currently only intended for use with images as inputs and images as outputs from napari-workflows, though there is future potential to have other outputs possible, such as .csv measurement arrays.</p>"},{"location":"#3-apoc-widget","title":"3. APOC Widget","text":"<p>Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting. Recognizes pre established feature set, and custom feature sets (a string of filters and radii) can be generated with a corresponding widget. Also contains a Custom Feature Set widget which allows application of all the features to a layer in the viewer, for improved visualization.</p>"},{"location":"#4-measure-widget","title":"4. Measure Widget","text":"<p>Batch measurements using scikit-image's regionprops. This can measure features of a label such as area, eccentricity, and more but also can measure various intensity metrics. Attempts to support post-processing of measurements, grouping, and more to make downstream analyses easier for users. Will be updated in the future to include nyxus.</p>"},{"location":"installation/","title":"Installation","text":"<p>napari-ndev is a pure Python package, and can be installed with [pip]:</p> <pre><code>pip install napari-ndev\n</code></pre>"},{"location":"installation/#optional-libraries","title":"Optional Libraries","text":"<p>napari-ndev is most useful when interacting with some other napari plugins (e.g. napari-assistant) and can read additional filetypes (e.g. bioio-nd2). You may install these BSD-3 compatible plugins with [pip]:</p> <pre><code>pip install napari-ndev[extras]\n</code></pre> <p>napari-ndev can optionally use GPL-3 licensed libraries to enhance its functionality, but are not required. If you choose to install and use these optional dependencies, you must comply with the GPL-3 license terms. The main functional improvement is from <code>napari-bioio</code> to properly handle metadata with the <code>Image Utilities</code> widget. These libraries can be installed with [pip]:</p> <pre><code>pip install napari-ndev[gpl-extras]\n\nor\n\npip install napari-ndev[all]\n</code></pre> <p>In addition, you may need to install specific <code>bioio</code> readers to support your specific image, such as <code>bioio-czi</code> and <code>bioio-lif</code> (included in <code>[gpl-extras]</code>) or <code>bioio-bioformats</code>.</p>"},{"location":"installation/#development-libraries","title":"Development Libraries","text":"<p>For development use the <code>[dev]</code> optional libraries. You may also like to install <code>[docs]</code> and <code>[testing]</code> to verify your changes. However, <code>tox</code> will test any pull requests. You can also install <code>[dev-all]</code> to get all three of these dev dependencies.</p>"},{"location":"api/helpers/","title":"Helpers","text":""},{"location":"api/helpers/#napari_ndev.helpers","title":"napari_ndev.helpers","text":"<p>Helper functions for file handling, image processing, and logging setup.</p> <p>Functions:</p> <ul> <li> <code>get_directory_and_files : Get the directory and files in the specified directory.</code>             \u2013              </li> <li> <code>get_channel_names : Get the channel names from an BioImage object.</code>             \u2013              </li> <li> <code>get_squeezed_dim_order : Return a string containing the squeezed dimensions of the given BioImage object.</code>             \u2013              </li> <li> <code>create_id_string : Create an ID string for the given image.</code>             \u2013              </li> <li> <code>check_for_missing_files : Check if the given files are missing in the specified directories.</code>             \u2013              </li> <li> <code>setup_logger : Set up a logger with the specified log location.</code>             \u2013              </li> </ul>"},{"location":"api/helpers/#napari_ndev.helpers.check_for_missing_files","title":"check_for_missing_files","text":"<pre><code>check_for_missing_files(files, *directories)\n</code></pre> <p>Check if the given files are missing in the specified directories.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list of tuple</code>           \u2013            <p>List of tuples containing the missing files and their corresponding directories.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def check_for_missing_files(\n    files: list[Path] | list[str], *directories: Path | str\n) -&gt; list[tuple]:\n    \"\"\"\n    Check if the given files are missing in the specified directories.\n\n    Parameters\n    ----------\n    files : list of Path or list of str\n        List of files to check.\n    directories : tuple of Path or str\n        Tuple of directories to search for the files.\n\n    Returns\n    -------\n    list of tuple\n        List of tuples containing the missing files and their corresponding directories.\n\n    \"\"\"\n    missing_files = []\n    for file in files:\n        for directory in directories:\n            if isinstance(directory, str):\n                directory = Path(directory)\n            if isinstance(file, str):\n                file = Path(file)\n\n            file_loc = directory / file.name\n            if not file_loc.exists():\n                missing_files.append((file.name, directory.name))\n\n    return missing_files\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.check_for_missing_files(files)","title":"<code>files</code>","text":"(<code>list of Path or list of str</code>)           \u2013            <p>List of files to check.</p>"},{"location":"api/helpers/#napari_ndev.helpers.check_for_missing_files(directories)","title":"<code>directories</code>","text":"(<code>tuple of Path or str</code>, default:                   <code>()</code> )           \u2013            <p>Tuple of directories to search for the files.</p>"},{"location":"api/helpers/#napari_ndev.helpers.create_id_string","title":"create_id_string","text":"<pre><code>create_id_string(img, identifier)\n</code></pre> <p>Create an ID string for the given image.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The ID string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create_id_string(img, 'test')\n'test__0__Scene:0'\n</code></pre> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def create_id_string(img: BioImage, identifier: str) -&gt; str:\n    \"\"\"\n    Create an ID string for the given image.\n\n    Parameters\n    ----------\n    img : BioImage\n        The image object.\n    identifier : str\n        The identifier string.\n\n    Returns\n    -------\n    str\n        The ID string.\n\n    Examples\n    --------\n    &gt;&gt;&gt; create_id_string(img, 'test')\n    'test__0__Scene:0'\n\n    \"\"\"\n    scene_idx = img.current_scene_index\n    # scene = img.current_scene\n    # instead use ome_metadata.name because this gets saved with OmeTiffWriter\n    try:\n        if img.ome_metadata.images[scene_idx].name is None:\n            scene = img.current_scene\n        else:\n            scene = img.ome_metadata.images[scene_idx].name\n    except NotImplementedError:\n        scene = img.current_scene  # not useful with OmeTiffReader, atm\n    id_string = f'{identifier}__{scene_idx}__{scene}'\n    return id_string\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.create_id_string(img)","title":"<code>img</code>","text":"(<code>BioImage</code>)           \u2013            <p>The image object.</p>"},{"location":"api/helpers/#napari_ndev.helpers.create_id_string(identifier)","title":"<code>identifier</code>","text":"(<code>str</code>)           \u2013            <p>The identifier string.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_Image","title":"get_Image","text":"<pre><code>get_Image(file)\n</code></pre> <p>Read the image file with BioImage.</p> <p>Open the image file with BioImage.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>BioImage</code>           \u2013            <p>The image object.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_Image(file: str | Path) -&gt; BioImage:\n    \"\"\"\n    Read the image file with BioImage.\n\n    Open the image file with BioImage.\n\n    Parameters\n    ----------\n    file : str or Path\n        The file path.\n\n    Returns\n    -------\n    BioImage\n        The image object.\n\n    \"\"\"\n    from bioio import BioImage\n\n    return BioImage(file)\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_Image(file)","title":"<code>file</code>","text":"(<code>str or Path</code>)           \u2013            <p>The file path.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_channel_names","title":"get_channel_names","text":"<pre><code>get_channel_names(img)\n</code></pre> <p>Get the channel names from a BioImage object.</p> <p>If the image has a dimension order that includes \"S\" (it is RGB), return the default channel names [\"red\", \"green\", \"blue\"]. Otherwise, return the channel names from the image.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list of str</code>           \u2013            <p>The channel names.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_channel_names(img: BioImage) -&gt; list[str]:\n    \"\"\"\n    Get the channel names from a BioImage object.\n\n    If the image has a dimension order that includes \"S\" (it is RGB),\n    return the default channel names [\"red\", \"green\", \"blue\"].\n    Otherwise, return the channel names from the image.\n\n    Parameters\n    ----------\n    img : BioImage\n        The BioImage object.\n\n    Returns\n    -------\n    list of str\n        The channel names.\n\n    \"\"\"\n    if 'S' in img.dims.order:\n        return ['red', 'green', 'blue']\n    return img.channel_names\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_channel_names(img)","title":"<code>img</code>","text":"(<code>BioImage</code>)           \u2013            <p>The BioImage object.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_directory_and_files","title":"get_directory_and_files","text":"<pre><code>get_directory_and_files(dir_path=None, pattern=None)\n</code></pre> <p>Get the directory and files in the specified directory.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>tuple of (Path, list of Path)</code>           \u2013            <p>A tuple containing the directory path and a list of file paths.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_directory_and_files(\n    dir_path: str | Path | None = None,\n    pattern: list[str] | str | None = None,\n) -&gt; tuple[Path, list[Path]]:\n    \"\"\"\n    Get the directory and files in the specified directory.\n\n    Parameters\n    ----------\n    dir_path : str or Path or None, optional\n        The directory path.\n    pattern : list of str or str or None, optional\n        The file pattern(s) to match. If a string is provided, it will be treated as a single pattern.\n        If a list is provided, each element will be treated as a separate pattern.\n        Defaults to ['tif', 'tiff', 'nd2', 'czi', 'lif', 'oib', 'png', 'jpg', 'jpeg', 'bmp', 'gif'].\n\n    Returns\n    -------\n    tuple of (Path, list of Path)\n        A tuple containing the directory path and a list of file paths.\n\n    \"\"\"\n    if pattern is None:\n        pattern = [\n            'tif',\n            'tiff',\n            'nd2',\n            'czi',\n            'lif',\n            'oib',\n            'png',\n            'jpg',\n            'jpeg',\n            'bmp',\n            'gif',\n        ]\n    if dir_path is None:\n        return None, []\n\n    directory = Path(dir_path)\n\n    if dir_path is not None and not directory.exists():\n        raise FileNotFoundError(f'Directory {dir_path} does not exist.')\n\n    pattern = [pattern] if isinstance(pattern, str) else pattern\n    # add *. to each pattern if it doesn't already have either\n    pattern_glob = []\n    for pat in pattern:\n        if '.' not in pat:\n            pat = f'*.{pat}'\n        if '*' not in pat:\n            pat = f'*{pat}'\n        pattern_glob.append(pat)\n\n    files = []\n    for p_glob in pattern_glob:\n        for file in directory.glob(p_glob):\n            files.append(file)\n    return directory, files\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_directory_and_files(dir_path)","title":"<code>dir_path</code>","text":"(<code>str or Path or None</code>, default:                   <code>None</code> )           \u2013            <p>The directory path.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_directory_and_files(pattern)","title":"<code>pattern</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>The file pattern(s) to match. If a string is provided, it will be treated as a single pattern. If a list is provided, each element will be treated as a separate pattern. Defaults to ['tif', 'tiff', 'nd2', 'czi', 'lif', 'oib', 'png', 'jpg', 'jpeg', 'bmp', 'gif'].</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_squeezed_dim_order","title":"get_squeezed_dim_order","text":"<pre><code>get_squeezed_dim_order(img, skip_dims=None)\n</code></pre> <p>Return a string containing the squeezed dimensions of the given BioImage.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string containing the squeezed dimensions.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_squeezed_dim_order(\n    img: BioImage,\n    skip_dims: list[str] | str | None = None,\n) -&gt; str:\n    \"\"\"\n    Return a string containing the squeezed dimensions of the given BioImage.\n\n    Parameters\n    ----------\n    img : BioImage\n        The BioImage object.\n    skip_dims : list of str or str or None, optional\n        Dimensions to skip. Defaults to [\"C\", \"S\"].\n\n    Returns\n    -------\n    str\n        A string containing the squeezed dimensions.\n\n    \"\"\"\n    if skip_dims is None:\n        skip_dims = ['C', 'S']\n    return ''.join(\n        {k: v for k, v in img.dims.items() if v &gt; 1 and k not in skip_dims}\n    )\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_squeezed_dim_order(img)","title":"<code>img</code>","text":"(<code>BioImage</code>)           \u2013            <p>The BioImage object.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_squeezed_dim_order(skip_dims)","title":"<code>skip_dims</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>Dimensions to skip. Defaults to [\"C\", \"S\"].</p>"},{"location":"api/helpers/#napari_ndev.helpers.setup_logger","title":"setup_logger","text":"<pre><code>setup_logger(log_loc=Union[str, Path])\n</code></pre> <p>Set up a logger with the specified log location.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>logger</code> (              <code>Logger</code> )          \u2013            <p>The logger object.</p> </li> <li> <code>handler</code> (              <code>FileHandler</code> )          \u2013            <p>The file handler object.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def setup_logger(log_loc=Union[str, Path]):\n    \"\"\"\n    Set up a logger with the specified log location.\n\n    Parameters\n    ----------\n    log_loc : str or Path\n        The path to the log file.\n\n    Returns\n    -------\n    logger : logging.Logger\n        The logger object.\n    handler : logging.FileHandler\n        The file handler object.\n\n    \"\"\"\n    logger = logging.getLogger(__name__ + str(time.time()))\n    logger.setLevel(logging.INFO)\n    handler = logging.FileHandler(log_loc)\n    handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    return logger, handler\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.setup_logger(log_loc)","title":"<code>log_loc</code>","text":"(<code>str or Path</code>, default:                   <code>Union[str, Path]</code> )           \u2013            <p>The path to the log file.</p>"},{"location":"api/image_overview/","title":"Image Overview","text":""},{"location":"api/image_overview/#napari_ndev.image_overview","title":"napari_ndev.image_overview","text":"<p>Function and class to create and manage image overviews with stackview.</p> <p>It includes a function <code>image_overview</code> to generate an overview of images and a class <code>ImageOverview</code> to generate and save image overviews.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview","title":"ImageOverview","text":"<p>A class for generating and saving image overviews.</p> <p>Use this class to prevent a memory leak otherwise generated by the image_overview() function when show=True. For some reason, preventing the memory leak requires the use of a class instead of a function, and show=False.</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>class ImageOverview:\n    \"\"\"\n    A class for generating and saving image overviews.\n\n    Use this class to prevent a memory leak otherwise generated by the\n    image_overview() function when show=True. For some reason, preventing\n    the memory leak requires the use of a class instead of a function, and\n    show=False.\n    \"\"\"\n\n    def __init__(\n        self,\n        image_sets: list[dict],\n        xscale: float = 3,\n        yscale: float = 3,\n        image_title: str = '',\n        show: bool = False,\n    ):\n        \"\"\"\n        Initialize an ImageOverivew object.\n\n        Parameters\n        ----------\n        image_sets : list of dict\n            A list of dictionaries containing image sets. See\n            `napari_ndev.image_overview` for more information.\n        xscale : float, optional\n            The scale factor for the x-axis. Default is 3.\n        yscale : float, optional\n            The scale factor for the y-axis. Default is 3.\n        image_title : str, optional\n            The title of the image overview. Default is an empty string.\n        show : bool, optional\n            Whether to display the generated overview. Default is False.\n            Prevents memory leak when False.\n\n        \"\"\"\n        plt.ioff()\n        self.fig = image_overview(image_sets, xscale, yscale, image_title)\n        if show:\n            plt.show()\n        plt.close()\n\n    def save(\n        self,\n        directory: str | None = None,\n        filename: str | None = None,\n    ):\n        \"\"\"\n        Save the generated image overview with matplotlib.savefig.\n\n        Parameters\n        ----------\n        directory : str, optional\n            The directory to save the image overview. If not provided, the\n            current directory will be used.\n        filename : str, optional\n            The filename of the saved image overview. If not provided, a\n            default filename will be used.\n\n        \"\"\"\n        import pathlib\n\n        path_dir = pathlib.Path(directory)\n        path_dir.mkdir(parents=True, exist_ok=True)\n        filepath = path_dir / filename\n        self.fig.savefig(filepath)\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__","title":"__init__","text":"<pre><code>__init__(image_sets, xscale=3, yscale=3, image_title='', show=False)\n</code></pre> <p>Initialize an ImageOverivew object.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def __init__(\n    self,\n    image_sets: list[dict],\n    xscale: float = 3,\n    yscale: float = 3,\n    image_title: str = '',\n    show: bool = False,\n):\n    \"\"\"\n    Initialize an ImageOverivew object.\n\n    Parameters\n    ----------\n    image_sets : list of dict\n        A list of dictionaries containing image sets. See\n        `napari_ndev.image_overview` for more information.\n    xscale : float, optional\n        The scale factor for the x-axis. Default is 3.\n    yscale : float, optional\n        The scale factor for the y-axis. Default is 3.\n    image_title : str, optional\n        The title of the image overview. Default is an empty string.\n    show : bool, optional\n        Whether to display the generated overview. Default is False.\n        Prevents memory leak when False.\n\n    \"\"\"\n    plt.ioff()\n    self.fig = image_overview(image_sets, xscale, yscale, image_title)\n    if show:\n        plt.show()\n    plt.close()\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(image_sets)","title":"<code>image_sets</code>","text":"(<code>list of dict</code>)           \u2013            <p>A list of dictionaries containing image sets. See <code>napari_ndev.image_overview</code> for more information.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(xscale)","title":"<code>xscale</code>","text":"(<code>float</code>, default:                   <code>3</code> )           \u2013            <p>The scale factor for the x-axis. Default is 3.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(yscale)","title":"<code>yscale</code>","text":"(<code>float</code>, default:                   <code>3</code> )           \u2013            <p>The scale factor for the y-axis. Default is 3.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(image_title)","title":"<code>image_title</code>","text":"(<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The title of the image overview. Default is an empty string.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(show)","title":"<code>show</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display the generated overview. Default is False. Prevents memory leak when False.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.save","title":"save","text":"<pre><code>save(directory=None, filename=None)\n</code></pre> <p>Save the generated image overview with matplotlib.savefig.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def save(\n    self,\n    directory: str | None = None,\n    filename: str | None = None,\n):\n    \"\"\"\n    Save the generated image overview with matplotlib.savefig.\n\n    Parameters\n    ----------\n    directory : str, optional\n        The directory to save the image overview. If not provided, the\n        current directory will be used.\n    filename : str, optional\n        The filename of the saved image overview. If not provided, a\n        default filename will be used.\n\n    \"\"\"\n    import pathlib\n\n    path_dir = pathlib.Path(directory)\n    path_dir.mkdir(parents=True, exist_ok=True)\n    filepath = path_dir / filename\n    self.fig.savefig(filepath)\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.save(directory)","title":"<code>directory</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The directory to save the image overview. If not provided, the current directory will be used.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.save(filename)","title":"<code>filename</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The filename of the saved image overview. If not provided, a default filename will be used.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview","title":"image_overview","text":"<pre><code>image_overview(image_sets, xscale=3, yscale=3, plot_title='')\n</code></pre> <p>Create an overview of images.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>fig</code> (              <code>Figure</code> )          \u2013            <p>The matplotlib figure object containing the image overview.</p> </li> </ul> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def image_overview(\n    image_sets: list[dict],\n    xscale: float = 3,\n    yscale: float = 3,\n    plot_title: str = '',\n):\n    \"\"\"\n    Create an overview of images.\n\n    Parameters\n    ----------\n    image_sets : list of dict\n        A list of dictionaries, each containing an image set. Each image set\n        should be a dictionary containing the following keys:\n        - image (list): A list of images to display.\n        - title (list of str, optional): The title of the image set.\n        - colormap (list of str, optional): The colormap to use.\n            \"labels\" will display the image as labels.\n        - labels (list of bool, optional): Whether to display labels.\n        - **kwargs: Additional keyword arguments to pass to stackview.imshow.\n    xscale : float, optional\n        The x scale of the overview. Defaults to 3.\n    yscale : float, optional\n        The y scale of the overview. Defaults to 3.\n    plot_title : str, optional\n        The title of the plot. Defaults to an empty string.\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The matplotlib figure object containing the image overview.\n\n    \"\"\"\n    # create the subplot grid\n    num_rows = len(image_sets)\n    num_columns = max([len(image_set['image']) for image_set in image_sets])\n    fig, axs = plt.subplots(\n        num_rows,\n        num_columns,\n        figsize=(num_columns * xscale, num_rows * yscale),\n    )\n\n    if num_rows == 1:\n        axs = [axs]\n    if num_columns == 1:\n        axs = [[ax] for ax in axs]\n\n    # iterate through the image sets\n    for row, image_set in enumerate(image_sets):\n        for col, _image in enumerate(image_set['image']):\n            # create a dictionary from the col-th values of each key\n            image_dict = {key: value[col] for key, value in image_set.items()}\n\n            # turn off the subplot and continue if there is no image\n            if image_dict.get('image') is None:\n                axs[row][col].axis('off')\n                continue\n\n            # create a labels key if it doesn't exist, but does in colormap\n            cmap = image_dict.get('colormap')\n            if cmap is not None and cmap.lower() == 'labels':\n                image_dict['labels'] = True\n\n            stackview.imshow(**image_dict, plot=axs[row][col])\n\n    plt.suptitle(plot_title, fontsize=16)\n    plt.tight_layout()\n    # plt.subplots_adjust(wspace=0.1, hspace=0.1)\n\n    return fig\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(image_sets)","title":"<code>image_sets</code>","text":"(<code>list of dict</code>)           \u2013            <p>A list of dictionaries, each containing an image set. Each image set should be a dictionary containing the following keys: - image (list): A list of images to display. - title (list of str, optional): The title of the image set. - colormap (list of str, optional): The colormap to use.     \"labels\" will display the image as labels. - labels (list of bool, optional): Whether to display labels. - **kwargs: Additional keyword arguments to pass to stackview.imshow.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(xscale)","title":"<code>xscale</code>","text":"(<code>float</code>, default:                   <code>3</code> )           \u2013            <p>The x scale of the overview. Defaults to 3.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(yscale)","title":"<code>yscale</code>","text":"(<code>float</code>, default:                   <code>3</code> )           \u2013            <p>The y scale of the overview. Defaults to 3.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(plot_title)","title":"<code>plot_title</code>","text":"(<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The title of the plot. Defaults to an empty string.</p>"},{"location":"api/measure/","title":"Measure","text":""},{"location":"api/measure/#napari_ndev.measure","title":"napari_ndev.measure","text":"<p>Functions for measuring properties of labels.</p> <p>Measure properties of labels in images using sci-kit image's regionprops. It includes utilities for handling label and intensity images, extracting information from ID strings, renaming intensity columns, and mapping treatment dictionaries to DataFrame ID columns.</p> <p>Functions:</p> <ul> <li> <code>measure_regionprops : Measure properties of labels with sci-kit image regionprops.</code>             \u2013              </li> <li> <code>group_and_agg_measurements : Count and aggregate measurements by grouping IDs from measurement results.</code>             \u2013              </li> </ul>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements","title":"group_and_agg_measurements","text":"<pre><code>group_and_agg_measurements(\n    df, grouping_cols=\"id\", count_col=\"label\", agg_cols=None, agg_funcs=\"mean\"\n)\n</code></pre> <p>Count and aggregate measurements by grouping IDs from measurement results.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The DataFrame with grouped and aggregated measurements.</p> </li> </ul> Source code in <code>src/napari_ndev/measure.py</code> <pre><code>def group_and_agg_measurements(\n    df: pd.DataFrame,\n    grouping_cols: str | list[str] = 'id',\n    count_col: str = 'label',\n    agg_cols: list[str] | None = None,\n    agg_funcs: str | list[str] = 'mean',\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Count and aggregate measurements by grouping IDs from measurement results.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame with measurement properties, usually from measure_regionprops.\n    grouping_cols : str or list of str, optional\n        The columns to group by. By default, just the image ID.\n    count_col : str, optional\n        The column to count. By default, just the 'label' column.\n    agg_cols : list of str or None, optional\n        The columns to aggregate. By default, None.\n    agg_funcs : str or list of str, optional\n        The aggregating functions. By default, just the mean.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame with grouped and aggregated measurements.\n\n    \"\"\"\n    # get count data\n    df_count = (\n            df.copy().groupby(grouping_cols)\n            .agg({count_col: 'count'}) # counts count_col\n            .rename(columns={count_col: f'{count_col}_count'})\n            .reset_index()\n        )\n\n    if agg_cols is None or agg_cols == []:\n        return df_count\n\n    # get aggregated data\n    agg_cols = df[agg_cols]\n    agg_dict = {col: agg_funcs for col in agg_cols}\n    df_agg = (\n            df.copy()\n            .groupby(grouping_cols)  # sw\n            .agg(agg_dict)\n            .reset_index()\n        )  # genereates a multi-index\n        # collapse multi index and combine columns names with '_' sep\n    df_agg.columns = [\n            f'{col[0]}_{col[1]}' if col[1] else col[0]\n            for col in df_agg.columns\n        ]\n\n    # insert label count column into df_agg after grouping columns\n    insert_pos = 1 if isinstance(grouping_cols, str) else len(grouping_cols)\n    df_agg.insert(insert_pos, 'label_count', df_count['label_count'])\n\n    return df_agg\n</code></pre>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(df)","title":"<code>df</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame with measurement properties, usually from measure_regionprops.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(grouping_cols)","title":"<code>grouping_cols</code>","text":"(<code>str or list of str</code>, default:                   <code>'id'</code> )           \u2013            <p>The columns to group by. By default, just the image ID.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(count_col)","title":"<code>count_col</code>","text":"(<code>str</code>, default:                   <code>'label'</code> )           \u2013            <p>The column to count. By default, just the 'label' column.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(agg_cols)","title":"<code>agg_cols</code>","text":"(<code>list of str or None</code>, default:                   <code>None</code> )           \u2013            <p>The columns to aggregate. By default, None.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(agg_funcs)","title":"<code>agg_funcs</code>","text":"(<code>str or list of str</code>, default:                   <code>'mean'</code> )           \u2013            <p>The aggregating functions. By default, just the mean.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops","title":"measure_regionprops","text":"<pre><code>measure_regionprops(\n    label_images,\n    label_names=None,\n    intensity_images=None,\n    intensity_names=None,\n    properties=None,\n    scale=(1, 1),\n    id_string=None,\n    id_regex_dict=None,\n    tx_id=None,\n    tx_dict=None,\n    tx_n_well=None,\n    save_data_path=None,\n)\n</code></pre> <p>Measure properties of labels with sci-kit image regionprops.</p> <p>Optionally give a list of intensity_images to measure intensity properties of labels (i.e. 'intensity_mean', 'intensity_min', 'intensity_max', 'intensity_std'). If no label or intensity names are given, the names are automatically generated as a string of the input variable name. Choose from a list of properties to measure: [         \"label\",         \"area\",         \"area_convex\",         \"bbox\",         \"centroid\",         \"eccentricity\",         \"extent\",         \"feret_diameter_max\",         \"intensity_max\",         \"intensity_mean\",         \"intensity_min\",         \"intensity_std\",         \"num_pixels\",         \"orientation\",         \"perimeter\",         \"solidity\",     ].</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The DataFrame with measured properties.</p> </li> </ul> Source code in <code>src/napari_ndev/measure.py</code> <pre><code>def measure_regionprops(\n    label_images: list[ArrayLike] | ArrayLike,\n    label_names: list[str] | str | None = None,\n    intensity_images: list[ArrayLike] | ArrayLike | None = None,\n    intensity_names: list[str] | str | None = None,\n    properties: list[str] | None = None,\n    scale: tuple[float, float] | tuple[float, float, float] = (1, 1),\n    id_string: str | None = None,\n    id_regex_dict: dict | None = None,\n    tx_id: str | None = None,\n    tx_dict: dict | None = None,\n    tx_n_well: int | None = None,\n    save_data_path: PathLike = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Measure properties of labels with sci-kit image regionprops.\n\n    Optionally give a list of intensity_images to measure intensity properties\n    of labels (i.e. 'intensity_mean', 'intensity_min', 'intensity_max',\n    'intensity_std'). If no label or intensity names are given, the names are\n    automatically generated as a string of the input variable name.\n    Choose from a list of properties to measure: [\n            \"label\",\n            \"area\",\n            \"area_convex\",\n            \"bbox\",\n            \"centroid\",\n            \"eccentricity\",\n            \"extent\",\n            \"feret_diameter_max\",\n            \"intensity_max\",\n            \"intensity_mean\",\n            \"intensity_min\",\n            \"intensity_std\",\n            \"num_pixels\",\n            \"orientation\",\n            \"perimeter\",\n            \"solidity\",\n        ].\n\n    Parameters\n    ----------\n    label_images : list of ArrayLike or ArrayLike\n        The label images.\n    label_names : list of str or str or None, optional\n        The names of the label images.\n    intensity_images : list of ArrayLike or ArrayLike or None, optional\n        The intensity images.\n    intensity_names : list of str or str or None, optional\n        The names of the intensity images.\n    properties : list of str or None, optional\n        The properties to measure.\n    scale : tuple of float, optional\n        The scale for the measurements.\n    id_string : str or None, optional\n        The ID string.\n    id_regex_dict : dict or None, optional\n        The regex dictionary for extracting information from the ID string.\n    tx_id : str or None, optional\n        The treatment ID.\n    tx_dict : dict or None, optional\n        The treatment dictionary.\n    tx_n_well : int or None, optional\n        The number of wells in the plate.\n    save_data_path : PathLike or None, optional\n        The path to save the data.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame with measured properties.\n\n    \"\"\"\n    from skimage import measure\n\n    if properties is None:\n        properties = ['area']\n    measure_dict = _generate_measure_dict(\n        label_images, label_names, intensity_images, intensity_names\n    )\n\n    if intensity_images is not None:\n        if len(measure_dict['intensity_images']) == 1:\n            intensity_stack = measure_dict['intensity_images'][0]\n        else:\n            intensity_stack = np.stack(\n                measure_dict['intensity_images'], axis=-1\n            )\n    else:\n        intensity_stack = None\n\n    measure_df_list = []\n\n    for label_idx, label_image in enumerate(measure_dict['label_images']):\n        measure_props = measure.regionprops_table(\n            label_image=label_image,\n            intensity_image=intensity_stack,\n            properties=properties,\n            spacing=scale,\n        )\n\n        measure_df = pd.DataFrame(measure_props)\n        measure_df.insert(0, 'label_name', measure_dict['label_names'][label_idx])\n        measure_df_list.append(measure_df)\n\n    if len(measure_df_list) &gt; 1:\n        measure_df = pd.concat(measure_df_list, ignore_index=True)\n\n    if intensity_names is not None:\n        measure_df = _rename_intensity_columns(\n            measure_df, measure_dict['intensity_names']\n        )\n\n    measure_df.insert(1, 'id', id_string)\n\n    if id_regex_dict is not None:\n        id_dict = _extract_info_from_id_string(id_string, id_regex_dict)\n        for key, value in id_dict.items():\n            measure_df.insert(2, key, value)\n\n    if tx_id is not None and tx_dict is not None:\n        _map_tx_dict_to_df_id_col(tx_dict, tx_n_well, measure_df, tx_id)\n\n    if save_data_path is not None:\n        measure_df.to_csv(save_data_path, index=False)\n\n    return measure_df\n</code></pre>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(label_images)","title":"<code>label_images</code>","text":"(<code>list of ArrayLike or ArrayLike</code>)           \u2013            <p>The label images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(label_names)","title":"<code>label_names</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the label images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(intensity_images)","title":"<code>intensity_images</code>","text":"(<code>list of ArrayLike or ArrayLike or None</code>, default:                   <code>None</code> )           \u2013            <p>The intensity images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(intensity_names)","title":"<code>intensity_names</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the intensity images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(properties)","title":"<code>properties</code>","text":"(<code>list of str or None</code>, default:                   <code>None</code> )           \u2013            <p>The properties to measure.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(scale)","title":"<code>scale</code>","text":"(<code>tuple of float</code>, default:                   <code>(1, 1)</code> )           \u2013            <p>The scale for the measurements.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(id_string)","title":"<code>id_string</code>","text":"(<code>str or None</code>, default:                   <code>None</code> )           \u2013            <p>The ID string.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(id_regex_dict)","title":"<code>id_regex_dict</code>","text":"(<code>dict or None</code>, default:                   <code>None</code> )           \u2013            <p>The regex dictionary for extracting information from the ID string.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_id)","title":"<code>tx_id</code>","text":"(<code>str or None</code>, default:                   <code>None</code> )           \u2013            <p>The treatment ID.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_dict)","title":"<code>tx_dict</code>","text":"(<code>dict or None</code>, default:                   <code>None</code> )           \u2013            <p>The treatment dictionary.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_n_well)","title":"<code>tx_n_well</code>","text":"(<code>int or None</code>, default:                   <code>None</code> )           \u2013            <p>The number of wells in the plate.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(save_data_path)","title":"<code>save_data_path</code>","text":"(<code>PathLike or None</code>, default:                   <code>None</code> )           \u2013            <p>The path to save the data.</p>"},{"location":"api/morphology/","title":"Morphology","text":""},{"location":"api/morphology/#napari_ndev.morphology","title":"napari_ndev.morphology","text":"<p>Functions for processing label morphology.</p> <p>Process labels with various functions using pyclesperanto and scikit-image. Intended to be compatible with workflow.yaml files, and will be incorporated into napari-workflows and napari-assistant in the future. Should accept both OCLArray and other ArrayLike types.</p> <p>Functions:</p> <ul> <li> <code>skeletonize_labels : Create skeletons with label identities from a label image.</code>             \u2013              </li> </ul>"},{"location":"api/morphology/#napari_ndev.morphology.connect_breaks_between_labels","title":"connect_breaks_between_labels","text":"<pre><code>connect_breaks_between_labels(label, connect_distance)\n</code></pre> <p>Connect breaks between labels in a label image.</p> <p>Return the input label image with new label identities connecting breaks between the original labels. The new labels have the original label dimensions, so this is intended to keep the overall morphology the same, just with new labels connecting the original labels if under the specified distance.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ArrayLike</code>           \u2013            <p>Label image with new labels connecting breaks between original labels.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def connect_breaks_between_labels(label: ArrayLike, connect_distance: float) -&gt; ArrayLike: # pragma: no cover\n    \"\"\"\n    Connect breaks between labels in a label image.\n\n    Return the input label image with new label identities connecting breaks\n    between the original labels. The new labels have the original label\n    dimensions, so this is intended to keep the overall morphology the same,\n    just with new labels connecting the original labels if under the specified\n    distance.\n\n    Parameters\n    ----------\n    label : ArrayLike\n        Label image.\n    connect_distance : float\n        Maximum distance to connect labels, in pixels.\n\n    Returns\n    -------\n    ArrayLike\n        Label image with new labels connecting breaks between original labels.\n\n    \"\"\"\n    label_dilated = cle.dilate_labels(label, radius=connect_distance/2)\n    label_merged = cle.merge_touching_labels(label_dilated)\n    # relabel original labels based on the merged labels\n    return (label_merged * (label &gt; 0)).astype(np.uint16)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.connect_breaks_between_labels(label)","title":"<code>label</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.connect_breaks_between_labels(connect_distance)","title":"<code>connect_distance</code>","text":"(<code>float</code>)           \u2013            <p>Maximum distance to connect labels, in pixels.</p>"},{"location":"api/morphology/#napari_ndev.morphology.label_voronoi_based_on_intensity","title":"label_voronoi_based_on_intensity","text":"<pre><code>label_voronoi_based_on_intensity(label, intensity_image)\n</code></pre> <p>Create a voronoi label masks of labels based on an intensity image.</p> <p>Return a label image with Voronoi regions based on the intensity image. The intensity image should be the same shape as the label image, and the labels will be assigned to the Voronoi regions based on the intensity values.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ArrayLike</code>           \u2013            <p>Label image with Voronoi regions based on the intensity image.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def label_voronoi_based_on_intensity(label: ArrayLike, intensity_image: ArrayLike) -&gt; ArrayLike: # pragma: no cover\n    \"\"\"\n    Create a voronoi label masks of labels based on an intensity image.\n\n    Return a label image with Voronoi regions based on the intensity image.\n    The intensity image should be the same shape as the label image, and the\n    labels will be assigned to the Voronoi regions based on the intensity\n    values.\n\n    Parameters\n    ----------\n    label : ArrayLike\n        Label image.\n    intensity_image : ArrayLike\n        Intensity image.\n\n    Returns\n    -------\n    ArrayLike\n        Label image with Voronoi regions based on the intensity image.\n\n    \"\"\"\n    label_binary = cle.greater_constant(label, constant=0) # binarize\n    intensity_blur = cle.gaussian_blur(intensity_image, sigma_x=1, sigma_y=1)\n    intensity_peaks = cle.detect_maxima_box(intensity_blur, radius_x=0, radius_y=0)\n    select_peaks_on_binary = cle.binary_and(intensity_peaks, label_binary)\n    return cle.masked_voronoi_labeling(select_peaks_on_binary, label_binary)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.label_voronoi_based_on_intensity(label)","title":"<code>label</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.label_voronoi_based_on_intensity(intensity_image)","title":"<code>intensity_image</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Intensity image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.skeletonize_labels","title":"skeletonize_labels","text":"<pre><code>skeletonize_labels(label)\n</code></pre> <p>Create skeletons and maintains label identities from a label image.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Skeletonized label image.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def skeletonize_labels(label: ArrayLike) -&gt; np.ndarray:\n    \"\"\"\n    Create skeletons and maintains label identities from a label image.\n\n    Parameters\n    ----------\n    label : ArrayLike\n        Label image.\n\n    Returns\n    -------\n    np.ndarray\n        Skeletonized label image.\n\n    \"\"\"\n    from skimage.morphology import skeletonize\n\n    skeleton = skeletonize(cle.pull(label))\n    return (label * skeleton).astype(np.uint16)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.skeletonize_labels(label)","title":"<code>label</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/plate_mapper/","title":"PlateMapper","text":""},{"location":"api/plate_mapper/#napari_ndev._plate_mapper","title":"napari_ndev._plate_mapper","text":""},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper","title":"PlateMapper","text":"<p>A class for creating and manipulating plate maps.</p> <p>Attributes:</p> <ul> <li> <code>plate_size</code>               (<code>int</code>)           \u2013            <p>The size of the plate (e.g., 96, 384).</p> </li> <li> <code>wells</code>               (<code>dict</code>)           \u2013            <p>A dictionary mapping plate sizes to the number of rows and columns.</p> </li> <li> <code>plate_map</code>               (<code>DataFrame</code>)           \u2013            <p>The plate map DataFrame with well labels.</p> </li> <li> <code>plate_map_pivot</code>               (<code>DataFrame</code>)           \u2013            <p>The wide-formatted plate map DataFrame with treatments as columns.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>__init__</code>             \u2013              <p>Initializes a PlateMapper object.</p> </li> <li> <code>create_empty_plate_map</code>             \u2013              <p>Creates an empty plate map DataFrame for a given plate size.</p> </li> <li> <code>assign_treatments</code>             \u2013              <p>Assigns treatments to specific wells in a plate map.</p> </li> <li> <code>get_pivoted_plate_map</code>             \u2013              <p>Pivots a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.</p> </li> <li> <code>get_styled_plate_map</code>             \u2013              <p>Styles a plate map DataFrame with different background colors for each unique value.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>class PlateMapper:\n    \"\"\"\n    A class for creating and manipulating plate maps.\n\n    Attributes\n    ----------\n    plate_size : int\n        The size of the plate (e.g., 96, 384).\n    wells : dict\n        A dictionary mapping plate sizes to the number of rows and columns.\n    plate_map : pandas.DataFrame\n        The plate map DataFrame with well labels.\n    plate_map_pivot : pandas.DataFrame\n        The wide-formatted plate map DataFrame with treatments as columns.\n\n    Methods\n    -------\n    __init__(plate_size=96)\n        Initializes a PlateMapper object.\n    create_empty_plate_map()\n        Creates an empty plate map DataFrame for a given plate size.\n    assign_treatments(treatments)\n        Assigns treatments to specific wells in a plate map.\n    get_pivoted_plate_map(treatment)\n        Pivots a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.\n    get_styled_plate_map(treatment, palette='colorblind')\n        Styles a plate map DataFrame with different background colors for each unique value.\n\n    \"\"\"\n\n    def __init__(self, plate_size=96):\n        \"\"\"\n        Initialize a PlateMapper object.\n\n        Parameters\n        ----------\n        plate_size : int, optional\n            The size of the plate. Defaults to 96.\n\n        \"\"\"\n        self.plate_size = plate_size\n        self.wells = {\n            6: (2, 3),\n            12: (3, 4),\n            24: (4, 6),\n            48: (6, 8),\n            96: (8, 12),\n            384: (16, 24),\n        }\n        self.plate_map = self.create_empty_plate_map()\n        self.plate_map_pivot = None\n\n    def create_empty_plate_map(self):\n        \"\"\"\n        Create an empty plate map DataFrame for a given plate size.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The empty plate map DataFrame with well labels.\n\n        \"\"\"\n        num_rows, num_columns = self.wells[self.plate_size]\n\n        row_labels = list(string.ascii_uppercase)[:num_rows]\n        column_labels = list(range(1, num_columns + 1))\n\n        well_rows = row_labels * num_columns\n        well_rows.sort()  # needed to sort the rows correctly\n        well_columns = column_labels * num_rows\n\n        well_labels_dict = {'row': well_rows, 'column': well_columns}\n\n        plate_map_df = pd.DataFrame(well_labels_dict)\n\n        plate_map_df['well_id'] = plate_map_df['row'] + plate_map_df[\n            'column'\n        ].astype(str)\n        self.plate_map = plate_map_df\n        return plate_map_df\n\n    def assign_treatments(self, treatments):\n        \"\"\"\n        Assign treatments to specific wells in a plate map.\n\n        Parameters\n        ----------\n        treatments : dict\n            A dictionary mapping treatments to conditions and well ranges.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The updated plate map with treatments assigned to specific wells.\n\n        \"\"\"\n        for treatment, conditions in treatments.items():\n            for condition, wells in conditions.items():\n                for well in wells:\n                    if ':' in well:\n                        start, end = well.split(':')\n                        start_row, start_col = start[0], int(start[1:])\n                        end_row, end_col = end[0], int(end[1:])\n                        well_condition = (\n                            (self.plate_map['row'] &gt;= start_row)\n                            &amp; (self.plate_map['row'] &lt;= end_row)\n                            &amp; (self.plate_map['column'] &gt;= start_col)\n                            &amp; (self.plate_map['column'] &lt;= end_col)\n                        )\n                    else:\n                        row, col = well[0], int(well[1:])\n                        well_condition = (self.plate_map['row'] == row) &amp; (\n                            self.plate_map['column'] == col\n                        )\n\n                    self.plate_map.loc[well_condition, treatment] = condition\n        return self.plate_map\n\n    def get_pivoted_plate_map(self, treatment):\n        \"\"\"\n        Pivot a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.\n\n        Parameters\n        ----------\n        treatment : str\n            The column name of the treatment variable in the plate map DataFrame.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The wide-formatted plate map DataFrame with treatments as columns.\n\n        \"\"\"\n        plate_map_pivot = self.plate_map.pivot(\n            index='row', columns='column', values=treatment\n        )\n        self.plate_map_pivot = plate_map_pivot\n        return plate_map_pivot\n\n    def get_styled_plate_map(self, treatment, palette='colorblind'):\n        \"\"\"\n        Style a plate map with background colors for each unique value.\n\n        Parameters\n        ----------\n        treatment : str\n            The column name of the treatment variable in the plate map DataFrame.\n        palette : str or list, optional\n            The color palette to use for styling. Defaults to 'colorblind'.\n\n        Returns\n        -------\n        pandas.io.formats.style.Styler\n            The styled plate map DataFrame with different background colors for each unique value.\n\n        \"\"\"\n        from seaborn import color_palette\n\n        self.plate_map_pivot = self.get_pivoted_plate_map(treatment)\n\n        unique_values = pd.unique(self.plate_map_pivot.values.flatten())\n        unique_values = unique_values[pd.notna(unique_values)]\n\n        color_palette_hex = color_palette(palette).as_hex()\n        # Create an infinite iterator that cycles through the palette\n        palette_cycle = itertools.cycle(color_palette_hex)\n        # Use next() to get the next color\n        color_dict = {value: next(palette_cycle) for value in unique_values}\n\n        def get_background_color(value):\n            if pd.isna(value):\n                return ''\n            return f'background-color: {color_dict[value]}'\n\n        plate_map_styled = (\n            self.plate_map_pivot.style.applymap(get_background_color)\n            .set_caption(f'{treatment} Plate Map')\n            .format(lambda x: '' if pd.isna(x) else x)\n        )\n\n        return plate_map_styled\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.__init__","title":"__init__","text":"<pre><code>__init__(plate_size=96)\n</code></pre> <p>Initialize a PlateMapper object.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def __init__(self, plate_size=96):\n    \"\"\"\n    Initialize a PlateMapper object.\n\n    Parameters\n    ----------\n    plate_size : int, optional\n        The size of the plate. Defaults to 96.\n\n    \"\"\"\n    self.plate_size = plate_size\n    self.wells = {\n        6: (2, 3),\n        12: (3, 4),\n        24: (4, 6),\n        48: (6, 8),\n        96: (8, 12),\n        384: (16, 24),\n    }\n    self.plate_map = self.create_empty_plate_map()\n    self.plate_map_pivot = None\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.__init__(plate_size)","title":"<code>plate_size</code>","text":"(<code>int</code>, default:                   <code>96</code> )           \u2013            <p>The size of the plate. Defaults to 96.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.assign_treatments","title":"assign_treatments","text":"<pre><code>assign_treatments(treatments)\n</code></pre> <p>Assign treatments to specific wells in a plate map.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The updated plate map with treatments assigned to specific wells.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def assign_treatments(self, treatments):\n    \"\"\"\n    Assign treatments to specific wells in a plate map.\n\n    Parameters\n    ----------\n    treatments : dict\n        A dictionary mapping treatments to conditions and well ranges.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The updated plate map with treatments assigned to specific wells.\n\n    \"\"\"\n    for treatment, conditions in treatments.items():\n        for condition, wells in conditions.items():\n            for well in wells:\n                if ':' in well:\n                    start, end = well.split(':')\n                    start_row, start_col = start[0], int(start[1:])\n                    end_row, end_col = end[0], int(end[1:])\n                    well_condition = (\n                        (self.plate_map['row'] &gt;= start_row)\n                        &amp; (self.plate_map['row'] &lt;= end_row)\n                        &amp; (self.plate_map['column'] &gt;= start_col)\n                        &amp; (self.plate_map['column'] &lt;= end_col)\n                    )\n                else:\n                    row, col = well[0], int(well[1:])\n                    well_condition = (self.plate_map['row'] == row) &amp; (\n                        self.plate_map['column'] == col\n                    )\n\n                self.plate_map.loc[well_condition, treatment] = condition\n    return self.plate_map\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.assign_treatments(treatments)","title":"<code>treatments</code>","text":"(<code>dict</code>)           \u2013            <p>A dictionary mapping treatments to conditions and well ranges.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.create_empty_plate_map","title":"create_empty_plate_map","text":"<pre><code>create_empty_plate_map()\n</code></pre> <p>Create an empty plate map DataFrame for a given plate size.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The empty plate map DataFrame with well labels.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def create_empty_plate_map(self):\n    \"\"\"\n    Create an empty plate map DataFrame for a given plate size.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The empty plate map DataFrame with well labels.\n\n    \"\"\"\n    num_rows, num_columns = self.wells[self.plate_size]\n\n    row_labels = list(string.ascii_uppercase)[:num_rows]\n    column_labels = list(range(1, num_columns + 1))\n\n    well_rows = row_labels * num_columns\n    well_rows.sort()  # needed to sort the rows correctly\n    well_columns = column_labels * num_rows\n\n    well_labels_dict = {'row': well_rows, 'column': well_columns}\n\n    plate_map_df = pd.DataFrame(well_labels_dict)\n\n    plate_map_df['well_id'] = plate_map_df['row'] + plate_map_df[\n        'column'\n    ].astype(str)\n    self.plate_map = plate_map_df\n    return plate_map_df\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_pivoted_plate_map","title":"get_pivoted_plate_map","text":"<pre><code>get_pivoted_plate_map(treatment)\n</code></pre> <p>Pivot a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The wide-formatted plate map DataFrame with treatments as columns.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def get_pivoted_plate_map(self, treatment):\n    \"\"\"\n    Pivot a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.\n\n    Parameters\n    ----------\n    treatment : str\n        The column name of the treatment variable in the plate map DataFrame.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The wide-formatted plate map DataFrame with treatments as columns.\n\n    \"\"\"\n    plate_map_pivot = self.plate_map.pivot(\n        index='row', columns='column', values=treatment\n    )\n    self.plate_map_pivot = plate_map_pivot\n    return plate_map_pivot\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_pivoted_plate_map(treatment)","title":"<code>treatment</code>","text":"(<code>str</code>)           \u2013            <p>The column name of the treatment variable in the plate map DataFrame.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_styled_plate_map","title":"get_styled_plate_map","text":"<pre><code>get_styled_plate_map(treatment, palette='colorblind')\n</code></pre> <p>Style a plate map with background colors for each unique value.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Styler</code>           \u2013            <p>The styled plate map DataFrame with different background colors for each unique value.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def get_styled_plate_map(self, treatment, palette='colorblind'):\n    \"\"\"\n    Style a plate map with background colors for each unique value.\n\n    Parameters\n    ----------\n    treatment : str\n        The column name of the treatment variable in the plate map DataFrame.\n    palette : str or list, optional\n        The color palette to use for styling. Defaults to 'colorblind'.\n\n    Returns\n    -------\n    pandas.io.formats.style.Styler\n        The styled plate map DataFrame with different background colors for each unique value.\n\n    \"\"\"\n    from seaborn import color_palette\n\n    self.plate_map_pivot = self.get_pivoted_plate_map(treatment)\n\n    unique_values = pd.unique(self.plate_map_pivot.values.flatten())\n    unique_values = unique_values[pd.notna(unique_values)]\n\n    color_palette_hex = color_palette(palette).as_hex()\n    # Create an infinite iterator that cycles through the palette\n    palette_cycle = itertools.cycle(color_palette_hex)\n    # Use next() to get the next color\n    color_dict = {value: next(palette_cycle) for value in unique_values}\n\n    def get_background_color(value):\n        if pd.isna(value):\n            return ''\n        return f'background-color: {color_dict[value]}'\n\n    plate_map_styled = (\n        self.plate_map_pivot.style.applymap(get_background_color)\n        .set_caption(f'{treatment} Plate Map')\n        .format(lambda x: '' if pd.isna(x) else x)\n    )\n\n    return plate_map_styled\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_styled_plate_map(treatment)","title":"<code>treatment</code>","text":"(<code>str</code>)           \u2013            <p>The column name of the treatment variable in the plate map DataFrame.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_styled_plate_map(palette)","title":"<code>palette</code>","text":"(<code>str or list</code>, default:                   <code>'colorblind'</code> )           \u2013            <p>The color palette to use for styling. Defaults to 'colorblind'.</p>"},{"location":"api/widgets/apoc_widget/","title":"Apoc widget","text":""},{"location":"api/widgets/apoc_widget/#napari_ndev.widgets._apoc_container","title":"napari_ndev.widgets._apoc_container","text":""},{"location":"api/widgets/apoc_widget/#napari_ndev.widgets._apoc_container.ApocContainer","title":"ApocContainer","text":"<p>               Bases: <code>Container</code></p> <p>Container class for managing the ApocContainer widget in napari.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>_viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_image_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the image directory.</p> </li> <li> <code>_label_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the label directory.</p> </li> <li> <code>_output_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the output directory.</p> </li> <li> <code>_classifier_file</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the classifier file.</p> </li> <li> <code>_classifier_type_mapping</code>               (<code>dict</code>)           \u2013            <p>Mapping of classifier types to their corresponding classes.</p> </li> <li> <code>_classifier_type</code>               (<code>RadioButtons</code>)           \u2013            <p>Widget for selecting the classifier type.</p> </li> <li> <code>_max_depth</code>               (<code>SpinBox</code>)           \u2013            <p>Widget for selecting the number of forests.</p> </li> <li> <code>_num_trees</code>               (<code>SpinBox</code>)           \u2013            <p>Widget for selecting the number of trees.</p> </li> <li> <code>_positive_class_id</code>               (<code>SpinBox</code>)           \u2013            <p>Widget for selecting the object label ID.</p> </li> <li> <code>_image_channels</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting the image channels.</p> </li> <li> <code>_channel_order_label</code>               (<code>Label</code>)           \u2013            <p>Label widget for displaying the selected channel order.</p> </li> <li> <code>_PDFS</code>               (<code>Enum</code>)           \u2013            <p>Enum for predefined feature sets.</p> </li> <li> <code>_predefined_features</code>               (<code>ComboBox</code>)           \u2013            <p>Widget for selecting the features.</p> </li> <li> <code>_custom_features</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering custom feature string.</p> </li> <li> <code>_open_custom_feature_generator</code>               (<code>PushButton</code>)           \u2013            <p>Button for opening the custom feature generator widget.</p> </li> <li> <code>_continue_training</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox for indicating whether to continue training.</p> </li> <li> <code>_batch_train_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for training the classifier on image-label pairs.</p> </li> <li> <code>_batch_predict_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for predicting labels with the classifier.</p> </li> <li> <code>_progress_bar</code>               (<code>ProgressBar</code>)           \u2013            <p>Progress bar widget.</p> </li> <li> <code>_image_layer</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting the image layers.</p> </li> <li> <code>_label_layer</code>               (<code>Widget</code>)           \u2013            <p>Widget for selecting the label layers.</p> </li> <li> <code>_train_image_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for training the classifier on selected layers using labels.</p> </li> <li> <code>_predict_image_layer</code>               (<code>PushButton</code>)           \u2013            <p>Button for predicting using the classifier on selected layers.</p> </li> <li> <code>_single_result_label</code>               (<code>Label</code>)           \u2013            <p>Label widget for displaying a single result.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_update_metadata_from_file</code>             \u2013              <p>Update the metadata from the selected image directory.</p> </li> <li> <code>_update_channel_order</code>             \u2013              <p>Update the channel order label based on the selected image channels.</p> </li> <li> <code>_set_value_from_pattern</code>             \u2013              <p>Set the value from a pattern in the content.</p> </li> <li> <code>_process_classifier_metadata</code>             \u2013              <p>Process the classifier metadata from the content.</p> </li> <li> <code>_update_classifier_metadata</code>             \u2013              <p>Update the classifier metadata based on the selected classifier file.</p> </li> <li> <code>_classifier_statistics_table</code>             \u2013              <p>Display the classifier statistics table.</p> </li> <li> <code>_get_feature_set</code>             \u2013              <p>Get the selected feature set.</p> </li> <li> <code>_get_training_classifier_instance</code>             \u2013              <p>Get the training classifier instance based on the selected classifier type.</p> </li> <li> <code>_get_channel_image</code>             \u2013              <p>Get the channel image based on the selected channel index list.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_apoc_container.py</code> <pre><code>class ApocContainer(Container):\n    \"\"\"\n    Container class for managing the ApocContainer widget in napari.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    Attributes\n    ----------\n    _viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    _image_directory : FileEdit\n        Widget for selecting the image directory.\n\n    _label_directory : FileEdit\n        Widget for selecting the label directory.\n\n    _output_directory : FileEdit\n        Widget for selecting the output directory.\n\n    _classifier_file : FileEdit\n        Widget for selecting the classifier file.\n\n    _classifier_type_mapping : dict\n        Mapping of classifier types to their corresponding classes.\n\n    _classifier_type : RadioButtons\n        Widget for selecting the classifier type.\n\n    _max_depth : SpinBox\n        Widget for selecting the number of forests.\n\n    _num_trees : SpinBox\n        Widget for selecting the number of trees.\n\n    _positive_class_id : SpinBox\n        Widget for selecting the object label ID.\n\n    _image_channels : Select\n        Widget for selecting the image channels.\n\n    _channel_order_label : Label\n        Label widget for displaying the selected channel order.\n\n    _PDFS : Enum\n        Enum for predefined feature sets.\n\n    _predefined_features : ComboBox\n        Widget for selecting the features.\n\n    _custom_features : LineEdit\n        Widget for entering custom feature string.\n\n    _open_custom_feature_generator : PushButton\n        Button for opening the custom feature generator widget.\n\n    _continue_training : CheckBox\n        Checkbox for indicating whether to continue training.\n\n    _batch_train_button : PushButton\n        Button for training the classifier on image-label pairs.\n\n    _batch_predict_button : PushButton\n        Button for predicting labels with the classifier.\n\n    _progress_bar : ProgressBar\n        Progress bar widget.\n\n    _image_layer : Select\n        Widget for selecting the image layers.\n\n    _label_layer : Widget\n        Widget for selecting the label layers.\n\n    _train_image_button : PushButton\n        Button for training the classifier on selected layers using labels.\n\n    _predict_image_layer : PushButton\n        Button for predicting using the classifier on selected layers.\n\n    _single_result_label : Label\n        Label widget for displaying a single result.\n\n    Methods\n    -------\n    _update_metadata_from_file()\n        Update the metadata from the selected image directory.\n\n    _update_channel_order()\n        Update the channel order label based on the selected image channels.\n\n    _set_value_from_pattern(pattern, content)\n        Set the value from a pattern in the content.\n\n    _process_classifier_metadata(content)\n        Process the classifier metadata from the content.\n\n    _update_classifier_metadata()\n        Update the classifier metadata based on the selected classifier file.\n\n    _classifier_statistics_table(custom_classifier)\n        Display the classifier statistics table.\n\n    _get_feature_set()\n        Get the selected feature set.\n\n    _get_training_classifier_instance()\n        Get the training classifier instance based on the selected classifier\n        type.\n\n    _get_channel_image(img, channel_index_list)\n        Get the channel image based on the selected channel index list.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        viewer: napari.viewer.Viewer = None,\n        # viewer = napari_viewer\n    ):\n        super().__init__()\n        self._viewer = viewer if viewer is not None else None\n        self._lazy_imports()\n        self._initialize_widgets()\n        self._initialize_batch_container()\n        self._initialize_viewer_container()\n        self._initialize_custom_apoc_container()\n        self._setup_widget_layout()\n        self._connect_events()\n\n    def _lazy_imports(self):\n        import apoc\n\n        self.apoc = apoc\n\n    def _filter_layers(self, layer_type):\n        # only do this if the viewer is not None\n        if self._viewer is None:\n            return []\n        return [x for x in self._viewer.layers if isinstance(x, layer_type)]\n\n    def _initialize_widgets(self):\n        self._classifier_file = FileEdit(\n            label='Classifier File (.cl)',\n            mode='r',\n            tooltip='Create a .txt file and rename it to .cl ending.',\n        )\n\n        self._continue_training = CheckBox(\n            label='Continue Training?',\n            value=True,\n            tooltip=(\n                'Continue training only matters if classifier already exists.'\n            ),\n        )\n\n        self._classifier_type_mapping = {\n            'PixelClassifier': self.apoc.PixelClassifier,\n            'ObjectSegmenter': self.apoc.ObjectSegmenter,\n        }\n\n        self._classifier_type = RadioButtons(\n            label='Classifier Type',\n            value='ObjectSegmenter',\n            choices=['ObjectSegmenter', 'PixelClassifier'],\n            tooltip='Object Segmenter is used for detecting objects of one '\n            'class, including connected components. '\n            'Pixel Classifier is used to classify pixel-types.',\n        )\n        self._max_depth = SpinBox(\n            label='Num. of Forests',\n            value=2,\n            max=20,\n            step=1,\n            tooltip='Increases training time for each forest',\n        )\n        self._num_trees = SpinBox(\n            label='Num. of Trees',\n            value=100,\n            step=50,\n            tooltip='Increases computational requirements.',\n        )\n        self._positive_class_id = SpinBox(\n            label='Object Label ID',\n            value=2,\n            step=1,\n            tooltip='Only used with ObjectSegmenter, otherwise ignored.',\n        )\n\n        self._PDFS = Enum(\n            'PDFS', self.apoc.PredefinedFeatureSet._member_names_\n        )\n        self._predefined_features = ComboBox(\n            label='Features',\n            choices=self._PDFS,\n            nullable=True,\n            value=None,\n            tooltip=\"All featuresets except 'custom' are premade\",\n        )\n        self._feature_string = LineEdit(\n            label='Feature String',\n            tooltip=(\n                'A string in the form of ' \"'filter1=radius1 filter2=radius2'.\"\n            ),\n        )\n\n    def _initialize_batch_container(self):\n        self._image_directory = FileEdit(label='Image Directory', mode='d')\n        self._label_directory = FileEdit(label='Label Directory', mode='d')\n        self._output_directory = FileEdit(label='Output Directory', mode='d')\n\n        self._image_channels = Select(\n            label='Image Channels',\n            choices=[],\n            tooltip=(\n                'Channel order should be same for training and prediction.'\n            ),\n        )\n        self._channel_order_label = Label(value='Select an Image Channel!')\n\n        self._batch_train_button = PushButton(label='Train')\n        self._batch_predict_button = PushButton(label='Predict')\n\n        self._batch_train_container = Container(\n            layout='horizontal',\n            # label=\"Train Classifier on Image-Label Pairs\",\n        )\n        self._batch_train_container.extend(\n            [self._label_directory, self._batch_train_button]\n        )\n\n        self._batch_predict_container = Container(\n            layout='horizontal',\n            # label=\"Predict Labels with Classifier on Images\"\n        )\n        self._batch_predict_container.extend(\n            [self._output_directory, self._batch_predict_button]\n        )\n\n        self._progress_bar = ProgressBar(label='Progress:')\n\n        self._batch_container = Container(layout='vertical')\n        self._batch_container.extend(\n            [\n                self._image_directory,\n                self._image_channels,\n                self._channel_order_label,\n                self._batch_train_container,\n                self._batch_predict_container,\n                self._progress_bar,\n            ]\n        )\n\n    def _initialize_viewer_container(self):\n        self._image_layers = Select(\n            choices=self._filter_layers(layers.Image),\n            label='Image Layers',\n        )\n        self._label_layer = ComboBox(\n            choices=self._filter_layers(layers.Labels),\n            label='Label Layer',\n        )\n        self._train_image_button = PushButton(\n            label='Train classifier on selected layers using label'\n        )\n        self._predict_image_layer = PushButton(\n            label='Predict using classifier on selected layers'\n        )\n        self._single_result_label = Label()\n\n        self._viewer_container = Container(layout='vertical')\n        self._viewer_container.extend(\n            [\n                self._image_layers,\n                self._label_layer,\n                self._train_image_button,\n                self._predict_image_layer,\n                self._single_result_label,\n            ]\n        )\n\n    def _initialize_custom_apoc_container(self):\n        from napari_ndev import ApocFeatureStack\n\n        self._custom_apoc_container = ApocFeatureStack(viewer=self._viewer)\n\n    def _setup_widget_layout(self):\n        # from napari_ndev import ApocFeatureStack\n        self.extend(\n            [\n                self._classifier_file,\n                self._continue_training,\n                self._classifier_type,\n                self._positive_class_id,\n                self._max_depth,\n                self._num_trees,\n                self._predefined_features,\n                self._feature_string,\n            ]\n        )\n\n        tabs = QTabWidget()\n        tabs.addTab(self._batch_container.native, 'Batch')\n        tabs.addTab(self._viewer_container.native, 'Viewer')\n        tabs.addTab(self._custom_apoc_container.native, 'Custom Feature Set')\n        self.native.layout().addWidget(tabs)\n\n    def _connect_events(self):\n        self._image_directory.changed.connect(self._update_metadata_from_file)\n        self._image_channels.changed.connect(self._update_channel_order)\n        self._classifier_file.changed.connect(self._update_classifier_metadata)\n\n        self._batch_train_button.clicked.connect(self.batch_train)\n        self._batch_predict_button.clicked.connect(self.batch_predict)\n        self._train_image_button.clicked.connect(self.image_train)\n        self._predict_image_layer.clicked.connect(self.image_predict)\n\n        self._custom_apoc_container._generate_string_button.clicked.connect(\n            self.insert_custom_feature_string\n        )\n        self._predefined_features.changed.connect(self._get_feature_set)\n\n        # when self._viewer.layers is updated, update the choices in the ComboBox\n        if self._viewer is not None:\n            self._viewer.layers.events.removed.connect(\n                self._update_layer_choices\n            )\n            self._viewer.layers.events.inserted.connect(\n                self._update_layer_choices\n            )\n\n    def _update_layer_choices(self):\n        self._label_layer.choices = self._filter_layers(layers.Labels)\n        self._image_layers.choices = self._filter_layers(layers.Image)\n\n    def _update_metadata_from_file(self):\n        from bioio import BioImage\n\n        _, files = helpers.get_directory_and_files(self._image_directory.value)\n        img = BioImage(files[0])\n        self._image_channels.choices = helpers.get_channel_names(img)\n\n    def _update_channel_order(self):\n        self._channel_order_label.value = 'Selected Channel Order: ' + str(\n            self._image_channels.value\n        )\n\n    ##############################\n    # Classifier Related Functions\n    ##############################\n    def _set_value_from_pattern(self, pattern, content):\n        match = re.search(pattern, content)\n        return match.group(1) if match else None\n\n    def _process_classifier_metadata(self, content):\n        self._classifier_type.value = self._set_value_from_pattern(\n            r'classifier_class_name\\s*=\\s*([^\\n]+)', content\n        )\n        self._max_depth.value = self._set_value_from_pattern(\n            r'max_depth\\s*=\\s*(\\d+)', content\n        )\n        self._num_trees.value = self._set_value_from_pattern(\n            r'num_trees\\s*=\\s*(\\d+)', content\n        )\n        self._positive_class_id.value = (\n            self._set_value_from_pattern(\n                r'positive_class_identifier\\s*=\\s*(\\d+)', content\n            )\n            or 2\n        )\n\n    def _update_classifier_metadata(self):\n        with open(self._classifier_file.value) as file:\n            content = file.read()\n\n        # Ignore rest of function if file contents are empty\n        if not content.strip():\n            return\n\n        self._process_classifier_metadata(content)\n\n        if self._classifier_type.value in self._classifier_type_mapping:\n            classifier_class = self._classifier_type_mapping[\n                self._classifier_type.value\n            ]\n            custom_classifier = classifier_class(\n                opencl_filename=self._classifier_file.value\n            )\n        else:\n            custom_classifier = None\n\n        self._classifier_statistics_table(custom_classifier)\n\n    def _classifier_statistics_table(self, custom_classifier):\n        table, _ = custom_classifier.statistics()\n\n        trans_table = {'filter_name': [], 'radius': []}\n\n        for value in table:\n            filter_name, radius = (\n                value.split('=') if '=' in value else (value, 0)\n            )\n            trans_table['filter_name'].append(filter_name)\n            trans_table['radius'].append(int(radius))\n\n        for i in range(len(next(iter(table.values())))):\n            trans_table[str(i)] = [round(table[key][i], 2) for key in table]\n\n        table_df = pd.DataFrame.from_dict(trans_table)\n        if self._viewer is not None:\n            self._viewer.window.add_dock_widget(\n                Table(value=table_df),\n                name=os.path.basename(self._classifier_file.value),\n            )\n\n    def _get_feature_set(self):\n        if self._predefined_features.value.value == 1:\n            feature_set = ''\n        else:\n            feature_set = self.apoc.PredefinedFeatureSet[\n                self._predefined_features.value.name\n            ].value\n        self._feature_string.value = feature_set\n        self._custom_apoc_container._feature_string.value = (\n            feature_set  # &lt;- potentially deprecated in future\n        )\n        return feature_set\n\n    def _get_training_classifier_instance(self):\n        if self._classifier_type.value == 'PixelClassifier':\n            return self.apoc.PixelClassifier(\n                opencl_filename=self._classifier_file.value,\n                max_depth=self._max_depth.value,\n                num_ensembles=self._num_trees.value,\n            )\n\n        if self._classifier_type.value == 'ObjectSegmenter':\n            return self.apoc.ObjectSegmenter(\n                opencl_filename=self._classifier_file.value,\n                positive_class_identifier=self._positive_class_id.value,\n                max_depth=self._max_depth.value,\n                num_ensembles=self._num_trees.value,\n            )\n        return None\n\n    ##############################\n    # Training and Prediction\n    ##############################\n    def _get_channel_image(self, img, channel_index_list):\n        if 'S' in img.dims.order:\n            channel_img = img.get_image_data('TSZYX', S=channel_index_list)\n        else:\n            channel_img = img.get_image_data('TCZYX', C=channel_index_list)\n        return channel_img\n\n    def batch_train(self):\n        from bioio import BioImage\n\n        image_directory, image_files = helpers.get_directory_and_files(\n            self._image_directory.value\n        )\n        label_directory, _ = helpers.get_directory_and_files(\n            self._label_directory.value\n        )\n        # missing_files = check_for_missing_files(image_files, label_directory)\n\n        log_loc = self._classifier_file.value.with_suffix('.log.txt')\n        logger, handler = helpers.setup_logger(log_loc)\n\n        logger.info(\n            \"\"\"\n        Classifier: %s\n        Channels: %s\n        Num. Files: %d\n        Image Directory: %s\n        Label Directory: %s\n        \"\"\",\n            self._classifier_file.value,\n            self._image_channels.value,\n            len(image_files),\n            image_directory,\n            label_directory,\n        )\n\n        # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n        set_wait_for_kernel_finish(True)\n\n        self._progress_bar.label = f'Training on %s {len(image_files)} Images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(image_files)\n\n        if not self._continue_training:\n            self.apoc.erase_classifier(self._classifier_file.value)\n\n        custom_classifier = self._get_training_classifier_instance()\n        feature_set = self._feature_string.value\n\n        channel_index_list = [\n            self._image_channels.choices.index(channel)\n            for channel in self._image_channels.value\n        ]\n\n        # Iterate over image files, only pulling label files with an identical\n        # name to the image file. Ensuring that files match by some other\n        # method would be much more complicated, so I'm leaving it up to the\n        # user at this point. In addition, the utilities widget saves with\n        # the same name, so this should be a non-issue, if staying within the\n        # same workflow.\n        for idx, image_file in enumerate(image_files):\n            if not (label_directory / image_file.name).exists():\n                logger.error('Label file missing for %s', image_file.name)\n                self._progress_bar.value = idx + 1\n                continue\n\n            logger.info('Training Image %d: %s', idx + 1, image_file.name)\n\n            img = BioImage(image_directory / image_file.name)\n            channel_img = self._get_channel_image(img, channel_index_list)\n\n            lbl = BioImage(label_directory / image_file.name)\n            label = lbl.get_image_data('TCZYX', C=0)\n\n            # &lt;- this is where setting up dask processing would be useful\n\n            try:\n                custom_classifier.train(\n                    features=feature_set,\n                    image=np.squeeze(channel_img),\n                    ground_truth=np.squeeze(label),\n                    continue_training=True,\n                )\n                self._progress_bar.value = idx + 1\n            except Exception:\n                logger.exception('Error training %s', image_file)\n                self._progress_bar.value = idx + 1\n                continue\n\n        self._classifier_statistics_table(custom_classifier)\n        self._progress_bar.label = f'Trained on {len(image_files)} Images'\n        logger.removeHandler(handler)\n\n    def _get_prediction_classifier_instance(self):\n        if self._classifier_type.value in self._classifier_type_mapping:\n            classifier_class = self._classifier_type_mapping[\n                self._classifier_type.value\n            ]\n            return classifier_class(\n                opencl_filename=self._classifier_file.value\n            )\n        return None\n\n    def batch_predict(self):\n        from bioio import BioImage\n        from bioio.writers import OmeTiffWriter\n\n        image_directory, image_files = helpers.get_directory_and_files(\n            dir_path=self._image_directory.value,\n        )\n\n        log_loc = self._output_directory.value / 'log.txt'\n        logger, handler = helpers.setup_logger(log_loc)\n\n        logger.info(\n            \"\"\"\n        Classifier: %s\n        Channels: %s\n        Num. Files: %d\n        Image Directory: %s\n        Output Directory: %s\n        \"\"\",\n            self._classifier_file.value,\n            self._image_channels.value,\n            len(image_files),\n            image_directory,\n            self._output_directory.value,\n        )\n\n        # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n        set_wait_for_kernel_finish(True)\n\n        self._progress_bar.label = f'Predicting {len(image_files)} Images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(image_files)\n\n        custom_classifier = self._get_prediction_classifier_instance()\n\n        channel_index_list = [\n            self._image_channels.choices.index(channel)\n            for channel in self._image_channels.value\n        ]\n\n        for idx, file in enumerate(image_files):\n            logger.info('Predicting Image %d: %s', idx + 1, file.name)\n\n            img = BioImage(file)\n            channel_img = self._get_channel_image(img, channel_index_list)\n            squeezed_dim_order = helpers.get_squeezed_dim_order(img)\n\n            # &lt;- this is where setting up dask processing would be useful\n\n            try:\n                result = custom_classifier.predict(\n                    image=np.squeeze(channel_img)\n                )\n            except Exception:\n                logger.exception('Error predicting %s', file)\n                self._progress_bar.value = idx + 1\n                continue\n\n            save_data = np.asarray(result)\n            if save_data.max() &gt; 65535:\n                save_data = save_data.astype(np.int32)\n            else:\n                save_data = save_data.astype(np.int16)\n\n            OmeTiffWriter.save(\n                data=save_data,\n                uri=self._output_directory.value / (file.stem + '.tiff'),\n                dim_order=squeezed_dim_order,\n                channel_names=['Labels'],\n                physical_pixel_sizes=img.physical_pixel_sizes,\n            )\n            del result\n\n            self._progress_bar.value = idx + 1\n\n        self._progress_bar.label = f'Predicted {len(image_files)} Images'\n        logger.removeHandler(handler)\n\n    def image_train(self):\n        image_names = [image.name for image in self._image_layers.value]\n        label_name = self._label_layer.value.name\n        self._single_result_label.value = (\n            f'Training on {image_names} using {label_name}'\n        )\n\n        image_list = [image.data for image in self._image_layers.value]\n        image_stack = np.stack(image_list, axis=0)\n        label = self._label_layer.value.data\n\n        # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n        set_wait_for_kernel_finish(True)\n\n        if not self._continue_training:\n            self.apoc.erase_classifier(self._classifier_file.value)\n\n        custom_classifier = self._get_training_classifier_instance()\n        feature_set = self._feature_string.value\n\n        custom_classifier.train(\n            features=feature_set,\n            image=np.squeeze(image_stack),\n            ground_truth=np.squeeze(label),\n            continue_training=True,\n        )\n\n        self._single_result_label.value = (\n            f'Trained on {image_names} using {label_name}'\n        )\n\n    def image_predict(self):\n        set_wait_for_kernel_finish(\n            True\n        )  # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n\n        image_names = [image.name for image in self._image_layers.value]\n        self._single_result_label.value = f'Predicting {image_names}'\n        image_list = [image.data for image in self._image_layers.value]\n        image_stack = np.stack(image_list, axis=0)\n        scale = self._image_layers.value[0].scale\n\n        custom_classifier = self._get_prediction_classifier_instance()\n\n        result = custom_classifier.predict(image=np.squeeze(image_stack))\n\n        # sometimes, input layers may have shape with 1s, like (1,1,10,10)\n        # however, we are squeezing the input, so the reuslt will have shape\n        # (10,10), and therefore scale needs to accomodate dropped axes\n        result_dims = result.ndim\n        if len(scale) &gt; result_dims:\n            scale = scale[-result_dims:]\n\n        self._viewer.add_labels(result, scale=scale)\n\n        self._single_result_label.value = f'Predicted {image_names}'\n\n        return result\n\n    def insert_custom_feature_string(self):\n        self._feature_string.value = (\n            self._custom_apoc_container._feature_string.value\n        )\n        return self._feature_string.value\n</code></pre>"},{"location":"api/widgets/apoc_widget/#napari_ndev.widgets._apoc_container.ApocContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/custom_apoc_feature_set/","title":"Custom apoc feature set","text":""},{"location":"api/widgets/custom_apoc_feature_set/#napari_ndev.widgets._apoc_feature_stack","title":"napari_ndev.widgets._apoc_feature_stack","text":""},{"location":"api/widgets/custom_apoc_feature_set/#napari_ndev.widgets._apoc_feature_stack.ApocFeatureStack","title":"ApocFeatureStack","text":"<p>               Bases: <code>Container</code></p> <p>Create and apply image features in the napari viewer.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>_viewer</code>               (<code>Viewer or None</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_original</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox to keep the original image.</p> </li> <li> <code>_gaussian_blur</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Gaussian Blur parameters.</p> </li> <li> <code>_DoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Difference of Gaussian parameters.</p> </li> <li> <code>_LoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Laplacian of Gaussian parameters.</p> </li> <li> <code>_SoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Sobel of Gaussian parameters.</p> </li> <li> <code>_sHoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Small Hessian of Gaussian parameters.</p> </li> <li> <code>_lHoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Large Hessian of Gaussian parameters.</p> </li> <li> <code>_median</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Median filter parameters.</p> </li> <li> <code>_tophat</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Top Hat filter parameters.</p> </li> <li> <code>_generate_string_button</code>               (<code>PushButton</code>)           \u2013            <p>Button to generate the feature string.</p> </li> <li> <code>_feature_string</code>               (<code>TextEdit</code>)           \u2013            <p>TextEdit to display the custom feature string.</p> </li> <li> <code>_image_layer</code>               (<code>ComboBox</code>)           \u2013            <p>ComboBox to select the image layer.</p> </li> <li> <code>_apply_button</code>               (<code>PushButton</code>)           \u2013            <p>Button to apply the feature stack to the selected image.</p> </li> <li> <code>_progress_bar</code>               (<code>ProgressBar</code>)           \u2013            <p>Progress bar to display the progress of feature application.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_filter_layers</code>             \u2013              <p>Filters the layers in the viewer by the specified layer type.</p> </li> <li> <code>_update_layer_choices</code>             \u2013              <p>Updates the choices in the image layer ComboBox.</p> </li> <li> <code>generate_feature_string</code>             \u2013              <p>Generates a feature string based on the user inputs.</p> </li> <li> <code>layer_to_feature_stack</code>             \u2013              <p>Applies the generated feature stack to the selected image layer.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_apoc_feature_stack.py</code> <pre><code>class ApocFeatureStack(Container):\n    \"\"\"\n    Create and apply image features in the napari viewer.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer, optional\n        The napari viewer instance to which this feature stack is attached. Default is None.\n\n    Attributes\n    ----------\n    _viewer : napari.viewer.Viewer or None\n        The napari viewer instance.\n    _original : CheckBox\n        Checkbox to keep the original image.\n    _gaussian_blur : LineEdit\n        LineEdit for specifying Gaussian Blur parameters.\n    _DoG : LineEdit\n        LineEdit for specifying Difference of Gaussian parameters.\n    _LoG : LineEdit\n        LineEdit for specifying Laplacian of Gaussian parameters.\n    _SoG : LineEdit\n        LineEdit for specifying Sobel of Gaussian parameters.\n    _sHoG : LineEdit\n        LineEdit for specifying Small Hessian of Gaussian parameters.\n    _lHoG : LineEdit\n        LineEdit for specifying Large Hessian of Gaussian parameters.\n    _median : LineEdit\n        LineEdit for specifying Median filter parameters.\n    _tophat : LineEdit\n        LineEdit for specifying Top Hat filter parameters.\n    _generate_string_button : PushButton\n        Button to generate the feature string.\n    _feature_string : TextEdit\n        TextEdit to display the custom feature string.\n    _image_layer : ComboBox\n        ComboBox to select the image layer.\n    _apply_button : PushButton\n        Button to apply the feature stack to the selected image.\n    _progress_bar : ProgressBar\n        Progress bar to display the progress of feature application.\n\n    Methods\n    -------\n    _filter_layers(layer_type)\n        Filters the layers in the viewer by the specified layer type.\n    _update_layer_choices()\n        Updates the choices in the image layer ComboBox.\n    generate_feature_string()\n        Generates a feature string based on the user inputs.\n    layer_to_feature_stack()\n        Applies the generated feature stack to the selected image layer.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        viewer: 'napari.viewer.Viewer' = None,\n    ):\n        super().__init__()\n        self._viewer = viewer if viewer is not None else None\n\n        self._original = CheckBox(label='Keep Original Image')\n        self._gaussian_blur = LineEdit(label='Gaussian Blur')\n        self._DoG = LineEdit(label='Difference of Gauss.')\n        self._LoG = LineEdit(label='Laplacian of Gauss.')\n        self._SoG = LineEdit(label='Sobel of Gauss.')\n        self._sHoG = LineEdit(label='Small Hessian of Gauss.')\n        self._lHoG = LineEdit(label='Large Hessian of Gauss.')\n        self._median = LineEdit(label='Median')\n        self._tophat = LineEdit(label='Top Hat')\n\n        self._generate_string_button = PushButton(\n            label='Generate Feature String'\n        )\n        self._feature_string = TextEdit(label='Custom Feature String')\n\n        self._image_layer = ComboBox(\n            choices=self._filter_layers(layers.Image), label='Image Layer'\n        )\n        self._apply_button = PushButton(label='Apply to selected image')\n        self._progress_bar = ProgressBar(label='Progress: ')\n\n        self.extend(\n            [\n                self._original,\n                self._gaussian_blur,\n                self._DoG,\n                self._LoG,\n                self._SoG,\n                self._sHoG,\n                self._lHoG,\n                self._median,\n                self._tophat,\n                self._generate_string_button,\n                self._feature_string,\n                self._image_layer,\n                self._apply_button,\n                self._progress_bar,\n            ]\n        )\n\n        self._generate_string_button.clicked.connect(\n            self.generate_feature_string\n        )\n        self._apply_button.clicked.connect(self.layer_to_feature_stack)\n\n        if self._viewer is not None:\n            self._viewer.layers.events.removed.connect(\n                self._update_layer_choices\n            )\n            self._viewer.layers.events.inserted.connect(\n                self._update_layer_choices\n            )\n\n    def _filter_layers(self, layer_type):\n        if self._viewer is None:\n            return []\n        return [x for x in self._viewer.layers if isinstance(x, layer_type)]\n\n    def _update_layer_choices(self):\n        self._image_layer.choices = self._filter_layers(layers.Image)\n\n    def generate_feature_string(self):\n        def process_feature(prefix, input_str):\n            return [\n                prefix + num.strip()\n                for num in input_str.split(',')\n                if num.strip()\n            ]\n\n        feature_list = []\n        if self._original.value:\n            feature_list.append('original')\n        feature_list.extend(\n            process_feature('gaussian_blur=', self._gaussian_blur.value)\n        )\n        feature_list.extend(\n            process_feature('difference_of_gaussian=', self._DoG.value)\n        )\n        feature_list.extend(\n            process_feature('laplace_box_of_gaussian_blur=', self._LoG.value)\n        )\n        feature_list.extend(\n            process_feature('sobel_of_gaussian_blur=', self._SoG.value)\n        )\n        feature_list.extend(\n            process_feature(\n                'small_hessian_eigenvalue_of_gaussian_blur=', self._sHoG.value\n            )\n        )\n        feature_list.extend(\n            process_feature(\n                'large_hessian_eigenvalue_of_gaussian_blur=',\n                self._lHoG.value,\n            )\n        )\n        feature_list.extend(\n            process_feature('median_sphere=', self._median.value)\n        )\n        feature_list.extend(\n            process_feature('top_hat_sphere=', self._tophat.value)\n        )\n\n        self._feature_string.value = ' '.join(feature_list)\n\n    def layer_to_feature_stack(self):\n        from apoc import generate_feature_stack\n\n        image = self._image_layer.value.data\n        feature_stack = generate_feature_stack(\n            image, self._feature_string.value\n        )\n\n        feature_strings = self._feature_string.value.split()\n\n        self._progress_bar.max = len(feature_stack)\n        self._progress_bar.value = 0\n\n        for idx, (feature, string) in enumerate(\n            zip(reversed(feature_stack), reversed(feature_strings))\n        ):\n            self._viewer.add_image(data=feature, name=string)\n            self._progress_bar.value = idx + 1\n</code></pre>"},{"location":"api/widgets/custom_apoc_feature_set/#napari_ndev.widgets._apoc_feature_stack.ApocFeatureStack(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance to which this feature stack is attached. Default is None.</p>"},{"location":"api/widgets/image_utilities/","title":"Image utilities","text":""},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container","title":"napari_ndev.widgets._utilities_container","text":""},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer","title":"UtilitiesContainer","text":"<p>               Bases: <code>ScrollableContainer</code></p> <p>A widget to work with images and labels in the napari viewer.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>_viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_image_save_dims</code>               (<code>str or None</code>)           \u2013            <p>The dimension order for saving images.</p> </li> <li> <code>_label_save_dims</code>               (<code>str or None</code>)           \u2013            <p>The dimension order for saving labels.</p> </li> <li> <code>_p_sizes</code>               (<code>PhysicalPixelSizes</code>)           \u2013            <p>The physical pixel sizes for the image.</p> </li> <li> <code>_files</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting file(s).</p> </li> <li> <code>_open_image_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for opening images.</p> </li> <li> <code>_save_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the save directory.</p> </li> <li> <code>_save_name</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering the file save name.</p> </li> <li> <code>_metadata_from_selected_layer</code>               (<code>PushButton</code>)           \u2013            <p>Button for updating metadata from the selected layer.</p> </li> <li> <code>_dim_order</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering the dimension order.</p> </li> <li> <code>_channel_names</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering the channel names.</p> </li> <li> <code>_physical_pixel_sizes_z</code>               (<code>FloatSpinBox</code>)           \u2013            <p>Widget for entering the Z pixel size in micrometers.</p> </li> <li> <code>_physical_pixel_sizes_y</code>               (<code>FloatSpinBox</code>)           \u2013            <p>Widget for entering the Y pixel size in micrometers.</p> </li> <li> <code>_physical_pixel_sizes_x</code>               (<code>FloatSpinBox</code>)           \u2013            <p>Widget for entering the X pixel size in micrometers.</p> </li> <li> <code>_image_layer</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting the image layer.</p> </li> <li> <code>_concatenate_image_files</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox for concatenating image files.</p> </li> <li> <code>_concatenate_image_layers</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox for concatenating image layers.</p> </li> <li> <code>_save_image_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for saving images.</p> </li> <li> <code>_labels_layer</code>               (<code>Widget</code>)           \u2013            <p>Widget for working with labels layer.</p> </li> <li> <code>_save_labels_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for saving labels.</p> </li> <li> <code>_shapes_layer</code>               (<code>Widget</code>)           \u2013            <p>Widget for working with shapes layer.</p> </li> <li> <code>_save_shapes_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for saving shapes as labels.</p> </li> <li> <code>_results</code>               (<code>TextEdit</code>)           \u2013            <p>Widget for displaying information.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_update_metadata</code>             \u2013              <p>Update the metadata based on the given image.</p> </li> <li> <code>update_metadata_from_file</code>             \u2013              <p>Update the metadata from the selected file.</p> </li> <li> <code>update_metadata_from_layer</code>             \u2013              <p>Update the metadata from the selected layer.</p> </li> <li> <code>open_images</code>             \u2013              <p>Open the selected images in the napari viewer.</p> </li> <li> <code>concatenate_images</code>             \u2013              <p>Concatenate the image data based on the selected options.</p> </li> <li> <code>p_sizes</code>             \u2013              <p>Get the physical pixel sizes.</p> </li> <li> <code>_get_save_loc</code>             \u2013              <p>Get the save location based on the parent directory.</p> </li> <li> <code>_common_save_logic</code>             \u2013              <p>Common logic for saving data as OME-TIFF.</p> </li> <li> <code>save_ome_tiff</code>             \u2013              <p>Save the concatenated image data as OME-TIFF.</p> </li> <li> <code>save_labels</code>             \u2013              <p>Save the labels data.</p> </li> <li> <code>save_shapes_as_labels</code>             \u2013              <p>Save the shapes data as labels.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>class UtilitiesContainer(ScrollableContainer):\n    \"\"\"\n    A widget to work with images and labels in the napari viewer.\n\n    Parameters\n    ----------\n    viewer: napari.viewer.Viewer, optional\n        The napari viewer instance.\n\n    Attributes\n    ----------\n    _viewer: napari.viewer.Viewer\n        The napari viewer instance.\n    _image_save_dims: str or None\n        The dimension order for saving images.\n    _label_save_dims: str or None\n        The dimension order for saving labels.\n    _p_sizes: PhysicalPixelSizes\n        The physical pixel sizes for the image.\n    _files: FileEdit\n        Widget for selecting file(s).\n    _open_image_button: PushButton\n        Button for opening images.\n    _save_directory: FileEdit\n        Widget for selecting the save directory.\n    _save_name: LineEdit\n        Widget for entering the file save name.\n    _metadata_from_selected_layer: PushButton\n        Button for updating metadata from the selected layer.\n    _dim_order: LineEdit\n        Widget for entering the dimension order.\n    _channel_names: LineEdit\n        Widget for entering the channel names.\n    _physical_pixel_sizes_z: FloatSpinBox\n        Widget for entering the Z pixel size in micrometers.\n    _physical_pixel_sizes_y: FloatSpinBox\n        Widget for entering the Y pixel size in micrometers.\n    _physical_pixel_sizes_x: FloatSpinBox\n        Widget for entering the X pixel size in micrometers.\n    _image_layer: Select\n        Widget for selecting the image layer.\n    _concatenate_image_files: CheckBox\n        Checkbox for concatenating image files.\n    _concatenate_image_layers: CheckBox\n        Checkbox for concatenating image layers.\n    _save_image_button: PushButton\n        Button for saving images.\n    _labels_layer: Widget\n        Widget for working with labels layer.\n    _save_labels_button: PushButton\n        Button for saving labels.\n    _shapes_layer: Widget\n        Widget for working with shapes layer.\n    _save_shapes_button: PushButton\n        Button for saving shapes as labels.\n    _results: TextEdit\n        Widget for displaying information.\n\n    Methods\n    -------\n    _update_metadata(img)\n        Update the metadata based on the given image.\n    update_metadata_from_file()\n        Update the metadata from the selected file.\n    update_metadata_from_layer()\n        Update the metadata from the selected layer.\n    open_images()\n        Open the selected images in the napari viewer.\n    concatenate_images(concatenate_files, files, concatenate_layers, layers)\n        Concatenate the image data based on the selected options.\n    p_sizes()\n        Get the physical pixel sizes.\n    _get_save_loc(parent)\n        Get the save location based on the parent directory.\n    _common_save_logic(data, uri, dim_order, channel_names, layer)\n        Common logic for saving data as OME-TIFF.\n    save_ome_tiff()\n        Save the concatenated image data as OME-TIFF.\n    save_labels()\n        Save the labels data.\n    save_shapes_as_labels()\n        Save the shapes data as labels.\n\n    \"\"\"\n\n    def __init__(self, viewer: napari.viewer.Viewer = None):\n        \"\"\"\n        Initialize the UtilitiesContainer widget.\n\n        Parameters\n        ----------\n        viewer : napari.viewer.Viewer, optional\n            The napari viewer instance.\n\n        \"\"\"\n        super().__init__(labels=False)\n\n        self.min_width = 500 # TODO: remove this hardcoded value\n        self._viewer = viewer if viewer is not None else None\n        self._squeezed_dims = None\n\n        self._init_widgets()\n        self._init_save_name_container()\n        self._init_file_options_container()\n        self._init_open_image_container()\n        self._init_metadata_container()\n        self._init_concatenate_files_container()\n        self._init_save_layers_container()\n        self._init_scene_container()\n        # self._init_figure_options_container() # TODO: add figure saving\n        self._init_layout()\n        self._connect_events()\n\n    def _init_layout(self):\n        \"\"\"Initialize the layout of the widget.\"\"\"\n        self.extend(\n            [\n                self._save_directory,\n                self._save_name_container,\n                self._files,\n                self._open_image_container,\n                self._file_options_container,\n                self._metadata_container,\n                self._concatenate_files_container,\n                self._scene_container,\n                # self._figure_options_container,\n                self._save_layers_container,\n                self._results,\n            ]\n        )\n\n    def _init_widgets(self):\n        \"\"\"Initialize widgets.\"\"\"\n        self._save_directory = FileEdit(\n            mode='d',\n            tooltip='Directory where images will be saved.',\n        )\n        self._files = FileEdit(\n            mode='rm',\n            tooltip='Select file(s) to load.',\n        )\n\n        self._results = TextEdit(label='Info')\n\n    def _init_save_name_container(self):\n        \"\"\"Initialize the save name container.\"\"\"\n        self._save_name_container = Container(layout='horizontal')\n        self._save_name = LineEdit(\n            label='Save Name',\n            tooltip='Name of the saved file. '\n            'Proper extension will be added when saved.',\n        )\n        self._append_scene_button = PushButton(\n            label='Append Scene to Name',\n        )\n        self._save_name_container.extend([\n            self._save_name,\n            self._append_scene_button\n        ])\n\n\n    def _init_file_options_container(self):\n        \"\"\"Initialize the file options collapsible container.\"\"\"\n        self._file_options_container = CollapsibleContainer(\n            layout='vertical',\n            text='File Options',\n            collapsed=True,\n        )\n        self._update_scale = CheckBox(\n            value=True,\n            label='Update Scale on File Select',\n            tooltip='Update the scale when files are selected.',\n        )\n        self._update_channel_names = CheckBox(\n            value=True,\n            label='Update Channel Names on File Select',\n            tooltip='Update the channel names when files are selected.',\n        )\n        self._save_directory_prefix = LineEdit(\n            label='Save Directory Prefix',\n            tooltip='Prefix for the save directories.',\n        )\n\n        self._file_options_container.extend([\n            self._update_scale,\n            self._update_channel_names,\n            self._save_directory_prefix,\n        ])\n\n    def _init_open_image_container(self):\n        \"\"\"Initialize the open image container.\"\"\"\n        self._open_image_container = Container(layout='horizontal')\n        self._open_image_button = PushButton(label='Open File(s)')\n        self._select_next_image_button = PushButton(\n            label='Select Next',\n            tooltip='Select the next file(s) in the directory. \\n'\n            'Note that the files are sorted alphabetically and numerically.'\n        )\n        self._open_image_container.append(self._open_image_button)\n        self._open_image_container.append(self._select_next_image_button)\n\n    def _init_concatenate_files_container(self):\n        self._concatenate_files_container = Container(\n            layout='horizontal',\n        )\n        self._concatenate_files_button = PushButton(label='Concat. Files')\n        self._concatenate_batch_button = PushButton(\n            label='Batch Concat.',\n            tooltip='Concatenate files in the selected directory by iterating'\n            ' over the remaing files in the directory based on the number of'\n            ' files selected. The files are sorted '\n            'alphabetically and numerically, which may not be consistent '\n            'with your file viewer. But, opening related consecutive files '\n            'should work as expected.',\n        )\n        self._concatenate_files_container.extend([\n            self._concatenate_files_button,\n            self._concatenate_batch_button,\n        ])\n\n\n    def _init_metadata_container(self):\n        self._metadata_container = CollapsibleContainer(\n            layout='vertical',  # label='Update Metadata from',\n            text='Metadata',\n            collapsed=True,\n        )\n        self._layer_metadata_update = PushButton(\n            label='Update Metadata from Selected Layer'\n        )\n\n        self._dim_order = Label(\n            label='Dimension Order: ',\n            tooltip='Sanity check for available dimensions.',\n        )\n        self._num_scenes = Label(\n            label='Number of Scenes: ',\n        )\n\n        self._channel_names = LineEdit(\n            label='Channel Name(s)',\n            tooltip='Enter channel names as a list. If left blank or the '\n            'channel names are not the proper length, then default channel '\n            'names will be used.',\n        )\n\n        self._scale_tuple = TupleEdit(\n            label='Scale, ZYX',\n            tooltip='Pixel size, usually in \u03bcm',\n            value=(0.0000, 1.0000, 1.0000),\n            options={'step': 0.0001},\n        )\n        self._scale_layers_button = PushButton(\n            label='Scale Layer(s)',\n            tooltip='Scale the selected layer(s) based on the given scale.',\n        )\n\n\n        self._metadata_container.extend([\n            # self._file_metadata_update,\n            self._layer_metadata_update,\n            self._dim_order,\n            self._num_scenes,\n            self._channel_names,\n            self._scale_tuple,\n            self._scale_layers_button,\n        ])\n\n    def _init_scene_container(self):\n        \"\"\"Initialize the scene container, allowing scene saving.\"\"\"\n        self._scene_container = Container(\n            layout='horizontal',\n            tooltip='Must be in list index format. Ex: [0, 1, 2] or [5:10]',\n        )\n        self._scenes_to_extract = LineEdit(\n            # label=\"Scenes to Extract\",\n            tooltip='Enter the scenes to extract as a list. If left blank '\n            'then all scenes will be extracted.',\n        )\n        self._extract_scenes = PushButton(\n            label='Extract and Save Scenes',\n            tooltip='Extract scenes from a single selected file.',\n        )\n        self._scene_container.append(self._scenes_to_extract)\n        self._scene_container.append(self._extract_scenes)\n\n    def _init_save_layers_container(self):\n        \"\"\"Initialize the container to save images, labels, and shapes.\"\"\"\n        self._save_layers_container = Container(\n            layout='horizontal',\n            label='Save Selected Layers',\n        )\n        self._save_layers_button = PushButton(\n            label='Save Selected Layers',\n            tooltip='Concatenate and save all selected layers as OME-TIFF.'\n            'Layers will save to corresponding directories based on the layer'\n            'type, e.g. Images, Labels, ShapesAsLabels. Shapes are saved as'\n            'labels based on the selected image layer dimensions. If multiple'\n            'layer types are selected, then the image will save to Layers.',\n        )\n        # self._export_figure_button = PushButton(\n        #     label='Export Figure',\n        #     tooltip='Export the current canvas figure to the save directory. '\n        #     'Saves image as a PNG to Figures directory.',\n        # )\n        self._save_layers_container.extend([\n            self._save_layers_button,\n            # self._export_figure_button,\n        ])\n\n    def _init_figure_options_container(self):\n        \"\"\"Initialize the container for figure options.\"\"\"\n        self._figure_options_container = CollapsibleContainer(\n            layout='vertical',\n            text='Figure Options',\n            collapsed=True,\n        )\n        self._figure_scale_factor = SpinBox(\n            label='Scale Factor',\n            min=0,\n            step=1,\n            value=1,\n        )\n        self._use_current_canvas_size = CheckBox(\n            label='Use current canvas dimensions',\n            value=True\n        )\n        self._current_canvas_dims = Label(label='Canvas Dimensions: ')\n        self._canvas_size = TupleEdit(\n            label='Canvas Size',\n            value=(0, 0),\n        )\n        # use this to automatically change the camera parameters\n        self._camera_zoom = SpinBox(\n            label='Camera Zoom',\n            min=0,\n            step=0.1,\n            value=self._viewer.camera.zoom,\n        )\n        self._camera_angle = TupleEdit(\n            label='Camera Angle',\n            value=(0, 0, 90),\n            options={'step': 1},\n        )\n        self._figure_options_container.extend([\n            self._figure_scale_factor,\n            self._use_current_canvas_size,\n            self._current_canvas_dims,\n            self._canvas_size,\n            self._camera_zoom,\n            self._camera_angle,\n        ])\n\n    def _connect_events(self):\n        \"\"\"Connect the events of the widgets to respective methods.\"\"\"\n        self._files.changed.connect(self.update_metadata_on_file_select)\n        self._append_scene_button.clicked.connect(self.append_scene_to_name)\n        self._open_image_button.clicked.connect(self.open_images)\n        self._select_next_image_button.clicked.connect(self.select_next_images)\n\n        self._layer_metadata_update.clicked.connect(\n            self.update_metadata_from_layer\n        )\n        self._scale_layers_button.clicked.connect(self.rescale_by)\n\n        self._concatenate_files_button.clicked.connect(self.save_files_as_ome_tiff)\n        self._concatenate_batch_button.clicked.connect(self.batch_concatenate_files)\n        self._extract_scenes.clicked.connect(self.save_scenes_ome_tiff)\n        self._save_layers_button.clicked.connect(self.save_layers_as_ome_tiff)\n        # self._export_figure_button.clicked.connect(self.export_figure)\n        self._results._on_value_change()\n\n    @property\n    def p_sizes(self):\n        \"\"\"\n        Get the physical pixel sizes.\n\n        Returns\n        -------\n        PhysicalPixelSizes\n            The physical pixel sizes.\n\n        \"\"\"\n        from bioio_base.types import PhysicalPixelSizes\n\n        return PhysicalPixelSizes(\n            self._scale_tuple.value[0],\n            self._scale_tuple.value[1],\n            self._scale_tuple.value[2],\n        )\n\n    # Converted\n    def _update_metadata_from_Image(\n        self,\n        img: BioImage,\n        update_channel_names: bool = True,\n        update_scale: bool = True,\n    ):\n        \"\"\"\n        Update the metadata based on the given image.\n\n        Parameters\n        ----------\n        img : BioImage\n            The image from which to update the metadata.\n        update_channel_names : bool, optional\n            Update the channel names, by default True.\n        update_scale : bool, optional\n            Update the scale, by default True.\n\n        \"\"\"\n        self._dim_order.value = img.dims.order\n        self._num_scenes.value = str(len(img.scenes))\n\n        self._squeezed_dims = helpers.get_squeezed_dim_order(img)\n\n        if update_channel_names:\n            self._channel_names.value = helpers.get_channel_names(img)\n        if update_scale:\n            self._scale_tuple.value = (\n                img.physical_pixel_sizes.Z or 1,\n                img.physical_pixel_sizes.Y or 1,\n                img.physical_pixel_sizes.X or 1,\n            )\n\n    # Converted\n    def update_metadata_on_file_select(self):\n        \"\"\"Update self._save_name.value and metadata if selected.\"\"\"\n        # TODO: get true stem of file, in case .ome.tiff\n        self._save_name.value = str(self._files.value[0].stem)\n        img = nImage(self._files.value[0])\n\n        self._update_metadata_from_Image(\n            img,\n            update_channel_names=self._update_channel_names.value,\n            update_scale=self._update_scale.value,\n        )\n\n    # Added\n    def append_scene_to_name(self):\n        \"\"\"Append the scene to the save name.\"\"\"\n        if self._viewer.layers.selection.active is not None:\n            try:\n                img = self._viewer.layers.selection.active.metadata['bioimage']\n                # remove bad characters from scene name\n                scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n                self._save_name.value = f'{self._save_name.value}_{scene}'\n            except AttributeError:\n                self._results.value = (\n                    'Tried to append scene to name, but layer not opened with'\n                    ' neuralDev reader.'\n                )\n        else:\n            self._results.value = (\n                'Tried to append scene to name, but no layer selected.'\n                ' So the first scene from the first file will be appended.'\n            )\n            img = nImage(self._files.value[0])\n            scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n            self._save_name.value = f'{self._save_name.value}_{scene}'\n\n    # Converted\n    def update_metadata_from_layer(self):\n        \"\"\"\n        Update metadata from the selected layer.\n\n        Expects images to be opened with napari-ndev reader.\n\n        Note:\n        ----\n        This should also support napari-bioio in the future, when released.\n\n        \"\"\"\n        selected_layer = self._viewer.layers.selection.active\n        try:\n            img = selected_layer.metadata['bioimage']\n            self._update_metadata_from_Image(img)\n\n        except AttributeError:\n            self._results.value = (\n                'Tried to update metadata, but no layer selected.'\n                f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n            )\n        except KeyError:\n            scale = selected_layer.scale\n            self._scale_tuple.value = (\n                scale[-3] if len(scale) &gt;= 3 else 1,\n                scale[-2],\n                scale[-1],\n            )\n            self._results.value = (\n                'Tried to update metadata, but could only update scale'\n                ' because layer not opened with neuralDev reader.'\n                f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n            )\n\n    # Converted\n    def open_images(self):\n        \"\"\"Open the selected images in the napari viewer with napari-ndev.\"\"\"\n        self._viewer.open(self._files.value, plugin='napari-ndev')\n\n    @staticmethod\n    def _natural_sort_key(s):\n        return [\n            int(text) if text.isdigit() else text.lower()\n            for text in re.split(r'(\\d+)', s)\n        ]\n\n    # Converted\n    def select_next_images(self):\n        from natsort import os_sorted\n        \"\"\"Open the next set of images in the directyory.\"\"\"\n        num_files = self._files.value.__len__()\n\n        # get the parent directory of the first file\n        first_file = self._files.value[0]\n        parent_dir = first_file.parent\n\n        # get the list of files in the parent directory\n        files = list(parent_dir.glob(f'*{first_file.suffix}'))\n        # sort the files naturally (case-insensitive and numbers in order)\n        # like would be scene in windows file explorer default sorting\n        # https://pypi.org/project/natsort/#sort-paths-like-my-file-browser-e-g-windows-explorer-on-windows\n\n        files = os_sorted(files)\n\n        # get the index of the first file in the list and then the next files\n        idx = files.index(first_file)\n        next_files = files[idx + num_files : idx + num_files + num_files]\n\n        # if there are no more files, then return\n        if not next_files:\n            self._results.value = (\n                'No more file sets to select.'\n            )\n            return\n        # set the nwe save names, and update the file value\n        img = nImage(next_files[0])\n\n        self._save_name.value = helpers.create_id_string(img, next_files[0].stem)\n        self._files.value = next_files\n\n        self.update_metadata_on_file_select()\n\n    # Converted\n    def rescale_by(self):\n        \"\"\"Rescale the selected layers based on the given scale.\"\"\"\n        layers = self._viewer.layers.selection\n        scale_tup = self._scale_tuple.value\n\n        for layer in layers:\n            scale_len = len(layer.scale)\n            # get the scale_tup from the back of the tuple first, in case dims\n            # are missing in the new layer\n            layer.scale = scale_tup[-scale_len:]\n\n    def concatenate_files(\n        self,\n        files: str | Path | list[str | Path],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Concatenate the image data from the selected files.\n\n        Removes \"empty\" channels, which are channels with no values above 0.\n        This is present in some microscope formats where it will image in RGB,\n        and then leave empty channels not represented by the color channels.\n\n        Does not currently handle scenes.\n\n        Parameters\n        ----------\n        files : str or Path or list of str or Path\n            The file(s) to concatenate.\n\n        Returns\n        -------\n        numpy.ndarray\n            The concatenated image data.\n\n        \"\"\"\n        array_list = []\n\n        for file in files:\n            img = nImage(file)\n\n            if 'S' in img.dims.order:\n                img_data = img.get_image_data('TSZYX')\n            else:\n                img_data = img.data\n\n            # iterate over all channels and only keep if not blank\n            for idx in range(img_data.shape[1]):\n                array = img_data[:, [idx], :, :, :]\n                if array.max() &gt; 0:\n                    array_list.append(array)\n        return np.concatenate(array_list, axis=1)\n\n    def concatenate_layers(\n        self,\n        layers: Layer | list[Layer],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Concatenate the image data from the selected layers.\n\n        Adapts all layers to 5D arrays for compatibility with image dims.\n        If the layer is a shapes layer, it will look for a corresponding image\n        layer to get the dimensions for the shapes layer.\n\n        Parameters\n        ----------\n        layers : napari.layers.Image or list of napari.layers.Image\n            The selected image layers.\n\n        Returns\n        -------\n        numpy.ndarray\n            The concatenated image data.\n\n        \"\"\"\n        if any(isinstance(layer, ShapesLayer) for layer in layers):\n            label_dim = self._get_dims_for_shape_layer(layers)\n\n        array_list = []\n\n        for layer in layers:\n            if isinstance(layer, ShapesLayer):\n                layer_data = layer.to_labels(labels_shape=label_dim)\n                layer_data = layer_data.astype(np.int16)\n            else:\n                layer_data = layer.data\n\n            # convert to 5D array for compatability with image dims\n            while len(layer_data.shape) &lt; 5:\n                layer_data = np.expand_dims(layer_data, axis=0)\n            array_list.append(layer_data)\n\n        return np.concatenate(array_list, axis=1)\n\n    def _get_dims_for_shape_layer(self, layers) -&gt; tuple[int]:\n        # TODO: Fix this not getting the first instance of the image layer\n        # get first instance of a napari.layers.Image or napari.layers.Labels\n        dim_layer = next(\n                (layer for layer in layers if isinstance(layer, (ImageLayer, LabelsLayer))),\n                None,\n            )\n        # if none of these layers is selected, get it from the first instance in the viewer\n        if dim_layer is None:\n            dim_layer = next(\n                    (layer for layer in self._viewer.layers if isinstance(layer, (ImageLayer, LabelsLayer))),\n                    None,\n                )\n        if dim_layer is None:\n            raise ValueError('No image or labels present to convert shapes layer.')\n        label_dim = dim_layer.data.shape\n            # drop last axis if represents RGB image\n        label_dim = label_dim[:-1] if label_dim[-1] == 3 else label_dim\n        return label_dim\n\n    def _get_save_loc(\n        self, root_dir: Path, parent: str, file_name: str\n    ) -&gt; Path:\n        \"\"\"\n        Get the save location based on the parent directory.\n\n        Parameters\n        ----------\n        root_dir : Path\n            The root directory.\n        parent : str\n            The parent directory. eg. 'Image', 'Labels', 'ShapesAsLabels'\n        file_name : str\n            The file name.\n\n        Returns\n        -------\n        Path\n            The save location. root_dir / parent / file_name\n\n        \"\"\"\n        save_directory = root_dir / parent\n        save_directory.mkdir(parents=False, exist_ok=True)\n        return save_directory / file_name\n\n    def _common_save_logic(\n        self,\n        data: np.ndarray,\n        uri: Path,\n        dim_order: str,\n        channel_names: list[str],\n        image_name: str | list[str | None] | None,\n        result_str: str,\n    ) -&gt; None:\n        \"\"\"\n        Save data as OME-TIFF with bioio based on common logic.\n\n        Converts labels to np.int32 if np.int64 is detected, due to bioio\n        not supporting np.int64 labels, even though napari and other libraries\n        generate np.int64 labels.\n\n        Parameters\n        ----------\n        data : np.ndarray\n            The data to save.\n        uri : Path\n            The URI to save the data to.\n        dim_order : str\n            The dimension order.\n        channel_names : list[str]\n            The channel names saved to OME metadata\n        image_name : str | list[str | None] | None\n            The image name saved to OME metadata\n        result_str : str\n            The string used for the result widget.\n\n        \"\"\"\n        # TODO: add image_name to save method\n        from bioio.writers import OmeTiffWriter\n\n        # BioImage does not allow saving labels as np.int64\n        # napari generates labels differently depending on the OS\n        # so we need to convert to np.int32 in case np.int64 generated\n        # see: https://github.com/napari/napari/issues/5545\n        # This is a failsafe\n        if data.dtype == np.int64:\n            data = data.astype(np.int32)\n\n        try:\n            OmeTiffWriter.save(\n                data=data,\n                uri=uri,\n                dim_order=dim_order or None,\n                channel_names=channel_names or None,\n                image_name=image_name or None,\n                physical_pixel_sizes=self.p_sizes,\n            )\n            self._results.value = f'Saved {result_str}: ' + str(\n                self._save_name.value\n            ) + f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        # if ValueError is raised, save with default channel names\n        except ValueError as e:\n            OmeTiffWriter.save(\n                data=data,\n                uri=uri,\n                dim_order=dim_order,\n                image_name=image_name or None,\n                physical_pixel_sizes=self.p_sizes,\n            )\n            self._results.value = (\n                'ValueError: '\n                + str(e)\n                + '\\nSo, saved with default channel names: \\n'\n                + str(self._save_name.value)\n                + f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n            )\n        return\n\n    def _determine_save_directory(self, save_dir: str | None = None) -&gt; str:\n        if self._save_directory_prefix.value != '':\n            save_dir = f'{self._save_directory_prefix.value}_{save_dir}'\n        else:\n            save_dir = f'{save_dir}'\n        return save_dir\n\n    def save_files_as_ome_tiff(self) -&gt; np.ndarray:\n        \"\"\"Save the selected files as OME-TIFF using BioImage.\"\"\"\n        img_data = self.concatenate_files(self._files.value)\n        save_dir = self._determine_save_directory('ConcatenatedImages')\n        img_save_name = f'{self._save_name.value}.tiff'\n        img_save_loc = self._get_save_loc(\n            self._save_directory.value,\n            save_dir,\n            img_save_name,\n        )\n\n        cnames = self._channel_names.value\n        channel_names = ast.literal_eval(cnames) if cnames else None\n\n        self._common_save_logic(\n            data=img_data,\n            uri=img_save_loc,\n            dim_order='TCZYX',\n            channel_names=channel_names,\n            image_name=self._save_name.value,\n            result_str='Concatenated Image',\n        )\n\n        return img_data\n\n    def batch_concatenate_files(self) -&gt; None:\n        \"\"\"\n        Concatenate files in the selected directory.\n\n        Save the concatenated files as OME-TIFF, then select the next set of\n        files in the directory to be concatenated. This is done by iterating\n        over the remaining files in the directory based on the number of files\n        selected. The files are sorted alphabetically and numerically. The\n        files will be concatenated until no more files are left in the parent\n        directory.\n        \"\"\"\n        # get total number of sets of files in the directory\n        parent_dir = self._files.value[0].parent\n        total_num_files = len(list(parent_dir.glob(f'*{self._files.value[0].suffix}')))\n        num_files = self._files.value.__len__()\n        num_file_sets = total_num_files // num_files\n\n        # save first set of files\n        self.save_files_as_ome_tiff()\n        # iterate through the remaining sets of files in the directory\n        for _ in range(num_file_sets):\n            self.select_next_images()\n            self.save_files_as_ome_tiff()\n\n        self._results.value = (\n            'Batch concatenated files in directory.'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n\n    def save_scenes_ome_tiff(self) -&gt; None:\n        \"\"\"\n        Save selected scenes as OME-TIFF.\n\n        This method is intended to save scenes from a single file. The scenes\n        are extracted based on the scenes_to_extract widget value, which is a\n        list of scene indices. If the widget is left blank, then all scenes\n        will be extracted.\n\n        \"\"\"\n        img = nImage(self._files.value[0])\n\n        scenes = self._scenes_to_extract.value\n        scenes_list = ast.literal_eval(scenes) if scenes else img.scenes\n        save_dir = self._determine_save_directory('ExtractedScenes')\n        save_directory = self._save_directory.value / save_dir\n        save_directory.mkdir(parents=False, exist_ok=True)\n\n        for scene in scenes_list:\n            # TODO: fix this to not have an issue if there are identical scenes\n            # presented as strings, though the asssumption is most times the\n            # user will input a list of integers.\n            img.set_scene(scene)\n\n            base_save_name = self._save_name.value.split('.')[0]\n            image_id = helpers.create_id_string(img, base_save_name)\n\n            img_save_name = f'{image_id}.tiff'\n            img_save_loc = save_directory / img_save_name\n\n            # get channel names from widget if truthy\n            cnames = self._channel_names.value\n            channel_names = ast.literal_eval(cnames) if cnames else None\n\n            self._common_save_logic(\n                data=img.data,\n                uri=img_save_loc,\n                dim_order='TCZYX',\n                channel_names=channel_names,\n                image_name=image_id,\n                result_str=f'Scene: {img.current_scene}',\n            )\n\n        self._results.value = (\n            f'Saved extracted scenes: {scenes_list}'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n        return\n\n    def save_layers_as_ome_tiff(self) -&gt; np.ndarray:\n        \"\"\"\n        Save the selected layers as OME-TIFF.\n\n        Determines types of layers and saves to corresponding directories.\n        \"\"\"\n        layer_data = self.concatenate_layers(\n            list(self._viewer.layers.selection)\n        )\n        # get the types of layers, to know where to save the image\n        layer_types = [\n            type(layer).__name__ for layer in self._viewer.layers.selection\n        ]\n\n        # if there are multiple layer types, save to Layers directory\n        layer_save_type = 'Layers' if len(set(layer_types)) &gt; 1 else layer_types[0]\n        layer_save_dir = self._determine_save_directory(layer_save_type)\n        layer_save_name = f'{self._save_name.value}.tiff'\n        layer_save_loc = self._get_save_loc(\n            self._save_directory.value, layer_save_dir, layer_save_name\n        )\n\n        # only get channel names if layer_save_type is not shapes or labels layer\n        if layer_save_type not in ['Shapes', 'Labels']:\n            cnames = self._channel_names.value\n            channel_names = ast.literal_eval(cnames) if cnames else None\n        else:\n            channel_names = [layer_save_type]\n\n        if layer_save_type == 'Shapes':\n            layer_data = layer_data.astype(np.int16)\n\n        elif layer_save_type == 'Labels':\n            if layer_data.max() &gt; 65535:\n                layer_data = layer_data.astype(np.int32)\n            else:\n                layer_data = layer_data.astype(np.int16)\n\n        self._common_save_logic(\n            data=layer_data,\n            uri=layer_save_loc,\n            dim_order='TCZYX',\n            channel_names=channel_names,\n            image_name=self._save_name.value,\n            result_str=layer_save_type,\n        )\n\n        return layer_data\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.p_sizes","title":"p_sizes  <code>property</code>","text":"<pre><code>p_sizes\n</code></pre> <p>Get the physical pixel sizes.</p> <p>Returns:</p> <ul> <li> <code>PhysicalPixelSizes</code>           \u2013            <p>The physical pixel sizes.</p> </li> </ul>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.__init__","title":"__init__","text":"<pre><code>__init__(viewer=None)\n</code></pre> <p>Initialize the UtilitiesContainer widget.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def __init__(self, viewer: napari.viewer.Viewer = None):\n    \"\"\"\n    Initialize the UtilitiesContainer widget.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer, optional\n        The napari viewer instance.\n\n    \"\"\"\n    super().__init__(labels=False)\n\n    self.min_width = 500 # TODO: remove this hardcoded value\n    self._viewer = viewer if viewer is not None else None\n    self._squeezed_dims = None\n\n    self._init_widgets()\n    self._init_save_name_container()\n    self._init_file_options_container()\n    self._init_open_image_container()\n    self._init_metadata_container()\n    self._init_concatenate_files_container()\n    self._init_save_layers_container()\n    self._init_scene_container()\n    # self._init_figure_options_container() # TODO: add figure saving\n    self._init_layout()\n    self._connect_events()\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.__init__(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.append_scene_to_name","title":"append_scene_to_name","text":"<pre><code>append_scene_to_name()\n</code></pre> <p>Append the scene to the save name.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def append_scene_to_name(self):\n    \"\"\"Append the scene to the save name.\"\"\"\n    if self._viewer.layers.selection.active is not None:\n        try:\n            img = self._viewer.layers.selection.active.metadata['bioimage']\n            # remove bad characters from scene name\n            scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n            self._save_name.value = f'{self._save_name.value}_{scene}'\n        except AttributeError:\n            self._results.value = (\n                'Tried to append scene to name, but layer not opened with'\n                ' neuralDev reader.'\n            )\n    else:\n        self._results.value = (\n            'Tried to append scene to name, but no layer selected.'\n            ' So the first scene from the first file will be appended.'\n        )\n        img = nImage(self._files.value[0])\n        scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n        self._save_name.value = f'{self._save_name.value}_{scene}'\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.batch_concatenate_files","title":"batch_concatenate_files","text":"<pre><code>batch_concatenate_files()\n</code></pre> <p>Concatenate files in the selected directory.</p> <p>Save the concatenated files as OME-TIFF, then select the next set of files in the directory to be concatenated. This is done by iterating over the remaining files in the directory based on the number of files selected. The files are sorted alphabetically and numerically. The files will be concatenated until no more files are left in the parent directory.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def batch_concatenate_files(self) -&gt; None:\n    \"\"\"\n    Concatenate files in the selected directory.\n\n    Save the concatenated files as OME-TIFF, then select the next set of\n    files in the directory to be concatenated. This is done by iterating\n    over the remaining files in the directory based on the number of files\n    selected. The files are sorted alphabetically and numerically. The\n    files will be concatenated until no more files are left in the parent\n    directory.\n    \"\"\"\n    # get total number of sets of files in the directory\n    parent_dir = self._files.value[0].parent\n    total_num_files = len(list(parent_dir.glob(f'*{self._files.value[0].suffix}')))\n    num_files = self._files.value.__len__()\n    num_file_sets = total_num_files // num_files\n\n    # save first set of files\n    self.save_files_as_ome_tiff()\n    # iterate through the remaining sets of files in the directory\n    for _ in range(num_file_sets):\n        self.select_next_images()\n        self.save_files_as_ome_tiff()\n\n    self._results.value = (\n        'Batch concatenated files in directory.'\n        f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n    )\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_files","title":"concatenate_files","text":"<pre><code>concatenate_files(files)\n</code></pre> <p>Concatenate the image data from the selected files.</p> <p>Removes \"empty\" channels, which are channels with no values above 0. This is present in some microscope formats where it will image in RGB, and then leave empty channels not represented by the color channels.</p> <p>Does not currently handle scenes.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The concatenated image data.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def concatenate_files(\n    self,\n    files: str | Path | list[str | Path],\n) -&gt; np.ndarray:\n    \"\"\"\n    Concatenate the image data from the selected files.\n\n    Removes \"empty\" channels, which are channels with no values above 0.\n    This is present in some microscope formats where it will image in RGB,\n    and then leave empty channels not represented by the color channels.\n\n    Does not currently handle scenes.\n\n    Parameters\n    ----------\n    files : str or Path or list of str or Path\n        The file(s) to concatenate.\n\n    Returns\n    -------\n    numpy.ndarray\n        The concatenated image data.\n\n    \"\"\"\n    array_list = []\n\n    for file in files:\n        img = nImage(file)\n\n        if 'S' in img.dims.order:\n            img_data = img.get_image_data('TSZYX')\n        else:\n            img_data = img.data\n\n        # iterate over all channels and only keep if not blank\n        for idx in range(img_data.shape[1]):\n            array = img_data[:, [idx], :, :, :]\n            if array.max() &gt; 0:\n                array_list.append(array)\n    return np.concatenate(array_list, axis=1)\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_files(files)","title":"<code>files</code>","text":"(<code>str or Path or list of str or Path</code>)           \u2013            <p>The file(s) to concatenate.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_layers","title":"concatenate_layers","text":"<pre><code>concatenate_layers(layers)\n</code></pre> <p>Concatenate the image data from the selected layers.</p> <p>Adapts all layers to 5D arrays for compatibility with image dims. If the layer is a shapes layer, it will look for a corresponding image layer to get the dimensions for the shapes layer.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The concatenated image data.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def concatenate_layers(\n    self,\n    layers: Layer | list[Layer],\n) -&gt; np.ndarray:\n    \"\"\"\n    Concatenate the image data from the selected layers.\n\n    Adapts all layers to 5D arrays for compatibility with image dims.\n    If the layer is a shapes layer, it will look for a corresponding image\n    layer to get the dimensions for the shapes layer.\n\n    Parameters\n    ----------\n    layers : napari.layers.Image or list of napari.layers.Image\n        The selected image layers.\n\n    Returns\n    -------\n    numpy.ndarray\n        The concatenated image data.\n\n    \"\"\"\n    if any(isinstance(layer, ShapesLayer) for layer in layers):\n        label_dim = self._get_dims_for_shape_layer(layers)\n\n    array_list = []\n\n    for layer in layers:\n        if isinstance(layer, ShapesLayer):\n            layer_data = layer.to_labels(labels_shape=label_dim)\n            layer_data = layer_data.astype(np.int16)\n        else:\n            layer_data = layer.data\n\n        # convert to 5D array for compatability with image dims\n        while len(layer_data.shape) &lt; 5:\n            layer_data = np.expand_dims(layer_data, axis=0)\n        array_list.append(layer_data)\n\n    return np.concatenate(array_list, axis=1)\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_layers(layers)","title":"<code>layers</code>","text":"(<code>napari.layers.Image or list of napari.layers.Image</code>)           \u2013            <p>The selected image layers.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.open_images","title":"open_images","text":"<pre><code>open_images()\n</code></pre> <p>Open the selected images in the napari viewer with napari-ndev.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def open_images(self):\n    \"\"\"Open the selected images in the napari viewer with napari-ndev.\"\"\"\n    self._viewer.open(self._files.value, plugin='napari-ndev')\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.rescale_by","title":"rescale_by","text":"<pre><code>rescale_by()\n</code></pre> <p>Rescale the selected layers based on the given scale.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def rescale_by(self):\n    \"\"\"Rescale the selected layers based on the given scale.\"\"\"\n    layers = self._viewer.layers.selection\n    scale_tup = self._scale_tuple.value\n\n    for layer in layers:\n        scale_len = len(layer.scale)\n        # get the scale_tup from the back of the tuple first, in case dims\n        # are missing in the new layer\n        layer.scale = scale_tup[-scale_len:]\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.save_files_as_ome_tiff","title":"save_files_as_ome_tiff","text":"<pre><code>save_files_as_ome_tiff()\n</code></pre> <p>Save the selected files as OME-TIFF using BioImage.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def save_files_as_ome_tiff(self) -&gt; np.ndarray:\n    \"\"\"Save the selected files as OME-TIFF using BioImage.\"\"\"\n    img_data = self.concatenate_files(self._files.value)\n    save_dir = self._determine_save_directory('ConcatenatedImages')\n    img_save_name = f'{self._save_name.value}.tiff'\n    img_save_loc = self._get_save_loc(\n        self._save_directory.value,\n        save_dir,\n        img_save_name,\n    )\n\n    cnames = self._channel_names.value\n    channel_names = ast.literal_eval(cnames) if cnames else None\n\n    self._common_save_logic(\n        data=img_data,\n        uri=img_save_loc,\n        dim_order='TCZYX',\n        channel_names=channel_names,\n        image_name=self._save_name.value,\n        result_str='Concatenated Image',\n    )\n\n    return img_data\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.save_layers_as_ome_tiff","title":"save_layers_as_ome_tiff","text":"<pre><code>save_layers_as_ome_tiff()\n</code></pre> <p>Save the selected layers as OME-TIFF.</p> <p>Determines types of layers and saves to corresponding directories.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def save_layers_as_ome_tiff(self) -&gt; np.ndarray:\n    \"\"\"\n    Save the selected layers as OME-TIFF.\n\n    Determines types of layers and saves to corresponding directories.\n    \"\"\"\n    layer_data = self.concatenate_layers(\n        list(self._viewer.layers.selection)\n    )\n    # get the types of layers, to know where to save the image\n    layer_types = [\n        type(layer).__name__ for layer in self._viewer.layers.selection\n    ]\n\n    # if there are multiple layer types, save to Layers directory\n    layer_save_type = 'Layers' if len(set(layer_types)) &gt; 1 else layer_types[0]\n    layer_save_dir = self._determine_save_directory(layer_save_type)\n    layer_save_name = f'{self._save_name.value}.tiff'\n    layer_save_loc = self._get_save_loc(\n        self._save_directory.value, layer_save_dir, layer_save_name\n    )\n\n    # only get channel names if layer_save_type is not shapes or labels layer\n    if layer_save_type not in ['Shapes', 'Labels']:\n        cnames = self._channel_names.value\n        channel_names = ast.literal_eval(cnames) if cnames else None\n    else:\n        channel_names = [layer_save_type]\n\n    if layer_save_type == 'Shapes':\n        layer_data = layer_data.astype(np.int16)\n\n    elif layer_save_type == 'Labels':\n        if layer_data.max() &gt; 65535:\n            layer_data = layer_data.astype(np.int32)\n        else:\n            layer_data = layer_data.astype(np.int16)\n\n    self._common_save_logic(\n        data=layer_data,\n        uri=layer_save_loc,\n        dim_order='TCZYX',\n        channel_names=channel_names,\n        image_name=self._save_name.value,\n        result_str=layer_save_type,\n    )\n\n    return layer_data\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.save_scenes_ome_tiff","title":"save_scenes_ome_tiff","text":"<pre><code>save_scenes_ome_tiff()\n</code></pre> <p>Save selected scenes as OME-TIFF.</p> <p>This method is intended to save scenes from a single file. The scenes are extracted based on the scenes_to_extract widget value, which is a list of scene indices. If the widget is left blank, then all scenes will be extracted.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def save_scenes_ome_tiff(self) -&gt; None:\n    \"\"\"\n    Save selected scenes as OME-TIFF.\n\n    This method is intended to save scenes from a single file. The scenes\n    are extracted based on the scenes_to_extract widget value, which is a\n    list of scene indices. If the widget is left blank, then all scenes\n    will be extracted.\n\n    \"\"\"\n    img = nImage(self._files.value[0])\n\n    scenes = self._scenes_to_extract.value\n    scenes_list = ast.literal_eval(scenes) if scenes else img.scenes\n    save_dir = self._determine_save_directory('ExtractedScenes')\n    save_directory = self._save_directory.value / save_dir\n    save_directory.mkdir(parents=False, exist_ok=True)\n\n    for scene in scenes_list:\n        # TODO: fix this to not have an issue if there are identical scenes\n        # presented as strings, though the asssumption is most times the\n        # user will input a list of integers.\n        img.set_scene(scene)\n\n        base_save_name = self._save_name.value.split('.')[0]\n        image_id = helpers.create_id_string(img, base_save_name)\n\n        img_save_name = f'{image_id}.tiff'\n        img_save_loc = save_directory / img_save_name\n\n        # get channel names from widget if truthy\n        cnames = self._channel_names.value\n        channel_names = ast.literal_eval(cnames) if cnames else None\n\n        self._common_save_logic(\n            data=img.data,\n            uri=img_save_loc,\n            dim_order='TCZYX',\n            channel_names=channel_names,\n            image_name=image_id,\n            result_str=f'Scene: {img.current_scene}',\n        )\n\n    self._results.value = (\n        f'Saved extracted scenes: {scenes_list}'\n        f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n    )\n    return\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.update_metadata_from_layer","title":"update_metadata_from_layer","text":"<pre><code>update_metadata_from_layer()\n</code></pre> <p>Update metadata from the selected layer.</p> <p>Expects images to be opened with napari-ndev reader.</p> Note: <p>This should also support napari-bioio in the future, when released.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def update_metadata_from_layer(self):\n    \"\"\"\n    Update metadata from the selected layer.\n\n    Expects images to be opened with napari-ndev reader.\n\n    Note:\n    ----\n    This should also support napari-bioio in the future, when released.\n\n    \"\"\"\n    selected_layer = self._viewer.layers.selection.active\n    try:\n        img = selected_layer.metadata['bioimage']\n        self._update_metadata_from_Image(img)\n\n    except AttributeError:\n        self._results.value = (\n            'Tried to update metadata, but no layer selected.'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n    except KeyError:\n        scale = selected_layer.scale\n        self._scale_tuple.value = (\n            scale[-3] if len(scale) &gt;= 3 else 1,\n            scale[-2],\n            scale[-1],\n        )\n        self._results.value = (\n            'Tried to update metadata, but could only update scale'\n            ' because layer not opened with neuralDev reader.'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.update_metadata_on_file_select","title":"update_metadata_on_file_select","text":"<pre><code>update_metadata_on_file_select()\n</code></pre> <p>Update self._save_name.value and metadata if selected.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def update_metadata_on_file_select(self):\n    \"\"\"Update self._save_name.value and metadata if selected.\"\"\"\n    # TODO: get true stem of file, in case .ome.tiff\n    self._save_name.value = str(self._files.value[0].stem)\n    img = nImage(self._files.value[0])\n\n    self._update_metadata_from_Image(\n        img,\n        update_channel_names=self._update_channel_names.value,\n        update_scale=self._update_scale.value,\n    )\n</code></pre>"},{"location":"api/widgets/measure_widget/","title":"Measure widget","text":""},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container","title":"napari_ndev.widgets._measure_container","text":""},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer","title":"MeasureContainer","text":"<p>               Bases: <code>Container</code></p> <p>Widget to measure labels from folders.</p> <p>This class provides functionality to measure labels and compare them against intensity images, which can be microscopic images or other labels. It initializes various widgets and containers for user input and interaction, and connects events to handle user actions.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_label_choices</code>               (<code>list</code>)           \u2013            <p>List of label choices.</p> </li> <li> <code>_intensity_choices</code>               (<code>list</code>)           \u2013            <p>List of intensity image choices.</p> </li> <li> <code>_p_sizes</code>               (<code>None</code>)           \u2013            <p>Placeholder for pixel sizes.</p> </li> <li> <code>_squeezed_dims</code>               (<code>None</code>)           \u2013            <p>Placeholder for squeezed dimensions.</p> </li> <li> <code>_prop</code>               (<code>object</code>)           \u2013            <p>Dynamic object to hold region properties checkboxes.</p> </li> <li> <code>_label_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting label directory.</p> </li> <li> <code>_image_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting image directory.</p> </li> <li> <code>_region_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting region directory.</p> </li> <li> <code>_output_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting output directory.</p> </li> <li> <code>_label_image</code>               (<code>ComboBox</code>)           \u2013            <p>Widget for selecting label image.</p> </li> <li> <code>_intensity_images</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting intensity images.</p> </li> <li> <code>_scale_tuple</code>               (<code>TupleEdit</code>)           \u2013            <p>Widget for setting physical pixel sizes.</p> </li> <li> <code>_measure_button</code>               (<code>PushButton</code>)           \u2013            <p>Button to start measurement.</p> </li> <li> <code>_progress_bar</code>               (<code>ProgressBar</code>)           \u2013            <p>Progress bar to show measurement progress.</p> </li> <li> <code>_props_container</code>               (<code>Container</code>)           \u2013            <p>Container for region properties checkboxes.</p> </li> <li> <code>_sk_props</code>               (<code>list</code>)           \u2013            <p>List of region properties.</p> </li> <li> <code>_id_regex_container</code>               (<code>Container</code>)           \u2013            <p>Container for ID regex settings.</p> </li> <li> <code>_example_id_string</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for example ID string.</p> </li> <li> <code>_id_regex_dict</code>               (<code>TextEdit</code>)           \u2013            <p>Widget for ID regex dictionary.</p> </li> <li> <code>_tx_map_container</code>               (<code>Container</code>)           \u2013            <p>Container for treatment map settings.</p> </li> <li> <code>_tx_id</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for treatment ID.</p> </li> <li> <code>_tx_n_well</code>               (<code>ComboBox</code>)           \u2013            <p>Widget for number of wells.</p> </li> <li> <code>_tx_dict</code>               (<code>TextEdit</code>)           \u2013            <p>Widget for treatment dictionary.</p> </li> <li> <code>_grouping_container</code>               (<code>Container</code>)           \u2013            <p>Container for grouping settings.</p> </li> <li> <code>_create_grouped</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox to create grouped data.</p> </li> <li> <code>_group_by_sample_id</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox to group by sample ID.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_init_widgets</code>             \u2013              <p>Initializes the widgets for user input.</p> </li> <li> <code>_init_regionprops_container</code>             \u2013              <p>Initializes the container for region properties checkboxes.</p> </li> <li> <code>_init_id_regex_container</code>             \u2013              <p>Initializes the container for ID regex settings.</p> </li> <li> <code>_init_tx_map_container</code>             \u2013              <p>Initializes the container for treatment map settings.</p> </li> <li> <code>_init_grouping_container</code>             \u2013              <p>Initializes the container for grouping settings.</p> </li> <li> <code>_init_layout</code>             \u2013              <p>Initializes the layout of the container.</p> </li> <li> <code>_connect_events</code>             \u2013              <p>Connects events to handle user actions.</p> </li> <li> <code>_get_0th_img_from_dir</code>             \u2013              <p>Gets the first image from a directory.</p> </li> <li> <code>_update_dim_and_scales</code>             \u2013              <p>Updates the dimensions and scales based on the image.</p> </li> <li> <code>_update_choices</code>             \u2013              <p>Updates the choices for labels and intensity images.</p> </li> <li> <code>_update_image_choices</code>             \u2013              <p>Updates the choices for intensity images.</p> </li> <li> <code>_update_label_choices</code>             \u2013              <p>Updates the choices for label images.</p> </li> <li> <code>_update_region_choices</code>             \u2013              <p>Updates the choices for region images.</p> </li> <li> <code>_safe_dict_eval</code>             \u2013              <p>Safely evaluates a dictionary string.</p> </li> <li> <code>batch_measure</code>             \u2013              <p>Performs batch measurement of labels and intensity images, and returns the measurement results as a DataFrame.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>class MeasureContainer(Container):\n    \"\"\"\n    Widget to measure labels from folders.\n\n    This class provides functionality to measure labels and compare them against intensity images, which can be microscopic images or other labels. It initializes various widgets and containers for user input and interaction, and connects events to handle user actions.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance. Optional.\n\n    Attributes\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    _label_choices : list\n        List of label choices.\n    _intensity_choices : list\n        List of intensity image choices.\n    _p_sizes : None\n        Placeholder for pixel sizes.\n    _squeezed_dims : None\n        Placeholder for squeezed dimensions.\n    _prop : object\n        Dynamic object to hold region properties checkboxes.\n    _label_directory : FileEdit\n        Widget for selecting label directory.\n    _image_directory : FileEdit\n        Widget for selecting image directory.\n    _region_directory : FileEdit\n        Widget for selecting region directory.\n    _output_directory : FileEdit\n        Widget for selecting output directory.\n    _label_image : ComboBox\n        Widget for selecting label image.\n    _intensity_images : Select\n        Widget for selecting intensity images.\n    _scale_tuple : TupleEdit\n        Widget for setting physical pixel sizes.\n    _measure_button : PushButton\n        Button to start measurement.\n    _progress_bar : ProgressBar\n        Progress bar to show measurement progress.\n    _props_container : Container\n        Container for region properties checkboxes.\n    _sk_props : list\n        List of region properties.\n    _id_regex_container : Container\n        Container for ID regex settings.\n    _example_id_string : LineEdit\n        Widget for example ID string.\n    _id_regex_dict : TextEdit\n        Widget for ID regex dictionary.\n    _tx_map_container : Container\n        Container for treatment map settings.\n    _tx_id : LineEdit\n        Widget for treatment ID.\n    _tx_n_well : ComboBox\n        Widget for number of wells.\n    _tx_dict : TextEdit\n        Widget for treatment dictionary.\n    _grouping_container : Container\n        Container for grouping settings.\n    _create_grouped : CheckBox\n        Checkbox to create grouped data.\n    _group_by_sample_id : CheckBox\n        Checkbox to group by sample ID.\n\n    Methods\n    -------\n    _init_widgets()\n        Initializes the widgets for user input.\n    _init_regionprops_container()\n        Initializes the container for region properties checkboxes.\n    _init_id_regex_container()\n        Initializes the container for ID regex settings.\n    _init_tx_map_container()\n        Initializes the container for treatment map settings.\n    _init_grouping_container()\n        Initializes the container for grouping settings.\n    _init_layout()\n        Initializes the layout of the container.\n    _connect_events()\n        Connects events to handle user actions.\n    _get_0th_img_from_dir(directory)\n        Gets the first image from a directory.\n    _update_dim_and_scales(img)\n        Updates the dimensions and scales based on the image.\n    _update_choices(directory, prefix, update_label=False)\n        Updates the choices for labels and intensity images.\n    _update_image_choices()\n        Updates the choices for intensity images.\n    _update_label_choices()\n        Updates the choices for label images.\n    _update_region_choices()\n        Updates the choices for region images.\n    _safe_dict_eval(dict_string, dict_name=None)\n        Safely evaluates a dictionary string.\n    batch_measure()\n        Performs batch measurement of labels and intensity images, and returns the measurement results as a DataFrame.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        viewer: napari.viewer.Viewer = None,\n    ):\n        \"\"\"\n        Initialize the MeasureContainer.\n\n        Parameters\n        ----------\n        viewer : napari.viewer.Viewer\n            The napari viewer instance. Optional.\n\n        \"\"\"\n        super().__init__()\n\n        self.viewer = viewer if viewer is not None else None\n        self._label_choices = []\n        self._intensity_choices = []\n        self._p_sizes = None\n        self._squeezed_dims = None\n        self._prop = type('', (), {})()\n\n        self._init_widgets()\n        self._init_regionprops_container()\n        self._init_id_regex_container()\n        self._init_tx_map_container()\n        self._init_grouping_container()\n        self._init_layout()\n        self._connect_events()\n\n    def _init_widgets(self):\n        \"\"\"Initialize non-container widgets.\"\"\"\n        self._label_directory = FileEdit(label='Label directory', mode='d')\n        self._image_directory = FileEdit(\n            label='Image directory', mode='d', nullable=True\n        )\n        self._region_directory = FileEdit(\n            label='Region directory', mode='d', nullable=True\n        )\n        self._output_directory = FileEdit(label='Output directory', mode='d')\n\n        self._label_images = Select(\n            label='Label image',\n            choices=self._label_choices,\n            allow_multiple=True,\n            nullable=False,\n            tooltip='Select label images to measure',\n        )\n        self._intensity_images = Select(\n            label='Intensity images',\n            choices=self._intensity_choices,\n            allow_multiple=True,\n            nullable=True,\n            tooltip='Select intensity images to compare against labels',\n        )\n        self._scale_tuple = TupleEdit(\n            value=(0.0000, 1.0000, 1.0000),\n            label='Physical Pixel Sizes, ZYX',\n            tooltip='Pixel size, usually in \u03bcm/px',\n            options={'step': 0.0001},\n        )\n        self._measure_button = PushButton(label='Measure')\n\n        self._progress_bar = ProgressBar(label='Progress:')\n\n    def _init_regionprops_container(self):\n        \"\"\"Initialize the container for region properties checkboxes.\"\"\"\n        self._props_container = Container(layout='vertical')\n\n        self._sk_props = [\n            'label',\n            'area',\n            'area_convex',\n            'bbox',\n            'centroid',\n            'eccentricity',\n            'extent',\n            'feret_diameter_max',\n            'intensity_max',\n            'intensity_mean',\n            'intensity_min',\n            'intensity_std',\n            'num_pixels',\n            'orientation',\n            'perimeter',\n            'solidity',\n        ]\n\n        for feature in self._sk_props:\n            setattr(self._prop, feature, CheckBox(label=feature))\n            self._props_container.extend([getattr(self._prop, feature)])\n\n        self._prop.label.value = True\n        self._prop.area.value = True\n\n    def _init_id_regex_container(self):\n        \"\"\"Initialize the container for ID regex settings.\"\"\"\n        self._id_regex_container = Container(layout='vertical')\n        self._example_id_string = LineEdit(\n            label='Example ID String',\n            value=None,\n            nullable=True,\n        )\n        self._id_regex_dict = TextEdit(\n            label='ID Regex Dict',\n            value='{\\n\\n}',\n        )\n        self._id_regex_container.extend(\n            [self._example_id_string, self._id_regex_dict]\n        )\n\n    def _init_tx_map_container(self):\n        \"\"\"Initialize the container for treatment map settings.\"\"\"\n        self._tx_map_container = Container(layout='vertical')\n        self._update_tx_id_choices_button = PushButton(label='Update Treatment ID Choices')\n        self._tx_id = ComboBox(\n            label='Treatment ID',\n            choices=['id'],\n            value=None,\n            nullable=True,\n            tooltip='Usually, the treatment ID is the well ID or a unique identifier for each sample'\n            \"The treatment dict will be looked up against whatever this value is. If it is 'file', then will match against the filename\",\n        )\n        self._tx_n_well = ComboBox(\n            label='Number of Wells',\n            value=None,\n            choices=[6, 12, 24, 48, 96, 384],\n            nullable=True,\n            tooltip='By default, treatments must be verbosely defined for each condition and sample id '\n            'If you have a known plate map, then selecting wells will allow a sparse treatment map to be passed to PlateMapper',\n        )\n        self._tx_dict = TextEdit(label='Treatment Dict', value='{\\n\\n}')\n        # TODO: Add example treatment regex result widget when example id string or id regex dict is changed\n\n        self._tx_map_container.extend(\n            [\n                self._update_tx_id_choices_button,\n                self._tx_id,\n                self._tx_n_well,\n                self._tx_dict,\n            ]\n        )\n\n    def _init_grouping_container(self):\n        \"\"\"Initialize the container for grouping settings.\"\"\"\n        self._grouping_container = Container(layout='vertical')\n\n        self._measured_data_path = FileEdit(\n            label='Measured Data Path',\n            tooltip='Path to the measured data',\n        )\n        self._grouping_cols = Select(\n            label='Grouping Columns',\n            choices=[],\n            allow_multiple=True,\n            tooltip='Select columns to group the data by',\n        )\n        self._count_col = ComboBox(\n            label='Count Column',\n            choices=[],\n            tooltip='Select column that will be counted',\n        )\n        self._agg_cols = Select(\n            label='Aggregation Columns',\n            choices=[],\n            allow_multiple=True,\n            nullable=True,\n            value=None,\n            tooltip='Select columns to aggregate with functions',\n        )\n        self._agg_funcs = Select(\n            label='Aggregation Functions',\n            choices=[\n                'mean', 'median',\n                'std', 'sem',\n                'min', 'max',\n                'sum', 'nunique'\n            ],\n            value=['mean'],\n            allow_multiple=True,\n            tooltip='Select functions performed on aggregation columns',\n        )\n        self._pivot_wider = CheckBox(label='Pivot Wider', value=True)\n        self._group_measurements_button = PushButton(label='Group Measurements')\n\n\n        self._grouping_container.extend([\n            self._measured_data_path,\n            self._grouping_cols,\n            self._count_col,\n            self._agg_cols,\n            self._agg_funcs,\n            self._pivot_wider,\n            self._group_measurements_button,\n        ])\n\n    def _init_layout(self):\n        \"\"\"Initialize the layout of the container.\"\"\"\n        self.extend(\n            [\n                self._label_directory,\n                self._image_directory,\n                self._region_directory,\n                self._output_directory,\n                self._label_images,\n                self._intensity_images,\n                self._scale_tuple,\n                self._measure_button,\n                self._progress_bar,\n            ]\n        )\n\n        tabs = QTabWidget()\n        tabs.addTab(self._props_container.native, 'Region Props')\n        tabs.addTab(self._id_regex_container.native, 'ID Regex')\n        tabs.addTab(self._tx_map_container.native, 'Tx Map')\n        tabs.addTab(self._grouping_container.native, 'Grouping')\n        self.native.layout().addWidget(tabs)\n\n    def _connect_events(self):\n        \"\"\"Connect events to handle user actions.\"\"\"\n        self._image_directory.changed.connect(self._update_image_choices)\n        self._label_directory.changed.connect(self._update_label_choices)\n        self._region_directory.changed.connect(self._update_region_choices)\n        self._update_tx_id_choices_button.clicked.connect(self._update_tx_id_choices)\n        self._measure_button.clicked.connect(self.batch_measure)\n        self._measured_data_path.changed.connect(self._update_grouping_cols)\n        self._group_measurements_button.clicked.connect(self.group_measurements)\n\n    def _update_tx_id_choices(self):\n        \"\"\"Update the choices for treatment ID.\"\"\"\n        id_regex_dict = self._safe_dict_eval(self._id_regex_dict.value)\n        if id_regex_dict is None:\n            return\n        # add the keys to a list which already contains 'id'\n        regex_choices = list(id_regex_dict.keys())\n        self._tx_id.choices = ['id'] + regex_choices\n\n    def _update_grouping_cols(self):\n        \"\"\"Update the columns for grouping.\"\"\"\n        if self._measured_data_path.value is None:\n            return\n\n        df = pd.read_csv(self._measured_data_path.value)\n        self._grouping_cols.choices = df.columns\n        self._count_col.choices = df.columns\n        self._agg_cols.choices = df.columns\n\n        # set default value to label_name and id if exists\n        grouping_cols = []\n        if 'label_name' in df.columns:\n            grouping_cols.append('label_name')\n        if 'id' in df.columns:\n            grouping_cols.append('id')\n        self._grouping_cols.value = grouping_cols\n\n        if 'label' in df.columns:\n            self._count_col.value = 'label'\n\n        return\n\n    def _get_0th_img_from_dir(\n        self, directory: str | None = None\n    ) -&gt; tuple[BioImage, pathlib.Path]:\n        \"\"\"Get the first image from a directory.\"\"\"\n        from bioio import BioImage\n\n        _, files = helpers.get_directory_and_files(directory)\n        return BioImage(files[0]), files[0]\n\n    def _update_dim_and_scales(self, img):\n        \"\"\"Update the dimensions and scales based on the image.\"\"\"\n        self._squeezed_dims = helpers.get_squeezed_dim_order(img)\n        self._scale_tuple.value = (\n            img.physical_pixel_sizes.Z or 1,\n            img.physical_pixel_sizes.Y or 1,\n            img.physical_pixel_sizes.X or 1,\n        )\n\n    def _update_choices(self, directory, prefix, update_label=False):\n        \"\"\"Update the choices for labels and intensity images.\"\"\"\n        img, _ = self._get_0th_img_from_dir(directory)\n        img_channels = helpers.get_channel_names(img)\n        img_channels = [f'{prefix}: {channel}' for channel in img_channels]\n\n        if update_label:\n            self._update_dim_and_scales(img)\n            self._label_choices.extend(img_channels)\n            self._label_images.choices = self._label_choices\n\n        self._intensity_choices.extend(img_channels)\n        self._intensity_images.choices = self._intensity_choices\n\n    def _update_image_choices(self):\n        \"\"\"Update the choices for intensity images.\"\"\"\n        self._update_choices(self._image_directory.value, 'Intensity')\n\n    def _update_label_choices(self):\n        \"\"\"Update the choices for label images.\"\"\"\n        self._update_choices(\n            self._label_directory.value, 'Labels', update_label=True\n        )\n        img, file_id = self._get_0th_img_from_dir(self._label_directory.value)\n        id_string = helpers.create_id_string(img, file_id.stem)\n        self._example_id_string.value = id_string\n\n    def _update_region_choices(self):\n        \"\"\"Update the choices for region images.\"\"\"\n        self._update_choices(self._region_directory.value, 'Region')\n\n    def _safe_dict_eval(self, dict_string, dict_name=None):\n        \"\"\"Safely evaluate a string as a dictionary.\"\"\"\n        if dict_string is None:\n            return None\n\n        stripped_string = dict_string.strip()\n        if stripped_string == '{}' or not stripped_string:\n            return None\n        try:\n            return ast.literal_eval(stripped_string)\n        except (ValueError, SyntaxError):\n            return None\n\n    def batch_measure(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Perform batch measurement of labels and intensity images.\n\n        Use scikit-image's regionprops to measure properties of labels and\n        intensity images. The measurements are saved to a CSV file in the\n        output directory.\n\n        Returns\n        -------\n        pd.DataFrame\n            The measurement results as a DataFrame.\n\n        \"\"\"\n        from bioio import BioImage\n\n        # from skimage import measure\n        from napari_ndev import measure as ndev_measure\n\n        # get all the files in the label directory\n        label_dir, label_files = helpers.get_directory_and_files(\n            self._label_directory.value\n        )\n        image_dir, image_files = helpers.get_directory_and_files(\n            self._image_directory.value\n        )\n        region_dir, region_files = helpers.get_directory_and_files(\n            self._region_directory.value\n        )\n\n        log_loc = self._output_directory.value / 'measure.log.txt'\n        logger, handler = helpers.setup_logger(log_loc)\n\n        logger.info(\n            \"\"\"\n            Label Images: %s\n            Intensity Channels: %s\n            Num. Files: %d\n            Label Directory: %s\n            Image Directory: %s\n            Region Directory: %s\n            Output Directory: %s\n            ID Example: %s\n            ID Regex Dict: %s\n            Tx ID: %s\n            Tx N Well: %s\n            Tx Dict: %s\n            \"\"\",\n            self._label_images.value,\n            self._intensity_images.value,\n            len(label_files),\n            label_dir,\n            image_dir,\n            region_dir,\n            self._output_directory.value,\n            self._example_id_string.value,\n            self._id_regex_dict.value,\n            self._tx_id.value,\n            self._tx_n_well.value,\n            self._tx_dict.value,\n        )\n\n        # check if the label files are the same as the image files\n        if self._image_directory.value is not None and len(label_files) != len(image_files):\n            logger.error(\n                'Number of label files (%s) and image files (%s) do not match',\n                len(label_files), len(image_files),\n            )\n        if self._region_directory.value is not None and len(label_files) != len(region_files):\n            logger.error(\n                'Number of label files (%s) and region files (%s) do not match',\n                len(label_files), len(region_files),\n            )\n\n        self._progress_bar.label = f'Measuring {len(label_files)} Images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(label_files)\n        # get the relevant spacing for regionprops, depending on length\n        props_scale = self._scale_tuple.value\n        props_scale = props_scale[-len(self._squeezed_dims) :]\n        # get the properties list\n        properties = [\n            prop.label for prop in self._props_container if prop.value\n        ]\n\n        id_regex_dict = self._safe_dict_eval(\n            self._id_regex_dict.value, 'ID Regex Dict'\n        )\n        tx_dict = self._safe_dict_eval(self._tx_dict.value, 'Tx Dict')\n        measure_props_concat = []\n\n        for idx, file in enumerate(label_files):\n            # TODO: Add scene processing\n            logger.info('Processing file %s', file.name)\n            lbl = BioImage(label_dir / file.name)\n            id_string = helpers.create_id_string(lbl, file.stem)\n\n            # get the itnensity image only if the image directory is not empty\n            if self._image_directory.value:\n                image_path = image_dir / file.name\n                if not image_path.exists():\n                    logger.error(\n                        'Image file %s not found in intensity directory',\n                        file.name,\n                    )\n                    self._progress_bar.value = idx + 1\n                    continue\n                img = BioImage(image_path)\n            if self._region_directory.value:\n                region_path = region_dir / file.name\n                if not region_path.exists():\n                    logger.error(\n                        'Region file %s not found in region directory',\n                        file.name,\n                    )\n                    self._progress_bar.value = idx + 1\n                    continue\n                reg = BioImage(region_path)\n\n            for scene_idx, scene in enumerate(lbl.scenes):\n                logger.info('Processing scene: %s :: %s', scene_idx, scene)\n                lbl.set_scene(scene_idx)\n\n                label_images = []\n                label_names = []\n\n                # iterate through each channel in the label image\n                for label_chan in self._label_images.value:\n                    label_chan = label_chan[8:]\n                    label_names.append(label_chan)\n\n                    lbl_C = lbl.channel_names.index(label_chan)\n                    label = lbl.get_image_data(self._squeezed_dims, C=lbl_C)\n                    label_images.append(label)\n\n                intensity_images = []\n                intensity_names = []\n\n                # id_string = helpers.create_id_string(lbl, file.stem)\n\n                # Get stack of intensity images if there are any selected\n                if self._intensity_images.value and not None:\n                    for channel in self._intensity_images.value:\n                        if channel.startswith('Labels: '):\n                            chan = channel[8:]\n                            lbl_C = lbl.channel_names.index(chan)\n                            lbl.set_scene(scene_idx)\n                            inten_img = lbl.get_image_data(\n                                self._squeezed_dims, C=lbl_C\n                            )\n                        elif channel.startswith('Intensity: '):\n                            chan = channel[11:]\n                            img_C = img.channel_names.index(chan)\n                            img.set_scene(scene_idx)\n                            inten_img = img.get_image_data(\n                                self._squeezed_dims, C=img_C\n                            )\n                        elif channel.startswith('Region: '):\n                            chan = channel[8:]\n                            reg_C = reg.channel_names.index(chan)\n                            reg.set_scene(scene_idx)\n                            inten_img = reg.get_image_data(\n                                self._squeezed_dims, C=reg_C\n                            )\n                        intensity_names.append(chan)\n                        intensity_images.append(inten_img)\n\n                    # the last dim is the multi-channel dim for regionprops\n                    intensity_stack = np.stack(intensity_images, axis=-1)\n\n                else:\n                    intensity_stack = None\n                    intensity_names = None\n\n                # start the measuring here\n                # TODO: Add optional scaling, in case images have different scales?\n                measure_props_df = ndev_measure.measure_regionprops(\n                    label_images=label_images,\n                    label_names=label_names,\n                    intensity_images=intensity_stack,\n                    intensity_names=intensity_names,\n                    properties=properties,\n                    scale=props_scale,\n                    id_string=id_string,\n                    id_regex_dict=id_regex_dict,\n                    tx_id=self._tx_id.value,\n                    tx_dict=tx_dict,\n                    tx_n_well=self._tx_n_well.value,\n                    save_data_path=None,\n                )\n\n                measure_props_concat.append(measure_props_df)\n                self._progress_bar.value = idx + 1\n\n        measure_props_df = pd.concat(measure_props_concat)\n        labels_string = '_'.join(label_names)\n        save_loc = self._output_directory.value / f'measure_props_{labels_string}.csv'\n        measure_props_df.to_csv(save_loc, index=False)\n\n        logger.removeHandler(handler)\n\n        return measure_props_df\n\n    def group_measurements(self):\n        \"\"\"\n        Group measurements based on user input.\n\n        Uses the values in the Grouping Container of the Widget and passes them\n        to the group_and_agg_measurements function in the measure module. The\n        grouped measurements are saved to a CSV file in the same directory as\n        the measured data with '_grouped' appended.\n\n        Returns\n        -------\n        pd.DataFrame\n            The grouped measurements as a DataFrame.\n\n        \"\"\"\n        from napari_ndev import measure as ndev_measure\n\n        self._progress_bar.label = 'Grouping Measurements'\n        self._progress_bar.value = 0\n        self._progress_bar.max = 1\n\n        df = pd.read_csv(self._measured_data_path.value)\n\n        # Filter out None values from agg_cols\n        agg_cols = [col for col in self._agg_cols.value if col is not None]\n\n        grouped_df = ndev_measure.group_and_agg_measurements(\n            df=df,\n            grouping_cols=self._grouping_cols.value,\n            count_col=self._count_col.value,\n            agg_cols=agg_cols,\n            agg_funcs=self._agg_funcs.value,\n        )\n        # use the label_name column to make the dataframe wider\n        if self._pivot_wider.value:\n            # get grouping calls without label name\n            index_cols = [col for col in self._grouping_cols.value if col != 'label_name']\n\n            # alternatively, pivot every values column that is not present in index or columns\n            value_cols = [col for col in grouped_df.columns if col not in self._grouping_cols.value]\n\n            pivot_df = grouped_df.pivot(\n                index=index_cols,\n                columns='label_name',\n                values=value_cols,\n            )\n            # # flatten the multiindex columns\n            # pivot_df.columns = [f'{col[1]}_{col[0]}' for col in pivot_df.columns]\n\n            # reset index so that it is saved in the csv\n            pivot_df.reset_index(inplace=True)\n\n            grouped_df = pivot_df\n\n        save_loc = (\n            self._measured_data_path.value.parent /\n            f'{self._measured_data_path.value.stem}_grouped.csv'\n        )\n        grouped_df.to_csv(save_loc, index=False)\n\n        self._progress_bar.value = 1\n        return grouped_df\n</code></pre>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance. Optional.</p>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.__init__","title":"__init__","text":"<pre><code>__init__(viewer=None)\n</code></pre> <p>Initialize the MeasureContainer.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>def __init__(\n    self,\n    viewer: napari.viewer.Viewer = None,\n):\n    \"\"\"\n    Initialize the MeasureContainer.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance. Optional.\n\n    \"\"\"\n    super().__init__()\n\n    self.viewer = viewer if viewer is not None else None\n    self._label_choices = []\n    self._intensity_choices = []\n    self._p_sizes = None\n    self._squeezed_dims = None\n    self._prop = type('', (), {})()\n\n    self._init_widgets()\n    self._init_regionprops_container()\n    self._init_id_regex_container()\n    self._init_tx_map_container()\n    self._init_grouping_container()\n    self._init_layout()\n    self._connect_events()\n</code></pre>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.__init__(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance. Optional.</p>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.batch_measure","title":"batch_measure","text":"<pre><code>batch_measure()\n</code></pre> <p>Perform batch measurement of labels and intensity images.</p> <p>Use scikit-image's regionprops to measure properties of labels and intensity images. The measurements are saved to a CSV file in the output directory.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The measurement results as a DataFrame.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>def batch_measure(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Perform batch measurement of labels and intensity images.\n\n    Use scikit-image's regionprops to measure properties of labels and\n    intensity images. The measurements are saved to a CSV file in the\n    output directory.\n\n    Returns\n    -------\n    pd.DataFrame\n        The measurement results as a DataFrame.\n\n    \"\"\"\n    from bioio import BioImage\n\n    # from skimage import measure\n    from napari_ndev import measure as ndev_measure\n\n    # get all the files in the label directory\n    label_dir, label_files = helpers.get_directory_and_files(\n        self._label_directory.value\n    )\n    image_dir, image_files = helpers.get_directory_and_files(\n        self._image_directory.value\n    )\n    region_dir, region_files = helpers.get_directory_and_files(\n        self._region_directory.value\n    )\n\n    log_loc = self._output_directory.value / 'measure.log.txt'\n    logger, handler = helpers.setup_logger(log_loc)\n\n    logger.info(\n        \"\"\"\n        Label Images: %s\n        Intensity Channels: %s\n        Num. Files: %d\n        Label Directory: %s\n        Image Directory: %s\n        Region Directory: %s\n        Output Directory: %s\n        ID Example: %s\n        ID Regex Dict: %s\n        Tx ID: %s\n        Tx N Well: %s\n        Tx Dict: %s\n        \"\"\",\n        self._label_images.value,\n        self._intensity_images.value,\n        len(label_files),\n        label_dir,\n        image_dir,\n        region_dir,\n        self._output_directory.value,\n        self._example_id_string.value,\n        self._id_regex_dict.value,\n        self._tx_id.value,\n        self._tx_n_well.value,\n        self._tx_dict.value,\n    )\n\n    # check if the label files are the same as the image files\n    if self._image_directory.value is not None and len(label_files) != len(image_files):\n        logger.error(\n            'Number of label files (%s) and image files (%s) do not match',\n            len(label_files), len(image_files),\n        )\n    if self._region_directory.value is not None and len(label_files) != len(region_files):\n        logger.error(\n            'Number of label files (%s) and region files (%s) do not match',\n            len(label_files), len(region_files),\n        )\n\n    self._progress_bar.label = f'Measuring {len(label_files)} Images'\n    self._progress_bar.value = 0\n    self._progress_bar.max = len(label_files)\n    # get the relevant spacing for regionprops, depending on length\n    props_scale = self._scale_tuple.value\n    props_scale = props_scale[-len(self._squeezed_dims) :]\n    # get the properties list\n    properties = [\n        prop.label for prop in self._props_container if prop.value\n    ]\n\n    id_regex_dict = self._safe_dict_eval(\n        self._id_regex_dict.value, 'ID Regex Dict'\n    )\n    tx_dict = self._safe_dict_eval(self._tx_dict.value, 'Tx Dict')\n    measure_props_concat = []\n\n    for idx, file in enumerate(label_files):\n        # TODO: Add scene processing\n        logger.info('Processing file %s', file.name)\n        lbl = BioImage(label_dir / file.name)\n        id_string = helpers.create_id_string(lbl, file.stem)\n\n        # get the itnensity image only if the image directory is not empty\n        if self._image_directory.value:\n            image_path = image_dir / file.name\n            if not image_path.exists():\n                logger.error(\n                    'Image file %s not found in intensity directory',\n                    file.name,\n                )\n                self._progress_bar.value = idx + 1\n                continue\n            img = BioImage(image_path)\n        if self._region_directory.value:\n            region_path = region_dir / file.name\n            if not region_path.exists():\n                logger.error(\n                    'Region file %s not found in region directory',\n                    file.name,\n                )\n                self._progress_bar.value = idx + 1\n                continue\n            reg = BioImage(region_path)\n\n        for scene_idx, scene in enumerate(lbl.scenes):\n            logger.info('Processing scene: %s :: %s', scene_idx, scene)\n            lbl.set_scene(scene_idx)\n\n            label_images = []\n            label_names = []\n\n            # iterate through each channel in the label image\n            for label_chan in self._label_images.value:\n                label_chan = label_chan[8:]\n                label_names.append(label_chan)\n\n                lbl_C = lbl.channel_names.index(label_chan)\n                label = lbl.get_image_data(self._squeezed_dims, C=lbl_C)\n                label_images.append(label)\n\n            intensity_images = []\n            intensity_names = []\n\n            # id_string = helpers.create_id_string(lbl, file.stem)\n\n            # Get stack of intensity images if there are any selected\n            if self._intensity_images.value and not None:\n                for channel in self._intensity_images.value:\n                    if channel.startswith('Labels: '):\n                        chan = channel[8:]\n                        lbl_C = lbl.channel_names.index(chan)\n                        lbl.set_scene(scene_idx)\n                        inten_img = lbl.get_image_data(\n                            self._squeezed_dims, C=lbl_C\n                        )\n                    elif channel.startswith('Intensity: '):\n                        chan = channel[11:]\n                        img_C = img.channel_names.index(chan)\n                        img.set_scene(scene_idx)\n                        inten_img = img.get_image_data(\n                            self._squeezed_dims, C=img_C\n                        )\n                    elif channel.startswith('Region: '):\n                        chan = channel[8:]\n                        reg_C = reg.channel_names.index(chan)\n                        reg.set_scene(scene_idx)\n                        inten_img = reg.get_image_data(\n                            self._squeezed_dims, C=reg_C\n                        )\n                    intensity_names.append(chan)\n                    intensity_images.append(inten_img)\n\n                # the last dim is the multi-channel dim for regionprops\n                intensity_stack = np.stack(intensity_images, axis=-1)\n\n            else:\n                intensity_stack = None\n                intensity_names = None\n\n            # start the measuring here\n            # TODO: Add optional scaling, in case images have different scales?\n            measure_props_df = ndev_measure.measure_regionprops(\n                label_images=label_images,\n                label_names=label_names,\n                intensity_images=intensity_stack,\n                intensity_names=intensity_names,\n                properties=properties,\n                scale=props_scale,\n                id_string=id_string,\n                id_regex_dict=id_regex_dict,\n                tx_id=self._tx_id.value,\n                tx_dict=tx_dict,\n                tx_n_well=self._tx_n_well.value,\n                save_data_path=None,\n            )\n\n            measure_props_concat.append(measure_props_df)\n            self._progress_bar.value = idx + 1\n\n    measure_props_df = pd.concat(measure_props_concat)\n    labels_string = '_'.join(label_names)\n    save_loc = self._output_directory.value / f'measure_props_{labels_string}.csv'\n    measure_props_df.to_csv(save_loc, index=False)\n\n    logger.removeHandler(handler)\n\n    return measure_props_df\n</code></pre>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.group_measurements","title":"group_measurements","text":"<pre><code>group_measurements()\n</code></pre> <p>Group measurements based on user input.</p> <p>Uses the values in the Grouping Container of the Widget and passes them to the group_and_agg_measurements function in the measure module. The grouped measurements are saved to a CSV file in the same directory as the measured data with '_grouped' appended.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The grouped measurements as a DataFrame.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>def group_measurements(self):\n    \"\"\"\n    Group measurements based on user input.\n\n    Uses the values in the Grouping Container of the Widget and passes them\n    to the group_and_agg_measurements function in the measure module. The\n    grouped measurements are saved to a CSV file in the same directory as\n    the measured data with '_grouped' appended.\n\n    Returns\n    -------\n    pd.DataFrame\n        The grouped measurements as a DataFrame.\n\n    \"\"\"\n    from napari_ndev import measure as ndev_measure\n\n    self._progress_bar.label = 'Grouping Measurements'\n    self._progress_bar.value = 0\n    self._progress_bar.max = 1\n\n    df = pd.read_csv(self._measured_data_path.value)\n\n    # Filter out None values from agg_cols\n    agg_cols = [col for col in self._agg_cols.value if col is not None]\n\n    grouped_df = ndev_measure.group_and_agg_measurements(\n        df=df,\n        grouping_cols=self._grouping_cols.value,\n        count_col=self._count_col.value,\n        agg_cols=agg_cols,\n        agg_funcs=self._agg_funcs.value,\n    )\n    # use the label_name column to make the dataframe wider\n    if self._pivot_wider.value:\n        # get grouping calls without label name\n        index_cols = [col for col in self._grouping_cols.value if col != 'label_name']\n\n        # alternatively, pivot every values column that is not present in index or columns\n        value_cols = [col for col in grouped_df.columns if col not in self._grouping_cols.value]\n\n        pivot_df = grouped_df.pivot(\n            index=index_cols,\n            columns='label_name',\n            values=value_cols,\n        )\n        # # flatten the multiindex columns\n        # pivot_df.columns = [f'{col[1]}_{col[0]}' for col in pivot_df.columns]\n\n        # reset index so that it is saved in the csv\n        pivot_df.reset_index(inplace=True)\n\n        grouped_df = pivot_df\n\n    save_loc = (\n        self._measured_data_path.value.parent /\n        f'{self._measured_data_path.value.stem}_grouped.csv'\n    )\n    grouped_df.to_csv(save_loc, index=False)\n\n    self._progress_bar.value = 1\n    return grouped_df\n</code></pre>"},{"location":"api/widgets/workflow_widget/","title":"Workflow widget","text":""},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container","title":"napari_ndev.widgets._workflow_container","text":""},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer","title":"WorkflowContainer","text":"<p>               Bases: <code>Container</code></p> <p>Container class for managing the workflow functionality in napari-ndev.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>roots</code>               (<code>list</code>)           \u2013            <p>List of ComboBox widgets representing the workflow roots.</p> </li> <li> <code>_channel_names</code>               (<code>list</code>)           \u2013            <p>List of channel names extracted from the image data.</p> </li> <li> <code>_img_dims</code>               (<code>str</code>)           \u2013            <p>The dimensions of the image data.</p> </li> </ul> Widgets: <p>image_directory : FileEdit     Widget for selecting the image directory. result_directory : FileEdit     Widget for selecting the result directory. workflow_file : FileEdit     Widget for selecting the workflow file. _keep_original_images : CheckBox     Checkbox widget for specifying whether to keep original images. batch_button : PushButton     Button widget for triggering the batch workflow. _progress_bar : ProgressBar     Progress bar widget for displaying the progress of the workflow. _workflow_roots : Label     Label widget for displaying the workflow roots.</p> Events: <p>image_directory.changed : Signal     Signal emitted when the image directory is changed. workflow_file.changed : Signal     Signal emitted when the workflow file is changed. batch_button.clicked : Signal     Signal emitted when the batch button is clicked.</p> Source code in <code>src/napari_ndev/widgets/_workflow_container.py</code> <pre><code>class WorkflowContainer(Container):\n    \"\"\"\n    Container class for managing the workflow functionality in napari-ndev.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    Attributes\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n    roots : list\n        List of ComboBox widgets representing the workflow roots.\n    _channel_names : list\n        List of channel names extracted from the image data.\n    _img_dims : str\n        The dimensions of the image data.\n\n    Widgets:\n    --------\n    image_directory : FileEdit\n        Widget for selecting the image directory.\n    result_directory : FileEdit\n        Widget for selecting the result directory.\n    workflow_file : FileEdit\n        Widget for selecting the workflow file.\n    _keep_original_images : CheckBox\n        Checkbox widget for specifying whether to keep original images.\n    batch_button : PushButton\n        Button widget for triggering the batch workflow.\n    _progress_bar : ProgressBar\n        Progress bar widget for displaying the progress of the workflow.\n    _workflow_roots : Label\n        Label widget for displaying the workflow roots.\n\n    Events:\n    -------\n    image_directory.changed : Signal\n        Signal emitted when the image directory is changed.\n    workflow_file.changed : Signal\n        Signal emitted when the workflow file is changed.\n    batch_button.clicked : Signal\n        Signal emitted when the batch button is clicked.\n\n    \"\"\"\n\n    def __init__(self, viewer: napari.viewer.Viewer = None):\n        \"\"\"\n        Initialize the WorkflowContainer widget.\n\n        Parameters\n        ----------\n        viewer : napari.viewer.Viewer, optional\n            The napari viewer instance.\n\n        \"\"\"\n        super().__init__()\n        self.viewer = viewer if viewer is not None else None\n        self.roots = []\n        self._channel_names = []\n        self._img_dims = ''\n\n        self._init_widgets()\n        self._roots_container()\n        self._tasks_container()\n        self._init_layout()\n        self._connect_events()\n\n    def _init_widgets(self):\n        \"\"\"Initialize non-Container widgets.\"\"\"\n        self.image_directory = FileEdit(label='Image Directory', mode='d')\n        self.result_directory = FileEdit(label='Result Directory', mode='d')\n\n        self.workflow_file = FileEdit(\n            label='Workflow File',\n            filter='*.yaml',\n            tooltip='Select a workflow file to load',\n        )\n        self._keep_original_images = CheckBox(\n            label='Keep Original Images',\n            value=False,\n            tooltip='If checked, the original images will be '\n            'concatenated with the results',\n        )\n        self.batch_button = PushButton(label='Batch Workflow')\n\n        self._progress_bar = ProgressBar(label='Progress:')\n        self._workflow_roots = Label(label='Workflow Roots:')\n\n    def _roots_container(self):\n        \"\"\"Initialize the roots container.\"\"\"\n        self._roots_container = Container(layout='vertical')\n\n    def _tasks_container(self):\n        \"\"\"Initialize the tasks container.\"\"\"\n        self._tasks_container = Container(layout='vertical')\n\n        self._tasks_select = Select(\n            choices=[],\n            nullable=False,\n            allow_multiple=True,\n        )\n\n        self._tasks_container.append(self._tasks_select)\n\n    def _init_layout(self):\n        \"\"\"Initialize the layout of the widgets.\"\"\"\n        self.extend(\n            [\n                self.image_directory,\n                self.result_directory,\n                self.workflow_file,\n                self._keep_original_images,\n                self.batch_button,\n                self._progress_bar,\n                self._workflow_roots,\n            ]\n        )\n\n        tabs = QTabWidget()\n        tabs.addTab(self._roots_container.native, 'Roots')\n        tabs.addTab(self._tasks_container.native, 'Tasks')\n        self.native.layout().addWidget(tabs)\n\n    def _connect_events(self):\n        \"\"\"Connect the events of the widgets to respective methods.\"\"\"\n        self.image_directory.changed.connect(self._get_image_info)\n        self.workflow_file.changed.connect(self._get_workflow_info)\n        self.batch_button.clicked.connect(self.batch_workflow)\n\n    def _get_image_info(self):\n        \"\"\"Get channels and dims from first image in the directory.\"\"\"\n        self.image_dir, self.image_files = helpers.get_directory_and_files(\n            self.image_directory.value,\n        )\n        img = helpers.get_Image(self.image_files[0])\n\n        self._channel_names = helpers.get_channel_names(img)\n\n        for widget in self._roots_container:\n            widget.choices = self._channel_names\n\n        self._squeezed_img_dims = helpers.get_squeezed_dim_order(img)\n        return self._squeezed_img_dims\n\n    def _update_roots(self):\n        \"\"\"Get the roots from the workflow and update the ComboBox widgets.\"\"\"\n        self._roots_container.clear()\n\n        for idx, root in enumerate(self.workflow.roots()):\n            root_combo = ComboBox(\n                label=f'Root {idx}: {root}',\n                choices=self._channel_names,\n                nullable=True,\n                value=None,\n            )\n            self._roots_container.append(root_combo)\n            # self.append(root_combo)\n        return\n\n    def _update_task_choices(self, workflow):\n        \"\"\"Update the choices of the tasks with the workflow tasks.\"\"\"\n        self._tasks_select.choices = list(workflow._tasks.keys())\n        self._tasks_select.value = workflow.leafs()\n\n    def _get_workflow_info(self):\n        \"\"\"Load the workflow file and update the roots and leafs.\"\"\"\n        from napari_workflows._io_yaml_v1 import load_workflow\n\n        self.workflow = load_workflow(self.workflow_file.value)\n        self._workflow_roots.value = self.workflow.roots()\n        self._update_roots()\n        self._update_task_choices(self.workflow)\n        return\n\n    def batch_workflow(self):\n        \"\"\"Run the workflow on all images in the image directory.\"\"\"\n        import dask.array as da\n        from bioio.writers import OmeTiffWriter\n        from bioio_base import transforms\n\n        result_dir = self.result_directory.value\n        image_files = self.image_files\n        workflow = self.workflow\n\n        # get indexes of channel names, in case not all images have\n        # the same channel names, the index should be in the same order\n        root_list = [widget.value for widget in self._roots_container]\n        root_index_list = [self._channel_names.index(r) for r in root_list]\n\n        # Setting up Logging File\n        log_loc = result_dir / 'workflow.log.txt'\n        logger, handler = helpers.setup_logger(log_loc)\n        logger.info(\n            \"\"\"\n            Image Directory: %s\n            Result Directory: %s\n            Workflow File: %s\n            Roots: %s\n            Tasks: %s\n            \"\"\",\n            self.image_directory.value,\n            result_dir,\n            self.workflow_file.value,\n            root_list,\n            self._tasks_select.value,\n        )\n\n        self._progress_bar.label = f'Workflow on {len(image_files)} images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(image_files)\n\n        for idx_file, image_file in enumerate(image_files):\n            logger.info('Processing %d: %s', idx_file + 1, image_file.name)\n            img = helpers.get_Image(image_file)\n\n            root_stack = []\n            # get image corresponding to each root, and set it to the workflow\n            for idx, root_index in enumerate(root_index_list):\n                if 'S' in img.dims.order:\n                    root_img = img.get_image_data('TSZYX', S=root_index)\n                else:\n                    root_img = img.get_image_data('TCZYX', C=root_index)\n                # stack the TCZYX images for later stacking with results\n                root_stack.append(root_img)\n                # squeeze the root image for workflow\n                root_squeeze = np.squeeze(root_img)\n                # set the root image to the index of the root in the workflow\n                workflow.set(\n                    name=workflow.roots()[idx], func_or_data=root_squeeze\n                )\n\n            task_names = self._tasks_select.value\n            result = workflow.get(name=task_names)\n\n            result_stack = np.asarray(\n                result\n            )  # cle.pull stacks the results on the 0th axis as \"C\"\n            # transform result_stack to TCZYX\n            result_stack = transforms.reshape_data(\n                data=result_stack,\n                given_dims='C' + self._squeezed_img_dims,\n                return_dims='TCZYX',\n            )\n\n            if result_stack.dtype == np.int64:\n                result_stack = result_stack.astype(np.int32)\n\n            # &lt;- should I add a check for the result_stack to be a dask array?\n            # &lt;- should this be done using dask or numpy?\n            if self._keep_original_images.value:\n                dask_images = da.concatenate(root_stack, axis=1)  # along \"C\"\n                result_stack = da.concatenate(\n                    [dask_images, result_stack], axis=1\n                )\n                result_names = root_list + task_names\n            else:\n                result_names = task_names\n\n            OmeTiffWriter.save(\n                data=result_stack,\n                uri=result_dir / (image_file.stem + '.tiff'),\n                dim_order='TCZYX',\n                channel_names=result_names,\n                image_name=image_file.stem,\n                physical_pixel_sizes=img.physical_pixel_sizes,\n            )\n\n            self._progress_bar.value = idx_file + 1\n\n        logger.removeHandler(handler)\n        return\n</code></pre>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer.__init__","title":"__init__","text":"<pre><code>__init__(viewer=None)\n</code></pre> <p>Initialize the WorkflowContainer widget.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/widgets/_workflow_container.py</code> <pre><code>def __init__(self, viewer: napari.viewer.Viewer = None):\n    \"\"\"\n    Initialize the WorkflowContainer widget.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer, optional\n        The napari viewer instance.\n\n    \"\"\"\n    super().__init__()\n    self.viewer = viewer if viewer is not None else None\n    self.roots = []\n    self._channel_names = []\n    self._img_dims = ''\n\n    self._init_widgets()\n    self._roots_container()\n    self._tasks_container()\n    self._init_layout()\n    self._connect_events()\n</code></pre>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer.__init__(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer.batch_workflow","title":"batch_workflow","text":"<pre><code>batch_workflow()\n</code></pre> <p>Run the workflow on all images in the image directory.</p> Source code in <code>src/napari_ndev/widgets/_workflow_container.py</code> <pre><code>def batch_workflow(self):\n    \"\"\"Run the workflow on all images in the image directory.\"\"\"\n    import dask.array as da\n    from bioio.writers import OmeTiffWriter\n    from bioio_base import transforms\n\n    result_dir = self.result_directory.value\n    image_files = self.image_files\n    workflow = self.workflow\n\n    # get indexes of channel names, in case not all images have\n    # the same channel names, the index should be in the same order\n    root_list = [widget.value for widget in self._roots_container]\n    root_index_list = [self._channel_names.index(r) for r in root_list]\n\n    # Setting up Logging File\n    log_loc = result_dir / 'workflow.log.txt'\n    logger, handler = helpers.setup_logger(log_loc)\n    logger.info(\n        \"\"\"\n        Image Directory: %s\n        Result Directory: %s\n        Workflow File: %s\n        Roots: %s\n        Tasks: %s\n        \"\"\",\n        self.image_directory.value,\n        result_dir,\n        self.workflow_file.value,\n        root_list,\n        self._tasks_select.value,\n    )\n\n    self._progress_bar.label = f'Workflow on {len(image_files)} images'\n    self._progress_bar.value = 0\n    self._progress_bar.max = len(image_files)\n\n    for idx_file, image_file in enumerate(image_files):\n        logger.info('Processing %d: %s', idx_file + 1, image_file.name)\n        img = helpers.get_Image(image_file)\n\n        root_stack = []\n        # get image corresponding to each root, and set it to the workflow\n        for idx, root_index in enumerate(root_index_list):\n            if 'S' in img.dims.order:\n                root_img = img.get_image_data('TSZYX', S=root_index)\n            else:\n                root_img = img.get_image_data('TCZYX', C=root_index)\n            # stack the TCZYX images for later stacking with results\n            root_stack.append(root_img)\n            # squeeze the root image for workflow\n            root_squeeze = np.squeeze(root_img)\n            # set the root image to the index of the root in the workflow\n            workflow.set(\n                name=workflow.roots()[idx], func_or_data=root_squeeze\n            )\n\n        task_names = self._tasks_select.value\n        result = workflow.get(name=task_names)\n\n        result_stack = np.asarray(\n            result\n        )  # cle.pull stacks the results on the 0th axis as \"C\"\n        # transform result_stack to TCZYX\n        result_stack = transforms.reshape_data(\n            data=result_stack,\n            given_dims='C' + self._squeezed_img_dims,\n            return_dims='TCZYX',\n        )\n\n        if result_stack.dtype == np.int64:\n            result_stack = result_stack.astype(np.int32)\n\n        # &lt;- should I add a check for the result_stack to be a dask array?\n        # &lt;- should this be done using dask or numpy?\n        if self._keep_original_images.value:\n            dask_images = da.concatenate(root_stack, axis=1)  # along \"C\"\n            result_stack = da.concatenate(\n                [dask_images, result_stack], axis=1\n            )\n            result_names = root_list + task_names\n        else:\n            result_names = task_names\n\n        OmeTiffWriter.save(\n            data=result_stack,\n            uri=result_dir / (image_file.stem + '.tiff'),\n            dim_order='TCZYX',\n            channel_names=result_names,\n            image_name=image_file.stem,\n            physical_pixel_sizes=img.physical_pixel_sizes,\n        )\n\n        self._progress_bar.value = idx_file + 1\n\n    logger.removeHandler(handler)\n    return\n</code></pre>"},{"location":"examples/skimage_workflow/","title":"Skimage workflow","text":"In\u00a0[43]: Copied! <pre>import napari_segment_blobs_and_things_with_membranes as nsbatwm\nimport numpy as np\nimport stackview\nfrom bioio import BioImage\nfrom napari_workflows import Workflow\nfrom napari_workflows._io_yaml_v1 import load_workflow, save_workflow\n</pre> import napari_segment_blobs_and_things_with_membranes as nsbatwm import numpy as np import stackview from bioio import BioImage from napari_workflows import Workflow from napari_workflows._io_yaml_v1 import load_workflow, save_workflow  In\u00a0[53]: Copied! <pre>wf = Workflow()\n\nwf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1)\nwf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb')\nwf.set('membrane-label', nsbatwm.label, 'membrane-threshold')\n\nwf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1)\nwf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb')\nwf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')\n\nsave_workflow('cpu_workflow-2roots-2leafs.yaml', wf)\n</pre> wf = Workflow()  wf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1) wf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb') wf.set('membrane-label', nsbatwm.label, 'membrane-threshold')  wf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1) wf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb') wf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')  save_workflow('cpu_workflow-2roots-2leafs.yaml', wf)  In\u00a0[54]: Copied! <pre>wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')\n\nimg = BioImage(r'images\\cells3d2ch.tiff')\nmembrane = img.get_image_data('TCZYX', C=0)\nmembrane = np.squeeze(membrane)\n\nnuclei = img.get_image_data('TCZYX', C=1)\nnuclei = np.squeeze(nuclei)\n\nwf.set('membrane', membrane)\nwf.set('nucleus', nuclei)\nmembrane_label = wf.get('nucleus-label')\n\nstackview.imshow(membrane_label)\n</pre> wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')  img = BioImage(r'images\\cells3d2ch.tiff') membrane = img.get_image_data('TCZYX', C=0) membrane = np.squeeze(membrane)  nuclei = img.get_image_data('TCZYX', C=1) nuclei = np.squeeze(nuclei)  wf.set('membrane', membrane) wf.set('nucleus', nuclei) membrane_label = wf.get('nucleus-label')  stackview.imshow(membrane_label) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/measure/measure_widget/","title":"Measure Widget","text":"In\u00a0[3]: Copied! <pre>import napari\nfrom napari.utils import nbscreenshot\n\nviewer = napari.Viewer()\nviewer.window.resize(1000,700) # w x h\nviewer.window.add_plugin_dock_widget('napari-ndev', 'Measure Widget')\nnbscreenshot(viewer)\n</pre> import napari from napari.utils import nbscreenshot  viewer = napari.Viewer() viewer.window.resize(1000,700) # w x h viewer.window.add_plugin_dock_widget('napari-ndev', 'Measure Widget') nbscreenshot(viewer) <pre>WARNING: QWindowsWindow::setGeometry: Unable to set geometry 1920x1310+1280+550 (frame: 1942x1366+1269+505) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 2882x1968+1283+564 (frame: 2904x2024+1272+519) margins: 11, 45, 11, 11 minimum size: 385x492 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1040 maxtrack=0,0)\n21-Sep-24 11:32:12 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 1920x1310+1280+550 (frame: 1942x1366+1269+505) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 2882x1968+1283+564 (frame: 2904x2024+1272+519) margins: 11, 45, 11, 11 minimum size: 385x492 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1040 maxtrack=0,0)\n</pre> Out[3]: In\u00a0[4]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[4]: In\u00a0[5]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[5]: In\u00a0[6]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[6]: In\u00a0[7]: Copied! <pre>import pandas as pd\n\nraw_data = pd.read_csv(r'./data\\measure_props_Morphology.csv')\ndisplay(raw_data.shape)\nraw_data.head()\n</pre> import pandas as pd  raw_data = pd.read_csv(r'./data\\measure_props_Morphology.csv') display(raw_data.shape) raw_data.head() <pre>(1263, 12)</pre> Out[7]: id date HIC well scene label area intensity_max-DAPI Class row column chelation media 0 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 1 0.600632 0.0 H 9 100uM DFO NGM 1 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 2 0.246413 0.0 H 9 100uM DFO NGM 2 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 3 3.203368 0.0 H 9 100uM DFO NGM 3 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 4 0.308016 0.0 H 9 100uM DFO NGM 4 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 5 269.283163 1.0 H 9 100uM DFO NGM In\u00a0[8]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[8]: In\u00a0[9]: Copied! <pre>grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv')\ndisplay(grouped_data.shape)\ngrouped_data.head()\n</pre> grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv') display(grouped_data.shape) grouped_data.head() <pre>(25, 2)</pre> Out[9]: id label_count 0 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 16 1 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 14 2 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 40 3 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 20 4 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 14 In\u00a0[10]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[10]: In\u00a0[12]: Copied! <pre>grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv')\ndisplay(grouped_data.shape)\ngrouped_data\n</pre> grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv') display(grouped_data.shape) grouped_data <pre>(47, 8)</pre> Out[12]: id date HIC well scene intensity_max-DAPI Class label_count area_mean 0 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 0.0 15 9.641934 1 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 1.0 1 269.283163 2 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 B9 P8-B9 0.0 12 1.036988 3 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 B9 P8-B9 1.0 2 461.962697 4 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 C9 P8-C9 0.0 39 0.576938 5 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 C9 P8-C9 1.0 1 297.451244 6 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 A9 P4-A9 0.0 18 3.002302 7 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 A9 P4-A9 1.0 2 446.762097 8 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 D9 P8-D9 0.0 12 6.541494 9 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 D9 P8-D9 1.0 2 439.747028 10 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P4-E9 0.0 27 1.536659 11 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P4-E9 1.0 2 438.938486 12 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P3-E9 0.0 8 10.378221 13 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P3-E9 1.0 2 414.428097 14 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 G9 P8-G9 0.0 55 0.816803 15 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 G9 P8-G9 1.0 2 407.266720 16 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 H9 P20-H9 0.0 34 1.123353 17 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 H9 P20-H9 1.0 2 360.717772 18 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P6-C9 0.0 34 5.815165 19 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P6-C9 1.0 3 355.055407 20 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P7-C9 0.0 16 4.552864 21 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P7-C9 1.0 2 503.483281 22 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P6-D9 0.0 59 0.548948 23 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P6-D9 1.0 4 404.764088 24 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P10-D9 0.0 54 0.568119 25 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P10-D9 1.0 2 439.947239 26 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 E9 P7-E9 0.0 52 1.061767 27 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 E9 P7-E9 1.0 4 573.364456 28 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 F9 P11-F9 0.0 201 13.183400 29 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 F9 P11-F9 1.0 2 824.220550 30 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 H9 P4-H9 0.0 44 0.557229 31 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 H9 P4-H9 1.0 1 517.975443 32 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P6-B9 0.0 68 2.446237 33 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P6-B9 1.0 1 656.428725 34 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P8-B9 0.0 64 0.430741 35 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P8-B9 1.0 1 602.941711 36 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P7-B9 0.0 73 0.641138 37 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P7-B9 1.0 1 1369.917450 38 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 A9 P3-A9 0.0 48 1.359763 39 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 D9 P7-D9 0.0 26 31.638595 40 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 D9 P7-D9 1.0 1 443.882146 41 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 E9 P2-E9 0.0 7 1.095658 42 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 E9 P2-E9 1.0 2 446.831401 43 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 F9 P13-F9 0.0 36 0.533039 44 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 F9 P13-F9 1.0 1 736.743949 45 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 G9 P9-G9 0.0 56 5.597644 46 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 G9 P9-G9 1.0 2 789.691934"},{"location":"examples/measure/measure_widget/#measure-widget","title":"Measure Widget\u00b6","text":"<p>This page describes how to generate data outputs from measuring label images. Currently, labels are measured with <code>scikit-image.regionprops</code> and exported to a <code>.csv</code> file (which can be opened in any spreadsheet application or stats program). In addition, the user can specify two different sets of metadata to add additional information: 1) <code>ID Regex</code> which will parse information currently from the filename and the scene information; an example will be shown in <code>Example ID String</code>. 2) <code>Tx Map</code> can be used to add information based on a multi-well plate map. The <code>ID</code> mapped to is any column that can be created by <code>ID Regex</code> or the <code>Scene</code> information.</p> <p>In some ways, this widget is knowingly complex, however, it is certainly intended that a more advanced user can provide the proper <code>ID Regex</code> and <code>Tx Map</code> for a user for the experiments, and in the end create a summarized dataset. While the measure widget initially spits out a raw data file which will contain more rows than most datasets you are familiar with, since it is in 'long' format. In other words, each row represents a single object.</p> <p>Thus, to summarize your data on any measure of summary that you would like, use the <code>Grouping</code> tab and select the unique identifiers to summarize by. You will then select a column to <code>Count</code> which will tell you the number of labels in that group. Optionally, you can add <code>Aggregation Columns</code> to summarize all selected columns by the selected aggregation functions. For example, you may wish to know the <code>mean area</code> of all objects in your groups.</p>"},{"location":"examples/measure/measure_widget/#example-folder","title":"Example folder\u00b6","text":"<p>The only required directory is the <code>label directory</code> whereby the objects that you want to measure are found. You should also select/make an <code>output directory</code> so that you know where your file is saved.</p> <p>Once you select the <code>label directory</code>, label names will populate both the <code>label image</code> dropdown and <code>intensity images</code>. The only required selection is a <code>label image</code> once this is done, you can hit the <code>Measure</code> button and will get the most minimal dataset possible.</p> <p>However, you can also add other intensity images (by loading an image or region directory, the reasoning for these namings will come in future tutorials) and select them in the widget to be measured against. Then, in <code>Region Props</code> tab you can select additional properties to measure.</p> <p>In this example I want to measure the <code>intensity max</code> of the corresponding <code>Labels: DAPI Class</code> because this will give me the 'type' of DAPI that is inside each <code>Morphology</code> object. This is because the background is 0, live is 1, and dead is 2. So, we can later filter by the 'DAPI Class' of each morphology object. In other words, intensity images don't have to be raw intensity values, but other labels can be used.</p>"},{"location":"examples/measure/measure_widget/#id-regex","title":"ID Regex\u00b6","text":"<p>In this example, one such ID string is: <code>'2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 488 DAPI OBL_107_106_P1-H9.ome__0__Image:0'</code> From here, I can extract multiple different bits of information, which is why saving interesting metadata into filenames can be useful. This needs to be a dictionary, where each key represents a column, and the value for that key is the regex (regular expression) pattern used to extract that information. The only quirk (besides regex) is that there must be at least 1 'group' aka a pattern surrounded by parenetheses. This pattern surrounded by parentheses is what will be saved into the column. As such, there can be extra regex that isn't kept, but can be used to locate the pattern.</p> <pre><code>{\n    'scene': r'(P\\d{1,3}-\\w+).ome',\n    'well': r'-(\\w+).ome',\n    'HIC': r'(\\d{1,3})HIC',\n    'date': r'(\\d{4}-\\d{2}-\\d{2})',\n}\n</code></pre>"},{"location":"examples/measure/measure_widget/#tx-map","title":"Tx Map\u00b6","text":"<p>This section uses <code>napari_ndev:PlateMapper</code>. It is currently only set up to be used with typical culture plate dimensions, but will hopefully be updated in the future to be flexible to arbitrary patterns, so that a <code>Treatment ID</code> can include something like slide or section information that can then be mapped to treatments or positions of some kind. First, press the <code>Update Treatment ID Choices</code> to read possibilities from the <code>ID Regex</code> container. In the <code>treatment ID</code>, select the name of the column with the ID in it, which will usually be obtained from <code>ID Regex</code>, for this example it is 'well'.</p> <p>Then, select the number of wells for your plate, to automatically make a plate in the typical layout. For example, a 96-well plate would automatically map a A-H (8 row) plate with 12 columns.</p> <p>For now, you provide lists of strings with ranges representing wells on a plate. For <code>PlateMapper</code> provide a dictionary, where each key represents a column header, and then the value-dictionary has a key which is what will get mapped to the matching well-value. For example:</p> <pre><code>{\n  'chelation':{\n    'Control': ['B1:C12'],\n    '50uM DFP': ['D1:E12'],\n    '100uM DFP': ['F1:G12'],\n    '100uM DFO': ['A1:A12', 'H1:H12'],\n  },\n  'media':{\n    'NGM': ['A1:H12'],\n  }\n}\n</code></pre>"},{"location":"examples/measure/measure_widget/#finally-measure","title":"Finally, Measure\u00b6","text":"<p>At any point once minimal selections were made, you could click the <code>Measure</code> button and it will measure all the labels in batch, and save the results to the output directory.</p>"},{"location":"examples/measure/measure_widget/#grouping-data","title":"Grouping Data!\u00b6","text":"<p>After acquiring your dataset, you may be interested in processing it further with the <code>Grouping</code> tab. This will reduce it from many rows, to much fewer. This example before has 1263 rows and 12 columns.</p>"},{"location":"examples/measure/measure_widget/#using-the-grouping-tab","title":"Using the Grouping Tab\u00b6","text":"<p>Load in your raw data of interest, and it will populate all the possible column names. Minimally, select grouping columns and the count column. For example, if I want to group by every 'id' (i.e. filename, with scene info) I would be able to leave the default values.</p>"},{"location":"examples/measure/measure_widget/#advanced-grouping","title":"Advanced grouping\u00b6","text":"<p>However, you will note that now only the 'id' and 'label_count' columns are present. If I instead wanted to keep all that careful metadata I extracted earlier, I would also want to select other grouping data, such as id, date, HIC, well, and scene, and 'intensity_max-DAPI Class' which represents the type of cell present.</p> <p>And I could also select a column to aggregate, such as getting the 'mean' of the 'area' for each of these groups. Remember, if you keep the 'id' then minimally each file will get summarized. To have a more general summary (which would not typically be recommended), do not use 'id'.</p>"},{"location":"examples/measure/measure_widget/#interpreting-the-results","title":"Interpreting the results\u00b6","text":"<p>Now, you should be able to place this easily into your stats program of choice (mine is using Python!). Note how we have shown in the first image that there are 15 labels with a DAPI class of zero, meaning that this label does not contain a nucleus and there is 1 label with a DAPI Class of 1 (meaning that it is alive, based on a previous classifier employed with APOC Widget). This also shows for example that the <code>area_mean</code> is larger for an alive cell, compared to whatever debris there must be that doesn't have a nucleus.</p> <p>This is also useful for grouping your data to double check that the results intuitively make sense. You should also make sure to check through your labels. You can try <code>napari-ndev:ImageOverview</code> for that. It will be added to the widgets soon, to quickly have overview .png files to scroll through on any system.</p>"},{"location":"examples/utilities/image_utilities/","title":"Image Utilities","text":"In\u00a0[1]: Copied! <pre>import pathlib\n\nimport napari\nfrom napari.utils import nbscreenshot\n\nparent = pathlib.Path.cwd().parent\nrel_path = 'images/cropped_neuron.ome.tiff'\n\nviewer = napari.Viewer()\nviewer.window.resize(1500, 800) # w x h\nviewer.window.add_plugin_dock_widget('napari-ndev', 'Image Utilities')\nviewer.open(parent / rel_path, plugin='napari-bioio')\n\nnbscreenshot(viewer)\n</pre> import pathlib  import napari from napari.utils import nbscreenshot  parent = pathlib.Path.cwd().parent rel_path = 'images/cropped_neuron.ome.tiff'  viewer = napari.Viewer() viewer.window.resize(1500, 800) # w x h viewer.window.add_plugin_dock_widget('napari-ndev', 'Image Utilities') viewer.open(parent / rel_path, plugin='napari-bioio')  nbscreenshot(viewer) Out[1]: In\u00a0[2]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[2]: In\u00a0[3]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[3]: In\u00a0[4]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[4]:"},{"location":"examples/utilities/image_utilities/#image-utilities","title":"Image Utilities\u00b6","text":"<p>This example will describe how to manage metadata, crop, and annotate images with the Image Utilities widget. The widget can be opened from <code>Plugins --&gt; neuralDev --&gt; Image Utilities</code>. To crop layers in the viewer, open <code>Plugins --&gt; crop region (napari_crop)</code>. Below, we load napari and open the Image Utilities Widget and load in a large image originally saved with the widget from a multi-scene CZI file. Note that currently no metadata populates the widget because the file was not selected with <code>Select Files</code>. Instead, the image was opened with the <code>napari-bioio</code> plugin; however, the metadata is saved and could normally be accessed from <code>viewer.layers[n].metadata['bioimage']</code>.</p> <p>To access metadata from any image in the viewer, press the <code>Selected Layer</code> button in the <code>Update Metadata from:</code> box.</p>"},{"location":"examples/utilities/image_utilities/#update-metadata-from-layer","title":"Update Metadata from layer\u00b6","text":"<p>Now both Channel Name(s) and the Scale is shown</p>"},{"location":"examples/utilities/image_utilities/#updating-metadata-automatically-with-widget-file-selection","title":"Updating Metadata Automatically with Widget File Selection\u00b6","text":"<p>Select one or multiple files which could be opened into the viewer, but these files do not have to be in order to be saved.</p> <p>To turn off auto metadata update on file selection uncheck <code>Update Metadata</code>. You may open the image (which will attempt to use <code>napari-aicsimageio</code>, if it exists, otherwise a different compatible reader) or <code>Select Next</code> and it will iterate to the next alpha-numerically sorted filename(s) matching the current number that are open.</p>"},{"location":"examples/utilities/image_utilities/#concatenating-files-and-saving-layers","title":"Concatenating Files and Saving Layers\u00b6","text":"<p><code>Concatenate Files</code> checkbox below allows saving of image data as OME-TIFF without empty channels. This could be useful if your microscope saves images as RGB with empty channels. Alternatively, if <code>Concatenate Layers</code> is checked then it will combine any layers selected in the left panel <code>layer list</code> of napari. Having both checked will stack the select file path with any select viewer layers, which could be useful if you wanted to process images and then combine with the original.</p> <p>All metadata is passed from the widget to <code>bioio.writers.OmeTiffWriter</code> to keep metadata and is used by all other widgets of the plugin.</p>"},{"location":"examples/utilities/image_utilities/#quick-annotation","title":"Quick Annotation\u00b6","text":"<p>Both the Shapes and Labels layers can be quickly drawn on to your image to annotate in whatever way suits your needs. Then, when the layer you want is selected hit the button in the widget to save your image, layer, or shape (which will be converted to a scaled label). Each 'Shape' will also get a corresponding label, allowing multi-ROI consistency across images.</p>"},{"location":"examples/utilities/image_utilities/#utilizing-shapes-for-future-annotations","title":"Utilizing Shapes for future annotations\u00b6","text":"<p>In order to re-use Shapes for future annotations (akin to an ImageJ/FIJI ROI), go to <code>File -&gt; Save Selected Layer</code> and save the Shapes layer as a .CSV. When you load this .csv back into napari it will always load with a scale of (1.0,1.0,1.0) and you will thus need to select the shapes layer and <code>Scale Layer(s)</code> using the widget to re-size your annotation to the expected size.</p>"},{"location":"examples/workflow/workflow_napari-assistant/","title":"Generating workflows with napari","text":"In\u00a0[1]: Copied! <pre>import napari\nfrom napari.utils import nbscreenshot\n\nviewer = napari.Viewer()\nviewer.window.resize(1000, 700) # w x h\nviewer.window.add_plugin_dock_widget('napari-assistant')\nviewer.open_sample('napari', 'human_mitosis')\nnbscreenshot(viewer)\n</pre> import napari from napari.utils import nbscreenshot  viewer = napari.Viewer() viewer.window.resize(1000, 700) # w x h viewer.window.add_plugin_dock_widget('napari-assistant') viewer.open_sample('napari', 'human_mitosis') nbscreenshot(viewer) Out[1]: <pre>2024-09-15 23:13:22.581 | INFO     | napari_assistant._gui._category_widget:call_op:178 - gaussian_blur (clesperanto)(..., 1.0, 1.0, 0.0)\n2024-09-15 23:13:25.405 | INFO     | napari_assistant._gui._category_widget:call_op:178 - median_sphere (clesperanto)(..., 1.0, 1.0, 0.0)\n2024-09-15 23:13:26.324 | INFO     | napari_assistant._gui._category_widget:call_op:178 - top_hat_box (clesperanto)(..., 10.0, 10.0, 0.0)\n2024-09-15 23:13:27.501 | INFO     | napari_assistant._gui._category_widget:call_op:178 - voronoi_otsu_labeling (clesperanto)(..., 2.0, 2.0)\n</pre> In\u00a0[2]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[2]:"},{"location":"examples/workflow/workflow_napari-assistant/#generating-workflows-with-napari","title":"Generating workflows with napari\u00b6","text":"<p>This page describes how to generate custom workflows using napari using the calculator-like interface from <code>napari-assistant</code>. In many ways, this should be reminiscent of using the <code>Macro Recorder</code> in FIJI/ImageJ, but you will hopefully find it has more flexibility and advantages. Ultimately, our goal is to easily reproduce image processing steps with a <code>napari-workflows</code> <code>.yaml</code> file and utilize it for batch processing with <code>napari-ndev:Workflow Widget</code>.</p>"},{"location":"examples/workflow/workflow_napari-assistant/#napari-assistant","title":"napari-assistant\u00b6","text":"<p>In order to generate workflows with napari, you may like to <code>pip install napari-ndev[extra-plugins]</code> to install the napari-assistant and other cooperating plugins. You can then access the assistant via the <code>Plugins menu -&gt; Assistant (clesperanto)</code></p> <p>A thorough tutorial on how to use napari-assistant, including video, can be found here. The assistant is quite flexible and both functions and parameters are modifiable on-the-fly, but can be overall quirky at times.</p>"},{"location":"examples/workflow/workflow_napari-assistant/#apply-processing-steps","title":"Apply processing steps\u00b6","text":"<p>With the napari-assistant, I've selected the 'nuclei' layer and do a few processing steps to label the image. This is flexible for 3D images as well, because napari-workflow will save the 2D or 3D parameters as necessary.</p>"},{"location":"examples/workflow/workflow_napari-assistant/#save-the-workflow-file","title":"Save the workflow file\u00b6","text":"<p>Using the 2nd from the lower right button, <code>save and load workflows</code> -&gt; export workflow to file. I have named this <code>viewer-segment-nuclei-sample.yaml</code> into the resources folder in the docs library, but you should save it wherever you want to keep it in your project.</p>"},{"location":"examples/workflow/workflow_scripting/","title":"Scripting a Workflow","text":"In\u00a0[\u00a0]: Copied! <pre>import napari_segment_blobs_and_things_with_membranes as nsbatwm\nimport numpy as np\nimport stackview\nfrom bioio import BioImage\nfrom napari_workflows import Workflow\nfrom napari_workflows._io_yaml_v1 import load_workflow, save_workflow\n</pre> import napari_segment_blobs_and_things_with_membranes as nsbatwm import numpy as np import stackview from bioio import BioImage from napari_workflows import Workflow from napari_workflows._io_yaml_v1 import load_workflow, save_workflow  In\u00a0[\u00a0]: Copied! <pre>wf = Workflow()\n\nwf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1)\nwf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb')\nwf.set('membrane-label', nsbatwm.label, 'membrane-threshold')\n\nwf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1)\nwf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb')\nwf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')\n\nsave_workflow('cpu_workflow-2roots-2leafs.yaml', wf)\n</pre> wf = Workflow()  wf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1) wf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb') wf.set('membrane-label', nsbatwm.label, 'membrane-threshold')  wf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1) wf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb') wf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')  save_workflow('cpu_workflow-2roots-2leafs.yaml', wf)  In\u00a0[\u00a0]: Copied! <pre>wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')\n\nimg = BioImage(r'images\\cells3d2ch.tiff')\nmembrane = img.get_image_data('TCZYX', C=0)\nmembrane = np.squeeze(membrane)\n\nnuclei = img.get_image_data('TCZYX', C=1)\nnuclei = np.squeeze(nuclei)\n\nwf.set('membrane', membrane)\nwf.set('nucleus', nuclei)\nmembrane_label = wf.get('nucleus-label')\n\nstackview.imshow(membrane_label)\n</pre> wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')  img = BioImage(r'images\\cells3d2ch.tiff') membrane = img.get_image_data('TCZYX', C=0) membrane = np.squeeze(membrane)  nuclei = img.get_image_data('TCZYX', C=1) nuclei = np.squeeze(nuclei)  wf.set('membrane', membrane) wf.set('nucleus', nuclei) membrane_label = wf.get('nucleus-label')  stackview.imshow(membrane_label)"},{"location":"examples/workflow/workflow_scripting/#scripting-a-workflow","title":"Scripting a Workflow\u00b6","text":""},{"location":"examples/workflow/workflow_widget/","title":"Workflow Widget","text":""},{"location":"examples/workflow/workflow_widget/#workflow-widget","title":"Workflow Widget\u00b6","text":"<p>The napari-ndev Workflow widgets</p>"}]}