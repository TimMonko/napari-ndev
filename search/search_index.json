{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>A collection of widgets intended to serve any person seeking to process microscopy images from start to finish. The wide breadth of this plugin's scope is only made possible by the amazing libraries and plugins from the napari community, especially Robert Haase. Currently, the plugin supports the following goals:</p> <ol> <li>Batch-utilities: Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. </li> <li>Batch-workflow: Batch pre-processing/processing images using napari-workflows.</li> <li>Annotation-saver: A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders.</li> <li>Batch-training/prediction: Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting.</li> </ol>"},{"location":"#further-info","title":"Further Info","text":""},{"location":"#1-batch-utilities","title":"1. Batch-utilities","text":"<p>Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. To be added: alternative projection types, slicing in T, and compatability with non TCZYX images (but this is not a priority since aicsimageio currently always extracts images as TCZYX even if a dim is only length 1. </p>"},{"location":"#2-batch-workflow","title":"2. Batch-workflow","text":"<p>Batch pre-processing/processing images using napari-workflows.  Images are processed outside the napari-viewer using aicsimageio as both reader and writer. Prior to passing the images to napari-workflows, the user selects the correct images as the roots (inputs) and thus napari-workflows matches the processing to create the outputs. The advantage of using napari-workflows for batch processing is that it provides an incredibly flexible processing interface without writing a novel widget for small changes to processing steps like specific filters, segmentation, or measurements. Currently only intended for use with images as inputs and images as outputs from napari-workflows, though there is future potential to have other outputs possible, such as .csv measurement arrays.</p>"},{"location":"#3-annotation-saver","title":"3. Annotation-saver","text":"<p>A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders. Requires that images are opened with napari-aicsimageio--which can be as simple as drag and drop opening by setting the appropriate default reader for each file type in Preferences -&gt; Plugins--in order to utilize the metadata present for saving the image-label pairs. (See Note about AICSImageIO)</p> <p>Intended to be used with apoc batch-training/prediction, but can be used for any napari widget or other script intended to grab corresponding images from folders for batch processing.</p>"},{"location":"#4-batch-trainingprediction","title":"4. Batch-training/prediction","text":"<p>Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting. Recognizes pre established</p>"},{"location":"#a-note-about-aicsimageio","title":"A Note about AICSImageIO","text":"<p>AICSImageIO is a convenient, multi-format file reader which also has the complimentary napari-aicsimageio reader plugin. By default, napari-aicsimageio installs all reader dependencies. Because napari-aicsimageio is not technically required for this plugin to work (you could build your own metadata for the annotation-saver) and just napari-aicsimage is required, the former is not an install requirement. This is to avoid using the GPL liscence and to stick with BSD-3. However, you should install napari-aicsimageio if you want the smoothest operation of the annotation-saver.</p>"},{"location":"installation/","title":"Installation","text":"<p>You can install <code>napari-ndev</code> via <code>pip</code>:</p> <pre><code>pip install napari-ndev\n</code></pre>"},{"location":"widget_reference/annotation_saver/","title":"annotation_saver","text":"<p>Annotation Saver</p> <p>Used for annotating images and saving images of interest into a folder for the image and a folder for the labels. The GUI allows selecting of the intended label layer and image layer, as well as the prefix for the output folders. These output folders can already exist: mkdir(exist_ok=True), so should be used to save multiple images within the same folder group. Images are saved as ome.tif  with aicsimageio.OmeTiffWriter</p>"},{"location":"widget_reference/annotation_saver/#napari_ndev._widget.annotation_saver--parameters","title":"Parameters","text":"napari.layers.layers.Image <p>Image layer to save</p> napari.layers.layers.Labels <p>Labels layer (annotation) to save</p> pathlib.Path <p>Top-level folder where separate image and labels folders are present</p> str <p>Prefix to _images or _labels folder created in <code>file_directory</code>, by default \"Annotated\"</p> str <p>File ending can be changed if needed for interoperability, but still  saves as an OME-TIFF with aicsimageio.OmeTiffWriter, by default \"ome.tif\"</p>"},{"location":"widget_reference/annotation_saver/#napari_ndev._widget.annotation_saver--returns","title":"Returns","text":"<p>str     Message of \"saved\" and the respective image name</p> Source code in <code>src\\napari_ndev\\_widget.py</code> <pre><code>@magic_factory(\n    auto_call=False,\n    result_widget=True,\n    call_button=\"Save Layers to Output Folders\",\n    file_directory=dict(\n        widget_type=\"FileEdit\", mode=\"d\", label=\"File Directory\"\n    ),\n    output_folder_prefix=dict(widget_type=\"LineEdit\", label=\"Output Folder\"),\n    save_suffix=dict(widget_type=\"LineEdit\", label=\"Save Suffix\"),\n)\ndef annotation_saver(\n    image: layers.Image,\n    labels: layers.Labels,\n    file_directory=pathlib.Path(),\n    output_folder_prefix=\"Annotated\",\n    save_suffix=\".ome.tif\",\n):\n\"\"\"Annotation Saver\n\n    Used for annotating images and saving images of interest into a\n    folder for the image and a folder for the labels. The GUI allows\n    selecting of the intended label layer and image layer, as well as\n    the prefix for the output folders. These output folders can already\n    exist: mkdir(exist_ok=True), so should be used to save multiple\n    images within the same folder group. Images are saved as ome.tif \n    with aicsimageio.OmeTiffWriter\n\n    Parameters\n    ----------\n    image : napari.layers.layers.Image\n        Image layer to save\n    labels : napari.layers.layers.Labels\n        Labels layer (annotation) to save\n    file_directory : pathlib.Path\n        Top-level folder where separate image and labels folders are present\n    output_folder_prefix : str\n        Prefix to _images or _labels folder created in `file_directory`,\n        by default \"Annotated\"\n    save_suffix : str \n        File ending can be changed if needed for interoperability, but still \n        saves as an OME-TIFF with aicsimageio.OmeTiffWriter,\n        by default \"ome.tif\"\n\n    Returns\n    -------\n    str\n        Message of \"saved\" and the respective image name\n    \"\"\"\n\n    def _format_filename(char_string):\n\"\"\"convert strings to valid file names\"\"\"\n        valid_chars = f\"-_.() {string.ascii_letters}{string.digits}\"\n        filename = \"\".join(char for char in char_string if char in valid_chars)\n        filename = filename.replace(\" \", \"_\")\n        return filename\n\n    def _save_path(folder_suffix, save_suffix_str):\n\"\"\"Create save directories and return the path to save a file\"\"\"\n        folder_name = str(output_folder_prefix + folder_suffix)\n        save_directory = file_directory / folder_name\n        save_directory.mkdir(parents=False, exist_ok=True)\n\n        image_name = str(image.name + save_suffix_str)\n        save_name = _format_filename(image_name)\n        save_path = save_directory / save_name\n        return save_path\n\n\"\"\"save image\"\"\"\n    img_path = _save_path(\"_images\", save_suffix)\n    img = image.metadata[\"aicsimage\"]\n    OmeTiffWriter.save(\n        data=img.data,\n        uri=img_path,\n        dim_order=img.dims.order,\n        channel_names=img.channel_names,\n        physical_pixel_sizes=img.physical_pixel_sizes,\n    )\n\n\"\"\"save label\"\"\"\n    lbl_path = _save_path(\"_labels\", save_suffix)\n    lbl_dims = _get_img_dims(img)\n    lbl = labels.data\n    lbl = lbl.astype(np.int32)\n    OmeTiffWriter.save(\n        data=lbl,\n        uri=lbl_path,\n        dim_order=lbl_dims,\n        channel_names=[\"Labels\"],\n        physical_pixel_sizes=img.physical_pixel_sizes,\n    )\n\n    return \"Saved: \" + image.name\n</code></pre>"},{"location":"widget_reference/batch_predict/","title":"batch_predict","text":"<p>Train APOC (Accelerated-Pixel-Object-Classifiers) on a folder of images and labels.</p>"},{"location":"widget_reference/batch_predict/#napari_ndev._widget.batch_predict--parameters","title":"Parameters","text":"pathlib.Path <p>Location of images</p> pathlib.Path <p>Location to save output labels</p> pathlib.Path <p>Location of apoc classifier \".cl\" file</p> str, optional <p>Choose between Pixel or Object Classifier, by default Pixel Classifier</p> list <p>Select channels to pass into the classifier to serve as bases for features, by default []</p> int, optional <p>Label id number if using Object Classifier for <code>cl_type</code>, by default 2</p> str, optional <p>Image dimensions read from aicsimageio metadata, by default None</p>"},{"location":"widget_reference/batch_predict/#napari_ndev._widget.batch_predict--returns","title":"Returns","text":"<p>None     Predicted labels saved to <code>result_directory</code></p>"},{"location":"widget_reference/batch_predict/#napari_ndev._widget.batch_predict--notes","title":"Notes","text":"Accelerated pixel object classifier information from <p>https://github.com/haesleinhuepf/apoc</p> Source code in <code>src\\napari_ndev\\_widget.py</code> <pre><code>@magic_factory(\n    widget_init=init_predict,\n    auto_call=False,\n    call_button=\"Batch Predict\",\n    image_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    result_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    cl_path=dict(widget_type=\"FileEdit\", mode=\"r\"),\n    cl_type=dict(widget_type=\"RadioButtons\", choices=cl_types),\n    channel_list=dict(widget_type=\"Select\", choices=[]),\n)\ndef batch_predict(\n    image_directory=pathlib.Path(),\n    result_directory=pathlib.Path(),\n    cl_path=pathlib.Path(),\n    cl_type: str = cl_types[0],\n    channel_list: str = [],\n    img_dims: str = None,\n):\n\"\"\"Train APOC (Accelerated-Pixel-Object-Classifiers) on a folder of\n    images and labels.\n\n    Parameters\n    ----------\n    image_directory : pathlib.Path\n        Location of images\n    result_directory : pathlib.Path\n        Location to save output labels\n    cl_path : pathlib.Path\n        Location of apoc classifier \".cl\" file\n    cl_type : str, optional\n        Choose between Pixel or Object Classifier, by default Pixel Classifier\n    channel_list : list\n        Select channels to pass into the classifier to serve as bases for features, by default []\n    cl_label_id : int, optional\n        Label id number if using Object Classifier for `cl_type`, by default 2\n    img_dims : str, optional\n        Image dimensions read from aicsimageio metadata, by default None\n\n    Returns\n    -------\n    None\n        Predicted labels saved to `result_directory`\n\n    Notes\n    -----\n    Accelerated pixel object classifier information from:\n        https://github.com/haesleinhuepf/apoc\n    \"\"\"\n    image_list = os.listdir(image_directory)\n\n    if cl_type == \"Pixel\":\n        custom_classifier = apoc.PixelClassifier(opencl_filename=cl_path)\n    if cl_type == \"Object\":\n        custom_classifier = apoc.ObjectSegmenter(opencl_filename=cl_path)\n\n    for file in tqdm(image_list, label=\"progress\"):\n        image_stack = []\n        img = AICSImage(image_directory / file)\n\n        for channels in channel_list:\n            ch_img = _get_channel_image(\n                img=img, dims=img_dims, channel=channels\n            )\n            image_stack.append(ch_img)\n\n        dask_stack = da.stack(image_stack, axis=0)\n        result = custom_classifier.predict(\n            image=dask_stack,\n        )\n\n        lbl = cle.pull(result)\n        lbl = lbl.astype(np.int32)\n        OmeTiffWriter.save(\n            data=lbl,\n            uri=result_directory / file,\n            dim_order=img_dims,\n            channel_names=[\"Labels\"],\n            physical_pixel_sizes=img.physical_pixel_sizes,\n        )\n    return\n</code></pre>"},{"location":"widget_reference/batch_training/","title":"batch_training","text":"<p>Train APOC (Accelerated-Pixel-Object-Classifiers) on a folder of images and labels.</p>"},{"location":"widget_reference/batch_training/#napari_ndev._widget.batch_training--parameters","title":"Parameters","text":"pathlib.Path <p>Location of images</p> pathlib.Path <p>Location of labels (annotations)</p> pathlib.Path <p>Location to save apoc classifier \".cl\" file</p> str, optional <p>Filename to save apoc classifier, end with \".cl\", by default \"classifier.cl\"</p> str, optional <p>Choose between Pixel or Object Classifier, by default Pixel Classifier</p> int, optional <p>Number of random forests, by default 2</p> int, optional <p>Number of trees, by default 100</p> str, optional <p>Allows selection of <code>apoc.PredefinedFeatureSets</code>, by default custom, requires input of <code>custom_features</code></p> str, optional <p>Space-separated string of pyclesperanto filters, by default None</p> list <p>Select channels to pass into the classifier to serve as bases for features, by default []</p> int, optional <p>Label id number if using Object Classifier for <code>cl_type</code>, by default 2</p> str, optional <p>Image dimensions read from aicsimageio metadata, by default None</p>"},{"location":"widget_reference/batch_training/#napari_ndev._widget.batch_training--returns","title":"Returns","text":"<p>str     String of feature importances returned in classifier file</p>"},{"location":"widget_reference/batch_training/#napari_ndev._widget.batch_training--notes","title":"Notes","text":"Accelerated pixel object classifier information from <p>https://github.com/haesleinhuepf/apoc</p> <p>Predefined features from https://github.com/haesleinhuepf/apoc/blob/main/demo/feature_stacks.ipynb</p> Source code in <code>src\\napari_ndev\\_widget.py</code> <pre><code>@magic_factory(\n    widget_init=init_training,\n    auto_call=False,\n    call_button=\"Batch Train\",\n    result_widget=True,\n    image_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    label_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    cl_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    cl_type=dict(widget_type=\"RadioButtons\", choices=cl_types),\n    predefined_features=dict(widget_type=\"ComboBox\", choices=PDFS),\n    channel_list=dict(widget_type=\"Select\", choices=[]),\n    cl_label_id=dict(widget_type=\"SpinBox\", min=1),\n)\ndef batch_training(\n    image_directory=pathlib.Path(),\n    label_directory=pathlib.Path(),\n    cl_directory=pathlib.Path(),\n    cl_filename: str = \"classifier.cl\",\n    cl_type: str = cl_types[0],\n    cl_forests: int = 2,\n    cl_trees: int = 100,\n    predefined_features=PDFS(1),\n    custom_features: str = None,\n    channel_list: str = [],\n    cl_label_id: int = 2,\n    img_dims: str = None,\n):\n\"\"\"Train APOC (Accelerated-Pixel-Object-Classifiers) on a folder of\n    images and labels.\n\n    Parameters\n    ----------\n    image_directory : pathlib.Path\n        Location of images\n    label_directory : pathlib.Path\n        Location of labels (annotations)\n    cl_directory : pathlib.Path\n        Location to save apoc classifier \".cl\" file\n    cl_filename : str, optional\n        Filename to save apoc classifier, end with \".cl\", by default \"classifier.cl\"\n    cl_type : str, optional\n        Choose between Pixel or Object Classifier, by default Pixel Classifier\n    cl_forests : int, optional\n        Number of random forests, by default 2\n    cl_trees : int, optional\n        Number of trees, by default 100\n    predefined_features : str, optional\n        Allows selection of `apoc.PredefinedFeatureSets`, by default custom, requires input of `custom_features`\n    custom_features : str, optional\n        Space-separated string of pyclesperanto filters, by default None\n    channel_list : list\n        Select channels to pass into the classifier to serve as bases for features, by default []\n    cl_label_id : int, optional\n        Label id number if using Object Classifier for `cl_type`, by default 2\n    img_dims : str, optional\n        Image dimensions read from aicsimageio metadata, by default None\n\n    Returns\n    -------\n    str\n        String of feature importances returned in classifier file\n\n    Notes\n    -----\n    Accelerated pixel object classifier information from: \n        https://github.com/haesleinhuepf/apoc\n    Predefined features from https://github.com/haesleinhuepf/apoc/blob/main/demo/feature_stacks.ipynb\n    \"\"\"\n    image_list = os.listdir(image_directory)\n\n    cl_path = str(cl_directory / cl_filename)\n\n    apoc.erase_classifier(cl_path)\n\n    if cl_type == \"Pixel\":\n        custom_classifier = apoc.PixelClassifier(\n            opencl_filename=cl_path,\n            max_depth=cl_forests,\n            num_ensembles=cl_trees,\n        )\n\n    if cl_type == \"Object\":\n        custom_classifier = apoc.ObjectSegmenter(\n            opencl_filename=cl_path,\n            positive_class_identifier=cl_label_id,\n            max_depth=cl_forests,\n            num_ensembles=cl_trees,\n        )\n\n    for file in tqdm(image_list, label=\"progress\"):\n\n        image_stack = []\n        img = AICSImage(image_directory / file)\n\n        for channels in channel_list:\n            ch_img = _get_channel_image(\n                img=img, dims=img_dims, channel=channels\n            )\n            image_stack.append(ch_img)\n\n        dask_stack = da.stack(image_stack, axis=0)\n\n        lbl = AICSImage(label_directory / file)\n        labels = _get_channel_image(img=lbl, dims=img_dims, channel=0)\n\n        if predefined_features.value == 1:\n            print(\"custom\")\n            feature_set = custom_features\n\n        else:\n            print(\"predefined\")\n            feature_set = apoc.PredefinedFeatureSet[\n                predefined_features.name\n            ].value\n\n        custom_classifier.train(\n            features=feature_set,\n            image=dask_stack,\n            ground_truth=labels,\n            continue_training=True,\n        )\n\n    feature_importances = custom_classifier.feature_importances()\n    print(\"success\")\n    # return pd.Series(feature_importances).plot.bar()\n    return feature_importances\n</code></pre>"},{"location":"widget_reference/batch_utilities/","title":"batch_utilities","text":"<p>Batch Utilities</p> <p>Quick adjustments to apply to a batch of images and save the resulting images in an output folder. Intended for adjustments either too simple (e.g. max projection, saving only certain channels) or not possible (e.g. cropping) with napari-workflows / batch-workflow widgets.</p>"},{"location":"widget_reference/batch_utilities/#napari_ndev._widget.batch_utilities--parameters","title":"Parameters","text":"pathlib.Path <p>Directory of files to be processed.</p> pathlib.Path <p>Directory to save output images to. Often created by user in OS GUI.</p> list <p>Channels to process. Extracted from aicsimageio metadata.</p> str, optional <p>Comma separated string of scene indexes or scene names.</p> bool <p>If True, then do a maximum project along Z axis</p> <p>X_range, Y_range, Z_range : slice     Dimension of respective axis to crop between. Use step to downsample.</p>"},{"location":"widget_reference/batch_utilities/#napari_ndev._widget.batch_utilities--returns","title":"Returns","text":"<p>None     Processed images are saved in result directory</p> Source code in <code>src\\napari_ndev\\_widget.py</code> <pre><code>@magic_factory(\n    widget_init=init_utilities,\n    auto_call=False,\n    call_button=\"Batch Adjust\",\n    image_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    result_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    channel_list=dict(widget_type=\"Select\", choices=[]),\n    keep_scenes=dict(widget_type=\"LineEdit\"),\n)\ndef batch_utilities(\n    image_directory=pathlib.Path(),\n    result_directory=pathlib.Path(),\n    channel_list: str = [],\n    keep_scenes: str = \"\",\n    project_bool: bool = False,\n    X_range: slice = slice(0, 1, 1),\n    Y_range: slice = slice(0, 1, 1),\n    Z_range: slice = slice(0, 1, 1),\n):\n\"\"\"Batch Utilities\n\n    Quick adjustments to apply to a batch of images and save the resulting images in an output folder. Intended for adjustments either too simple (e.g. max projection, saving only certain channels) or not possible (e.g. cropping) with napari-workflows / batch-workflow widgets.\n\n    Parameters\n    ----------\n    image_directory : pathlib.Path\n        Directory of files to be processed.\n    result_directory : pathlib.Path\n        Directory to save output images to. Often created by user in OS GUI.\n    channel_list : list\n        Channels to process. Extracted from aicsimageio metadata.\n    keep_scenes : str, optional\n        Comma separated string of scene indexes or scene names.\n    project_bool : bool\n        If True, then do a maximum project along Z axis\n    X_range, Y_range, Z_range : slice\n        Dimension of respective axis to crop between. Use step to downsample.\n\n    Returns\n    -------\n    None\n        Processed images are saved in result directory\n    \"\"\"\n\n    image_list = os.listdir(image_directory)\n\n    for file in tqdm(image_list, label=\"file\"):\n        result_stack = None\n        img = AICSImage(image_directory / file)\n\n        # Create kept scene list, if applicable. By using the else statement,\n        # will work for single scene images\n        if keep_scenes == \"\":\n            scene_list = img.scenes\n        else:\n            scene_list = keep_scenes.split(\",\")\n            try:  # for converting numeric keep_scenes to a list of indexes\n                # convert to np array, subtract 1-index\n                # (at least for ZEN/czi naming) and convert back to python list\n                scene_list = np.array(scene_list).astype(\"int\") - 1\n                scene_list = scene_list.tolist()\n            except ValueError:\n                pass\n\n        for scene in tqdm(scene_list, label=\"scene\"):\n            img.set_scene(scene)\n\n            for idx, channel in enumerate(channel_list):\n                ch_img = _get_channel_image(\n                    img=img, dims=img.dims.order, channel=channel\n                )\n\n                #  T C Z Y X default from aicsimageio\n                ch_img = ch_img[:, :, Z_range, Y_range, X_range]\n\n                # project along the Z axis (2)\n                if project_bool:\n                    ch_img = np.max(ch_img, axis=2, keepdims=True)\n\n                # concatenate images, to keep proper dims stack along C (1)\n                try:\n                    result_stack = np.concatenate(\n                        [result_stack, ch_img], axis=1\n                    )\n                except ValueError:\n                    result_stack = ch_img\n\n            # save the image\n            save_name = str(file + \"ome.tif\")\n            save_uri = result_directory / save_name\n            OmeTiffWriter.save(\n                data=result_stack,\n                uri=save_uri,\n                dim_order=img.dims.order,\n                channel_names=channel_list,\n                physical_pixel_sizes=img.physical_pixel_sizes,\n            )\n    return\n</code></pre>"},{"location":"widget_reference/batch_workflow/","title":"batch_workflow","text":"<p>Batch Workflow widget using napari-workflow metadata file</p> <p>Load a napari-workflow metadata file and show the original roots.  Select an image directory to populate the root dropdowns with channels from the first image read by aicsimageio. Then, select these  channels in the dropdown to match the Roots in the proper order.  If there are less roots than displayed, leave dropdown as  '-----' which represents python None. </p>"},{"location":"widget_reference/batch_workflow/#napari_ndev._widget.batch_workflow--parameters","title":"Parameters","text":"pathlib.Path <p>Location of image files to process, by default pathlib.Path()</p> pathlib.Path <p>Location to save output images, by default pathlib.Path()</p> pathlib.Path <p>Location of workflow metadata.yaml file, by default pathlib.Path()</p> list, optional <p>Roots extracted from , by default None</p> <p>root_0, root_1, root_2, root_3, root_4 : str, optional     description, by default None</p> str, optional <p>Can be changed, if necessary, to account for different image shapes by default None</p> bool, optional <p>Stack original images with result images prior to saving, by default True</p>"},{"location":"widget_reference/batch_workflow/#napari_ndev._widget.batch_workflow--returns","title":"Returns","text":"<p>None     Resulting image stacks are saved to result_directory after workflow processing</p> Source code in <code>src\\napari_ndev\\_widget.py</code> <pre><code>@magic_factory(\n    widget_init=init_workflow,\n    auto_call=False,\n    call_button=\"Batch Workflow\",\n    result_widget=True,\n    image_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    result_directory=dict(widget_type=\"FileEdit\", mode=\"d\"),\n    workflow_path=dict(widget_type=\"FileEdit\", mode=\"r\"),\n    workflow_roots=dict(widget_type=\"Label\", label=\"Roots:\"),\n    root_0=dict(widget_type=\"ComboBox\", choices=[], nullable=True),\n    root_1=dict(widget_type=\"ComboBox\", choices=[], nullable=True),\n    root_2=dict(widget_type=\"ComboBox\", choices=[], nullable=True),\n    root_3=dict(widget_type=\"ComboBox\", choices=[], nullable=True),\n    root_4=dict(widget_type=\"ComboBox\", choices=[], nullable=True),\n)\ndef batch_workflow(\n    image_directory=pathlib.Path(),\n    result_directory=pathlib.Path(),\n    workflow_path=pathlib.Path(),\n    workflow_roots: list = None,\n    root_0: str = None,\n    root_1: str = None,\n    root_2: str = None,\n    root_3: str = None,\n    root_4: str = None,\n    img_dims: str = None,\n    keep_original_images: bool = True,\n):\n\"\"\"Batch Workflow widget using napari-workflow metadata file\n\n    Load a napari-workflow metadata file and show the original roots. \n    Select an image directory to populate the root dropdowns with\n    channels from the first image read by aicsimageio. Then, select these \n    channels in the dropdown to match the Roots in the proper order. \n    If there are less roots than displayed, leave dropdown as \n    '-----' which represents python None. \n\n    Parameters\n    ----------\n    image_directory : pathlib.Path\n        Location of image files to process, by default pathlib.Path()\n    result_directory : pathlib.Path\n        Location to save output images, by default pathlib.Path()\n    workflow_path : pathlib.Path\n        Location of workflow _metadata_.yaml file, by default pathlib.Path()\n    workflow_roots : list, optional\n        Roots extracted from , by default None\n    root_0, root_1, root_2, root_3, root_4 : str, optional\n        _description_, by default None\n    img_dims : str, optional\n        Can be changed, if necessary, to account for different image shapes by default None\n    keep_original_images : bool, optional\n        Stack original images with result images prior to saving, by default True\n\n    Returns\n    -------\n    None\n        Resulting image stacks are saved to result_directory after workflow processing\n    \"\"\"\n    image_list = os.listdir(image_directory)\n\n    wf = load_workflow(workflow_path)\n\n    roots = []\n    roots.append(root_0)\n    roots.append(root_1)\n    roots.append(root_2)\n    roots.append(root_3)\n    roots.append(root_4)\n\n    root_list = [i for i in roots if i is not None]\n\n    for file in tqdm(image_list, label=\"progress\"):\n        image_stack = []\n        img = AICSImage(image_directory / file)\n\n        for idx, root in enumerate(root_list):\n            ch_img = _get_channel_image(img=img, dims=img_dims, channel=root)\n\n            wf.set(name=wf.roots()[idx], func_or_data=ch_img)\n\n            image_stack.append(ch_img)\n\n        # dask_stack = da.stack(image_stack, axis=0)\n\n        result = wf.get(name=wf.leafs())\n        result_stack = cle.pull(result)\n\n\"\"\"extract the leaf name corresponding to each root to save into\n        channel names\n        \"\"\"\n        result_names = reduce(\n            lambda res, lst: res + [lst[0] + \"_\" + lst[1]],\n            zip(root_list, wf.leafs()),\n            [],\n        )\n\n        if keep_original_images is True:\n            dask_images = da.stack(image_stack, axis=0)\n            dask_result = da.stack(result_stack, axis=0)\n            result_stack = da.concatenate([dask_images, dask_result], axis=0)\n            result_names = root_list + result_names\n\n        save_name = str(file + \".ome.tif\")\n        save_uri = result_directory / save_name\n\n        OmeTiffWriter.save(\n            data=result_stack,\n            uri=save_uri,\n            # dim_order=img.dims.order,\n            channel_names=result_names,\n            physical_pixel_sizes=img.physical_pixel_sizes,\n        )\n\n    return\n</code></pre>"}]}