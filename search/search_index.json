{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>A collection of widgets intended to serve any person seeking to process microscopy images from start to finish. The wide breadth of this plugin's scope is only made possible by the amazing libraries and plugins from the napari community, especially Robert Haase. Currently, the plugin supports the following goals:</p> <ol> <li>Batch-utilities: Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. </li> <li>Batch-workflow: Batch pre-processing/processing images using napari-workflows.</li> <li>Annotation-saver: A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders.</li> <li>Batch-training/prediction: Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting.</li> </ol>"},{"location":"#further-info","title":"Further Info","text":""},{"location":"#1-batch-utilities","title":"1. Batch-utilities","text":"<p>Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. To be added: alternative projection types, slicing in T, and compatability with non TCZYX images (but this is not a priority since aicsimageio currently always extracts images as TCZYX even if a dim is only length 1. </p>"},{"location":"#2-batch-workflow","title":"2. Batch-workflow","text":"<p>Batch pre-processing/processing images using napari-workflows.  Images are processed outside the napari-viewer using aicsimageio as both reader and writer. Prior to passing the images to napari-workflows, the user selects the correct images as the roots (inputs) and thus napari-workflows matches the processing to create the outputs. The advantage of using napari-workflows for batch processing is that it provides an incredibly flexible processing interface without writing a novel widget for small changes to processing steps like specific filters, segmentation, or measurements. Currently only intended for use with images as inputs and images as outputs from napari-workflows, though there is future potential to have other outputs possible, such as .csv measurement arrays.</p>"},{"location":"#3-annotation-saver","title":"3. Annotation-saver","text":"<p>A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders. Requires that images are opened with napari-aicsimageio--which can be as simple as drag and drop opening by setting the appropriate default reader for each file type in Preferences -&gt; Plugins--in order to utilize the metadata present for saving the image-label pairs. (See Note about AICSImageIO)</p> <p>Intended to be used with apoc batch-training/prediction, but can be used for any napari widget or other script intended to grab corresponding images from folders for batch processing.</p>"},{"location":"#4-batch-trainingprediction","title":"4. Batch-training/prediction","text":"<p>Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting. Recognizes pre established feature sets.</p>"},{"location":"#a-note-about-aicsimageio","title":"A Note about AICSImageIO","text":"<p>AICSImageIO is a convenient, multi-format file reader which also has the complimentary napari-aicsimageio reader plugin. By default, napari-aicsimageio installs all reader dependencies. Because napari-aicsimageio is not technically required for this plugin to work (you could build your own metadata for the annotation-saver) and just napari-aicsimage is required, the former is not an install requirement. This is to avoid using the GPL liscence and to stick with BSD-3. However, you should install napari-aicsimageio if you want the smoothest operation of the annotation-saver.</p>"},{"location":"installation/","title":"Installation","text":"<p>You can install <code>napari-ndev</code> via <code>pip</code>:</p> <pre><code>pip install napari-ndev\n</code></pre>"},{"location":"widget_reference/annotation_saver/","title":"annotation_saver","text":""},{"location":"widget_reference/annotation_saver/#napari_ndev._widget.annotation_saver","title":"<code>napari_ndev._widget.annotation_saver(image: layers.Image, labels: layers.Labels, file_directory = pathlib.Path(), output_folder_prefix = 'Annotated', save_suffix = '.ome.tif')</code>","text":"<p>Annotation Saver</p> <p>Used for annotating images and saving images of interest into a folder for the image and a folder for the labels. The GUI allows selecting of the intended label layer and image layer, as well as the prefix for the output folders. These output folders can already exist: mkdir(exist_ok=True), so should be used to save multiple images within the same folder group. Images are saved as ome.tif  with aicsimageio.OmeTiffWriter</p> <p>Parameters:</p> <ul> <li> image             (<code>napari.layers.layers.Image</code>)         \u2013 <p>Image layer to save</p> </li> <li> labels             (<code>napari.layers.layers.Labels</code>)         \u2013 <p>Labels layer (annotation) to save</p> </li> <li> file_directory             (<code>pathlib.Path</code>)         \u2013 <p>Top-level folder where separate image and labels folders are present</p> </li> <li> output_folder_prefix             (<code>str</code>)         \u2013 <p>Prefix to _images or _labels folder created in <code>file_directory</code>, by default \"Annotated\"</p> </li> <li> save_suffix             (<code>str</code>)         \u2013 <p>File ending can be changed if needed for interoperability, but still  saves as an OME-TIFF with aicsimageio.OmeTiffWriter, by default \"ome.tif\"</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013 <p>Message of \"saved\" and the respective image name</p> </li> </ul>"},{"location":"widget_reference/batch_predict/","title":"batch_predict","text":""},{"location":"widget_reference/batch_predict/#napari_ndev._widget.batch_predict","title":"<code>napari_ndev._widget.batch_predict(image_directory = pathlib.Path(), result_directory = pathlib.Path(), cl_path = pathlib.Path(), cl_type: str = cl_types[0], channel_list: str = [], img_dims: str = None)</code>","text":"<p>Train APOC (Accelerated-Pixel-Object-Classifiers) on a folder of images and labels.</p> <p>Parameters:</p> <ul> <li> image_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location of images</p> </li> <li> result_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location to save output labels</p> </li> <li> cl_path             (<code>pathlib.Path</code>)         \u2013 <p>Location of apoc classifier \".cl\" file</p> </li> <li> cl_type             (<code>str, optional</code>)         \u2013 <p>Choose between Pixel or Object Classifier, by default Pixel Classifier</p> </li> <li> channel_list             (<code>list</code>)         \u2013 <p>Select channels to pass into the classifier to serve as bases for features, by default []</p> </li> <li> cl_label_id             (<code>int, optional</code>)         \u2013 <p>Label id number if using Object Classifier for <code>cl_type</code>, by default 2</p> </li> <li> img_dims             (<code>str, optional</code>)         \u2013 <p>Image dimensions read from aicsimageio metadata, by default None</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>         \u2013 <p>Predicted labels saved to <code>result_directory</code></p> </li> </ul>"},{"location":"widget_reference/batch_predict/#napari_ndev._widget.batch_predict--notes","title":"Notes","text":"<p>Accelerated pixel object classifier information from:     https://github.com/haesleinhuepf/apoc</p>"},{"location":"widget_reference/batch_training/","title":"batch_training","text":""},{"location":"widget_reference/batch_training/#napari_ndev._widget.batch_training","title":"<code>napari_ndev._widget.batch_training(image_directory = pathlib.Path(), label_directory = pathlib.Path(), cl_directory = pathlib.Path(), cl_filename: str = 'classifier.cl', cl_type: str = cl_types[0], cl_forests: int = 2, cl_trees: int = 100, predefined_features = PDFS(1), custom_features: str = None, channel_list: str = [], cl_label_id: int = 2, img_dims: str = None)</code>","text":"<p>Train APOC (Accelerated-Pixel-Object-Classifiers) on a folder of images and labels.</p> <p>Parameters:</p> <ul> <li> image_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location of images</p> </li> <li> label_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location of labels (annotations)</p> </li> <li> cl_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location to save apoc classifier \".cl\" file</p> </li> <li> cl_filename             (<code>str, optional</code>)         \u2013 <p>Filename to save apoc classifier, end with \".cl\", by default \"classifier.cl\"</p> </li> <li> cl_type             (<code>str, optional</code>)         \u2013 <p>Choose between Pixel or Object Classifier, by default Pixel Classifier</p> </li> <li> cl_forests             (<code>int, optional</code>)         \u2013 <p>Number of random forests, by default 2</p> </li> <li> cl_trees             (<code>int, optional</code>)         \u2013 <p>Number of trees, by default 100</p> </li> <li> predefined_features             (<code>str, optional</code>)         \u2013 <p>Allows selection of <code>apoc.PredefinedFeatureSets</code>, by default custom, requires input of <code>custom_features</code></p> </li> <li> custom_features             (<code>str, optional</code>)         \u2013 <p>Space-separated string of pyclesperanto filters, by default None</p> </li> <li> channel_list             (<code>list</code>)         \u2013 <p>Select channels to pass into the classifier to serve as bases for features, by default []</p> </li> <li> cl_label_id             (<code>int, optional</code>)         \u2013 <p>Label id number if using Object Classifier for <code>cl_type</code>, by default 2</p> </li> <li> img_dims             (<code>str, optional</code>)         \u2013 <p>Image dimensions read from aicsimageio metadata, by default None</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013 <p>String of feature importances returned in classifier file</p> </li> </ul>"},{"location":"widget_reference/batch_training/#napari_ndev._widget.batch_training--notes","title":"Notes","text":"<p>Accelerated pixel object classifier information from:      https://github.com/haesleinhuepf/apoc Predefined features from https://github.com/haesleinhuepf/apoc/blob/main/demo/feature_stacks.ipynb</p>"},{"location":"widget_reference/batch_utilities/","title":"batch_utilities","text":""},{"location":"widget_reference/batch_utilities/#napari_ndev._widget.batch_utilities","title":"<code>napari_ndev._widget.batch_utilities(image_directory = pathlib.Path(), result_directory = pathlib.Path(), channel_list: str = [], keep_scenes: str = '', project_bool: bool = False, X_range: slice = slice(0, 1, 1), Y_range: slice = slice(0, 1, 1), Z_range: slice = slice(0, 1, 1))</code>","text":"<p>Batch Utilities</p> <p>Quick adjustments to apply to a batch of images and save the resulting images in an output folder. Intended for adjustments either too simple (e.g. max projection, saving only certain channels) or not possible (e.g. cropping) with napari-workflows / batch-workflow widgets.</p> <p>Parameters:</p> <ul> <li> image_directory             (<code>pathlib.Path</code>)         \u2013 <p>Directory of files to be processed.</p> </li> <li> result_directory             (<code>pathlib.Path</code>)         \u2013 <p>Directory to save output images to. Often created by user in OS GUI.</p> </li> <li> channel_list             (<code>list</code>)         \u2013 <p>Channels to process. Extracted from aicsimageio metadata.</p> </li> <li> keep_scenes             (<code>str, optional</code>)         \u2013 <p>Comma separated string of scene indexes or scene names.</p> </li> <li> project_bool             (<code>bool</code>)         \u2013 <p>If True, then do a maximum project along Z axis</p> </li> <li> X_range             (<code>slice</code>)         \u2013 <p>Dimension of respective axis to crop between. Use step to downsample.</p> </li> <li> Y_range             (<code>slice</code>)         \u2013 <p>Dimension of respective axis to crop between. Use step to downsample.</p> </li> <li> Z_range             (<code>slice</code>)         \u2013 <p>Dimension of respective axis to crop between. Use step to downsample.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>         \u2013 <p>Processed images are saved in result directory</p> </li> </ul>"},{"location":"widget_reference/batch_workflow/","title":"batch_workflow","text":""},{"location":"widget_reference/batch_workflow/#napari_ndev._widget.batch_workflow","title":"<code>napari_ndev._widget.batch_workflow(image_directory = pathlib.Path(), result_directory = pathlib.Path(), workflow_path = pathlib.Path(), workflow_roots: list = None, root_0: str = None, root_1: str = None, root_2: str = None, root_3: str = None, root_4: str = None, img_dims: str = None, keep_original_images: bool = True)</code>","text":"<p>Batch Workflow widget using napari-workflow metadata file</p> <p>Load a napari-workflow metadata file and show the original roots.  Select an image directory to populate the root dropdowns with channels from the first image read by aicsimageio. Then, select these  channels in the dropdown to match the Roots in the proper order.  If there are less roots than displayed, leave dropdown as  '-----' which represents python None. </p> <p>Parameters:</p> <ul> <li> image_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location of image files to process, by default pathlib.Path()</p> </li> <li> result_directory             (<code>pathlib.Path</code>)         \u2013 <p>Location to save output images, by default pathlib.Path()</p> </li> <li> workflow_path             (<code>pathlib.Path</code>)         \u2013 <p>Location of workflow metadata.yaml file, by default pathlib.Path()</p> </li> <li> workflow_roots             (<code>list, optional</code>)         \u2013 <p>Roots extracted from , by default None</p> </li> <li> root_0             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> root_1             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> root_2             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> root_3             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> root_4             (<code>str, optional</code>)         \u2013 <p>description, by default None</p> </li> <li> img_dims             (<code>str, optional</code>)         \u2013 <p>Can be changed, if necessary, to account for different image shapes by default None</p> </li> <li> keep_original_images             (<code>bool, optional</code>)         \u2013 <p>Stack original images with result images prior to saving, by default True</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>         \u2013 <p>Resulting image stacks are saved to result_directory after workflow processing</p> </li> </ul>"}]}