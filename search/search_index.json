{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#napari-ndev-ndev","title":"napari-ndev (nDev)","text":"<p>A collection of widgets intended to serve any person seeking to process microscopy images from start to finish, with no coding necessary. <code>napari-ndev</code> was designed to address the gap between the napari viewer and batch python scripting.</p> <ul> <li>Accepts diverse image formats, dimensionality, file size, and maintains key metadata.</li> <li>Allows advanced, arbitrary image processing workflows to be used by novices.</li> <li>User-friendly sparse annotation and batch training of machine learning classifiers.</li> <li>Flexible label measurements, parsing of metadata, and summarization for easily readable datasets.</li> <li>Designed for ease of use, modification, and reproducibility.</li> </ul> <p>Check out the poster presented at BINA 2024 for an overview of the plugins in action!</p> <p>Also check out the Virtual I2K 2024 Workshop for an interactive tutorial to learn more!</p>"},{"location":"#plugin-overview","title":"Plugin Overview","text":"<ol> <li>Image Utilities: Intended for high-throuput image-labeling and management, while passing down important metadata. Allows opening image files and displaying in napari. Also reads metadata and allows customization prior to saving images and labels layers. Allows concatenation of image files and image layers for saving new images. Speeds up annotation by saving corresponding images and labels in designated folders. Also allows saving of shapes layers as labels in case shapes are being used as a region of interest.</li> <li>Workflow Widget: Batch pre-processing/processing images using napari-workflows.</li> <li>APOC Widget: Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting.<ul> <li>Custom Feature Set Widget: Generate a featureset to be used with the APOC widget. Also allows quick application in the napari viewer to an image layer to see all the features.</li> </ul> </li> <li>Measure Widget: Batch measurement of a label with optional corresponding image, label, and regions (ROIs) that can be used as an intensity image. Currently passed to <code>scikit-image.measure.regionprops</code>.</li> </ol> <p>The wide breadth of this plugin's scope is only made possible by the amazing libraries and plugins from the python and napari community, especially Robert Haase.</p>"},{"location":"BINA_poster/","title":"Poster","text":""},{"location":"BINA_poster/#poster-and-slide-from-bina-2024-in-madison-wi","title":"Poster and slide from BINA 2024 in Madison, WI","text":""},{"location":"beginner_setup/","title":"Beginner Setup","text":""},{"location":"beginner_setup/#setup-guide-to-napari-and-napari-ndev-for-beginners","title":"Setup Guide to napari and napari-ndev for beginners","text":"<p>This guide is intended for those who do not want to work with the command line and instead get started with a more 'traditional' installation approach. Note that the napari developers do not currently recommend this approach, and you may run in to unforeseen limitations. However, napari-ndev is designed as a comprehensive package, so it should work fairly well with the napari installer.</p>"},{"location":"beginner_setup/#napari-bundled-installer","title":"napari bundled installer","text":"<p>Download the latest version of napari found in the Assets at the bottom of the page. See the napari bundled app page for detailed instructions. Currently, napari is around 500MB to install.</p>"},{"location":"beginner_setup/#opening-napari","title":"opening napari","text":"<p>In your operating system, you can search for <code>napari</code> and open the version that you just installed. If you followed the default installation, you will also likely have a shortcut to napari on your desktop, e.g. <code>napari (0.5.4)</code>.</p>"},{"location":"beginner_setup/#napari-ndev-minimal-installation-from-ui","title":"napari-ndev minimal installation from UI","text":"<p>Inside napari, navigate to <code>Plugins</code> --&gt; <code>Install/Uninstall Plugins...</code>. In the <code>filter...</code> text box, search for <code>napari-ndev</code>. Select <code>PyPI</code> as the Source and <code>Install</code> the most recent (default) version. This is a complete version of <code>napari-ndev</code> and currently support full integration with other tools such as the <code>napari-assistant</code> and <code>napari-workflows</code>. This minimal installation is sufficient for full reproducibility of any analysis. Note: You must close the little black <code>When installing/uninstalling npe2...</code> pop-up for the installation to look to proceed. This installation will potentially take a few minutes depending on your computer and internet speed.</p>"},{"location":"beginner_setup/#optional-napari-ndev-full-installation","title":"[Optional] napari-ndev full installation","text":"<p>This method only installs python libraries that are BSD3 licensed. Some image formats (such as czi and lif) are not available unless installing the full nDev package. To install extra plugins go to the integrated <code>napari console</code> (lower left button in UI) and enter <code>!pip install napari-ndev[all]</code>. Note: napari will freeze when you enter this command; please be patient as it downloads and sets up the remaining packages. Restart napari for changes to take affect.</p>"},{"location":"beginner_setup/#opening-widgets","title":"opening widgets","text":"<p>Navigate to <code>Plugins</code> --&gt; <code>nDev</code> --&gt; Click any widget. Note: Something (I believe napari) appears to be currently bugged and requires that the first widget be opened twice; the first time it will give a warning, the second time it should open.</p>"},{"location":"beginner_setup/#bio-formats-support","title":"bio-formats support","text":"<p>After the full installation, you may still be missing support for some image formats. To support all image formats you may find it useful to install bioformats support via bioio-bioformats. To install enter into the console <code>!pip install bioio-bioformats</code>. You may also need to install java, to do so: <code>!conda install scyjava</code></p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>If you are unfamiliar with python or the command line, instead use the bundled app installer as demonstrated in Beginner Setup.</p>"},{"location":"installation/#install-with-uv","title":"Install with uv","text":"<p>uv is the newest and fastest way to manage python libraries. It is very easy to install, and simplifies environment manage, but requires some minimal input to the command line.  Install uv from here. Then, the simplest way to install <code>napari-ndev</code>:</p> <pre><code>uv tool install napari-ndev\n</code></pre> <p>Alternatively, download the full opinionated package, which includes non-BSD3 licensed libraries with:</p> <pre><code>uv tool install napari-ndev[all]\n</code></pre> <p>Then, you can easily open napari with the command line every time by just typing:</p> <pre><code>napari-ndev\n</code></pre> <p>The tool version of <code>napari-ndev</code> effectively runs as an alias for <code>napari -w napari-ndev</code> and opens the <code>nDev App</code> upon launch. With this method, additional plugins installed via the plugin menu persist between each call to <code>napari-ndev</code></p> <p>To update a tool with uv:</p> <pre><code>uv tool upgrade napari-ndev\n</code></pre>"},{"location":"installation/#install-with-pip","title":"Install with pip","text":"<p>napari-ndev is a pure Python package, and can be installed with [pip] (and it is recommended to do so in a managed environment):</p> <pre><code>pip install napari-ndev\n</code></pre> <p>The easiest way to get started with napari-ndev is to install all the optional dependencies (see note below) with:</p> <pre><code>pip install napari-ndev[all]\n</code></pre> <p>Afterwards, you can call from the command line (in the same environment) <code>napari-ndev</code> to open napari with the <code>nDev App</code> open on launch.</p>"},{"location":"installation/#optional-libraries","title":"Optional Libraries","text":"<p>napari-ndev is most useful when interacting with some other napari plugins (e.g. napari-assistant) and can read additional filetypes. A few extra BSD3 compatible napari-plugins may be installed with [pip]:</p> <pre><code>pip install napari-ndev[extras]\n</code></pre> <p>napari-ndev can optionally use GPL-3 licensed libraries to enhance its functionality, but are not required. If you choose to install and use these optional dependencies, you must comply with the GPL-3 license terms. The main functional improvement is from some <code>bioio</code> libraries to support extra image formats, including <code>czi</code> and <code>lif</code> files. These libraries can be installed with [pip]:</p> <pre><code>pip install napari-ndev[gpl-extras]\n</code></pre> <p>In addition, you may need to install specific <code>bioio</code> readers to support your specific image, such as <code>bioio-czi</code> and <code>bioio-lif</code> (included in <code>[gpl-extras]</code>) or <code>bioio-bioformats</code> (which needs conda installed).</p>"},{"location":"installation/#development-libraries","title":"Development Libraries","text":"<p>For development use the <code>[dev]</code> optional libraries to verify your changes, which includes the <code>[docs]</code> and <code>[testing]</code> optional groups. However, the Github-CI will test pull requests with <code>[testing]</code> only.</p>"},{"location":"installation/#development-with-uv","title":"Development with uv","text":"<p>uv can be a useful tool for building as similar an environment as possible across systems. To do so, navigate in your terminal to the <code>napari-ndev</code> source directory. <code>--python</code> sets the minimum python version. <code>--no-workspace</code> prevents discovering parent workspaces. Then:</p> <pre><code>uv init --python 3.11 --no-workspace\nuv sync\n</code></pre> <p>You may use uv to set a certain python version, e.g.:</p> <pre><code>uv pin python 3.11\n</code></pre> <p>To use uv to install extras (like with <code>napari-ndev[dev]</code>), use:</p> <pre><code>uv sync --extra dev\n</code></pre> <p>You may also test the tool version of uv during development with:</p> <pre><code>uv install tool .\n</code></pre> <p>You can also test with tox in parallel (via tox-uv) with:</p> <pre><code>tox - p auto\n</code></pre>"},{"location":"widget_further_info/","title":"Further Widget Info","text":""},{"location":"widget_further_info/#further-info","title":"Further Info","text":""},{"location":"widget_further_info/#1-image-utilities","title":"1. Image Utilities","text":"<p>A quick and easy way to save annotations (a napari labels layer) and corresponding images to corresponding folders. Best if the images are opened with the <code>nDev</code> reader (using bioio under the hood) -- which can be as simple as drag and drop opening by setting the appropriate default reader for each file type in Preferences -&gt; Plugins--in order to utilize the metadata present for saving the image-label pairs.</p> <p>Quick uniform adjustments to a folder of images, saving the output. Currently supports selecting channels, slicing Z, cropping/downsampling in XY, and doing a max projection of the sliced/cropped image data. To be added: alternative projection types, slicing in T, and compatibility with non TCZYX images (but this is not a priority since bioio currently always extracts images as TCZYX even if a dim is only length 1.</p>"},{"location":"widget_further_info/#2-workflow-widget","title":"2. Workflow Widget","text":"<p>Batch pre-processing/processing images using napari-workflows.  Images are processed outside the napari-viewer using bioio as both reader and writer. Prior to passing the images to napari-workflows, the user selects the correct images as the roots (inputs) and thus napari-workflows matches the processing to create the outputs. The advantage of using napari-workflows for batch processing is that it provides an incredibly flexible processing interface without writing a novel widget for small changes to processing steps like specific filters, segmentation, or measurements. Currently only intended for use with images as inputs and images as outputs from napari-workflows, though there is future potential to have other outputs possible, such as .csv measurement arrays.</p>"},{"location":"widget_further_info/#3-apoc-widget","title":"3. APOC Widget","text":"<p>Utilizes the excellent accelerated-pixel-and-object-classification (apoc) in a similar fashion to napari-apoc, but intended for batch training and prediction with a napari widget instead of scripting. Recognizes pre established feature set, and custom feature sets (a string of filters and radii) can be generated with a corresponding widget. Also contains a Custom Feature Set widget which allows application of all the features to a layer in the viewer, for improved visualization.</p>"},{"location":"widget_further_info/#4-measure-widget","title":"4. Measure Widget","text":"<p>Batch measurements using scikit-image's regionprops. This can measure features of a label such as area, eccentricity, and more but also can measure various intensity metrics. Attempts to support post-processing of measurements, grouping, and more to make downstream analyses easier for users. Will be updated in the future to include nyxus.</p>"},{"location":"api/helpers/","title":"Helpers","text":""},{"location":"api/helpers/#napari_ndev.helpers","title":"napari_ndev.helpers","text":"<p>Helper functions for file handling, image processing, and logging setup.</p> <p>Functions:</p> <ul> <li> <code>get_directory_and_files : Get the directory and files in the specified directory.</code>             \u2013              </li> <li> <code>get_channel_names : Get the channel names from an BioImage object.</code>             \u2013              </li> <li> <code>get_squeezed_dim_order : Return a string containing the squeezed dimensions of the given BioImage object.</code>             \u2013              </li> <li> <code>create_id_string : Create an ID string for the given image.</code>             \u2013              </li> <li> <code>check_for_missing_files : Check if the given files are missing in the specified directories.</code>             \u2013              </li> <li> <code>setup_logger : Set up a logger with the specified log location.</code>             \u2013              </li> </ul>"},{"location":"api/helpers/#napari_ndev.helpers.check_for_missing_files","title":"check_for_missing_files","text":"<pre><code>check_for_missing_files(files, *directories)\n</code></pre> <p>Check if the given files are missing in the specified directories.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list of tuple</code>           \u2013            <p>List of tuples containing the missing files and their corresponding directories.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def check_for_missing_files(\n    files: list[Path] | list[str], *directories: Path | str\n) -&gt; list[tuple]:\n    \"\"\"\n    Check if the given files are missing in the specified directories.\n\n    Parameters\n    ----------\n    files : list of Path or list of str\n        List of files to check.\n    directories : tuple of Path or str\n        Tuple of directories to search for the files.\n\n    Returns\n    -------\n    list of tuple\n        List of tuples containing the missing files and their corresponding directories.\n\n    \"\"\"\n    missing_files = []\n    for file in files:\n        for directory in directories:\n            if isinstance(directory, str):\n                directory = Path(directory)\n            if isinstance(file, str):\n                file = Path(file)\n\n            file_loc = directory / file.name\n            if not file_loc.exists():\n                missing_files.append((file.name, directory.name))\n\n    return missing_files\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.check_for_missing_files(files)","title":"<code>files</code>","text":"(<code>list of Path or list of str</code>)           \u2013            <p>List of files to check.</p>"},{"location":"api/helpers/#napari_ndev.helpers.check_for_missing_files(directories)","title":"<code>directories</code>","text":"(<code>tuple of Path or str</code>, default:                   <code>()</code> )           \u2013            <p>Tuple of directories to search for the files.</p>"},{"location":"api/helpers/#napari_ndev.helpers.create_id_string","title":"create_id_string","text":"<pre><code>create_id_string(img, identifier)\n</code></pre> <p>Create an ID string for the given image.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>The ID string.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; create_id_string(img, 'test')\n'test__0__Scene:0'\n</code></pre> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def create_id_string(img: nImage | BioImage, identifier: str) -&gt; str:\n    \"\"\"\n    Create an ID string for the given image.\n\n    Parameters\n    ----------\n    img : BioImage\n        The image object.\n    identifier : str\n        The identifier string.\n\n    Returns\n    -------\n    str\n        The ID string.\n\n    Examples\n    --------\n    &gt;&gt;&gt; create_id_string(img, 'test')\n    'test__0__Scene:0'\n\n    \"\"\"\n    scene_idx = img.current_scene_index\n    # scene = img.current_scene\n    # instead use ome_metadata.name because this gets saved with OmeTiffWriter\n    try:\n        if img.ome_metadata.images[scene_idx].name is None:\n            scene = img.current_scene\n        else:\n            scene = img.ome_metadata.images[scene_idx].name\n    except NotImplementedError:\n        scene = img.current_scene  # not useful with OmeTiffReader, atm\n    id_string = f'{identifier}__{scene_idx}__{scene}'\n    return id_string\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.create_id_string(img)","title":"<code>img</code>","text":"(<code>BioImage</code>)           \u2013            <p>The image object.</p>"},{"location":"api/helpers/#napari_ndev.helpers.create_id_string(identifier)","title":"<code>identifier</code>","text":"(<code>str</code>)           \u2013            <p>The identifier string.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_channel_names","title":"get_channel_names","text":"<pre><code>get_channel_names(img)\n</code></pre> <p>Get the channel names from a BioImage object.</p> <p>If the image has a dimension order that includes \"S\" (it is RGB), return the default channel names [\"red\", \"green\", \"blue\"]. Otherwise, return the channel names from the image.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list of str</code>           \u2013            <p>The channel names.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_channel_names(img: nImage | BioImage) -&gt; list[str]:\n    \"\"\"\n    Get the channel names from a BioImage object.\n\n    If the image has a dimension order that includes \"S\" (it is RGB),\n    return the default channel names [\"red\", \"green\", \"blue\"].\n    Otherwise, return the channel names from the image.\n\n    Parameters\n    ----------\n    img : BioImage\n        The BioImage object.\n\n    Returns\n    -------\n    list of str\n        The channel names.\n\n    \"\"\"\n    if 'S' in img.dims.order:\n        return ['red', 'green', 'blue']\n    return img.channel_names\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_channel_names(img)","title":"<code>img</code>","text":"(<code>BioImage</code>)           \u2013            <p>The BioImage object.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_directory_and_files","title":"get_directory_and_files","text":"<pre><code>get_directory_and_files(dir_path=None, pattern=None)\n</code></pre> <p>Get the directory and files in the specified directory.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>tuple of (Path, list of Path)</code>           \u2013            <p>A tuple containing the directory path and a list of file paths.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_directory_and_files(\n    dir_path: str | Path | None = None,\n    pattern: list[str] | str | None = None,\n) -&gt; tuple[Path, list[Path]]:\n    \"\"\"\n    Get the directory and files in the specified directory.\n\n    Parameters\n    ----------\n    dir_path : str or Path or None, optional\n        The directory path.\n    pattern : list of str or str or None, optional\n        The file pattern(s) to match. If a string is provided, it will be treated as a single pattern.\n        If a list is provided, each element will be treated as a separate pattern.\n        Defaults to ['tif', 'tiff', 'nd2', 'czi', 'lif', 'oib', 'png', 'jpg', 'jpeg', 'bmp', 'gif'].\n\n    Returns\n    -------\n    tuple of (Path, list of Path)\n        A tuple containing the directory path and a list of file paths.\n\n    \"\"\"\n    if pattern is None:\n        pattern = [\n            'tif',\n            'tiff',\n            'nd2',\n            'czi',\n            'lif',\n            'oib',\n            'png',\n            'jpg',\n            'jpeg',\n            'bmp',\n            'gif',\n        ]\n    if dir_path is None:\n        return None, []\n\n    directory = Path(dir_path)\n\n    if dir_path is not None and not directory.exists():\n        raise FileNotFoundError(f'Directory {dir_path} does not exist.')\n\n    pattern = [pattern] if isinstance(pattern, str) else pattern\n    # add *. to each pattern if it doesn't already have either\n    pattern_glob = []\n    for pat in pattern:\n        if '.' not in pat:\n            pat = f'*.{pat}'\n        if '*' not in pat:\n            pat = f'*{pat}'\n        pattern_glob.append(pat)\n\n    files = []\n    for p_glob in pattern_glob:\n        for file in directory.glob(p_glob):\n            files.append(file)\n    return directory, files\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_directory_and_files(dir_path)","title":"<code>dir_path</code>","text":"(<code>str or Path or None</code>, default:                   <code>None</code> )           \u2013            <p>The directory path.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_directory_and_files(pattern)","title":"<code>pattern</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>The file pattern(s) to match. If a string is provided, it will be treated as a single pattern. If a list is provided, each element will be treated as a separate pattern. Defaults to ['tif', 'tiff', 'nd2', 'czi', 'lif', 'oib', 'png', 'jpg', 'jpeg', 'bmp', 'gif'].</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_squeezed_dim_order","title":"get_squeezed_dim_order","text":"<pre><code>get_squeezed_dim_order(img, skip_dims=None)\n</code></pre> <p>Return a string containing the squeezed dimensions of the given BioImage.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str</code>           \u2013            <p>A string containing the squeezed dimensions.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def get_squeezed_dim_order(\n    img: nImage | BioImage,\n    skip_dims: list[str] | str | None = None,\n) -&gt; str:\n    \"\"\"\n    Return a string containing the squeezed dimensions of the given BioImage.\n\n    Parameters\n    ----------\n    img : BioImage\n        The BioImage object.\n    skip_dims : list of str or str or None, optional\n        Dimensions to skip. Defaults to [\"C\", \"S\"].\n\n    Returns\n    -------\n    str\n        A string containing the squeezed dimensions.\n\n    \"\"\"\n    if skip_dims is None:\n        skip_dims = ['C', 'S']\n    return ''.join(\n        {k: v for k, v in img.dims.items() if v &gt; 1 and k not in skip_dims}\n    )\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.get_squeezed_dim_order(img)","title":"<code>img</code>","text":"(<code>BioImage</code>)           \u2013            <p>The BioImage object.</p>"},{"location":"api/helpers/#napari_ndev.helpers.get_squeezed_dim_order(skip_dims)","title":"<code>skip_dims</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>Dimensions to skip. Defaults to [\"C\", \"S\"].</p>"},{"location":"api/helpers/#napari_ndev.helpers.setup_logger","title":"setup_logger","text":"<pre><code>setup_logger(log_loc=Union[str, Path])\n</code></pre> <p>Set up a logger with the specified log location.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>logger</code> (              <code>Logger</code> )          \u2013            <p>The logger object.</p> </li> <li> <code>handler</code> (              <code>FileHandler</code> )          \u2013            <p>The file handler object.</p> </li> </ul> Source code in <code>src/napari_ndev/helpers.py</code> <pre><code>def setup_logger(log_loc=Union[str, Path]):\n    \"\"\"\n    Set up a logger with the specified log location.\n\n    Parameters\n    ----------\n    log_loc : str or Path\n        The path to the log file.\n\n    Returns\n    -------\n    logger : logging.Logger\n        The logger object.\n    handler : logging.FileHandler\n        The file handler object.\n\n    \"\"\"\n    logger = logging.getLogger(__name__ + str(time.time()))\n    logger.setLevel(logging.INFO)\n    handler = logging.FileHandler(log_loc)\n    handler.setLevel(logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    return logger, handler\n</code></pre>"},{"location":"api/helpers/#napari_ndev.helpers.setup_logger(log_loc)","title":"<code>log_loc</code>","text":"(<code>str or Path</code>, default:                   <code>Union[str, Path]</code> )           \u2013            <p>The path to the log file.</p>"},{"location":"api/image_overview/","title":"Image Overview","text":""},{"location":"api/image_overview/#napari_ndev.image_overview","title":"napari_ndev.image_overview","text":"<p>Function and class to create and manage image overviews with stackview.</p> <p>It includes a function <code>image_overview</code> to generate an overview of images and a class <code>ImageOverview</code> to generate and save image overviews.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview","title":"ImageOverview","text":"<p>A class for generating and saving image overviews.</p> <p>Use this class to prevent a memory leak otherwise generated by the image_overview() function when show=True. For some reason, preventing the memory leak requires the use of a class instead of a function, and show=False.</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>class ImageOverview:\n    \"\"\"\n    A class for generating and saving image overviews.\n\n    Use this class to prevent a memory leak otherwise generated by the\n    image_overview() function when show=True. For some reason, preventing\n    the memory leak requires the use of a class instead of a function, and\n    show=False.\n    \"\"\"\n\n    def __init__(\n        self,\n        image_sets: ImageSet | list[ImageSet] | dict | list[dict],\n        fig_scale: tuple[float, float] = (3, 3),\n        fig_title: str = '',\n        scalebar: float | dict | None = None,\n        show: bool = False,\n    ):\n        \"\"\"\n        Initialize an ImageOverivew object.\n\n        Parameters\n        ----------\n        image_sets : ImageSet, list of ImageSet, dict, or list of dict\n            A list of dictionaries, each containing an image set. Each image set\n            should be a dictionary containing the following keys:\n            - image (list): A list of images to display.\n            - title (list of str, optional): The title of the image set.\n            - colormap (list of str, optional): The colormap to use.\n                \"labels\" will display the image as labels.\n            - labels (list of bool, optional): Whether to display labels.\n            - **kwargs: Additional keyword arguments to pass to stackview.imshow.\n        fig_scale : tuple of float, optional\n            The scale of the plot. (Width, Height). Values lower than 2 are likely\n            to result in overlapping text. Increased values increase image size.\n            Defaults to (3, 3).\n        fig_title : str, optional\n            The title of the image overview. Default is an empty string.\n        scalebar : float or dict, optional\n            The scalebar to add to the image overview. If a float, it is used as\n            the dx parameter for the scalebar. If a dict, all **kwargs are passed\n            to the matplotlib_scalebar.scalebar.ScaleBar class. Defaults to None.\n        show : bool, optional\n            Whether to display the generated overview. Default is False.\n            Prevents memory leak when False.\n\n        \"\"\"\n        plt.ioff()\n        self.fig = image_overview(image_sets, fig_scale, fig_title, scalebar)\n        if show:\n            plt.show()\n        plt.close()\n\n    def save(\n        self,\n        directory: str | None = None,\n        filename: str | None = None,\n    ):\n        \"\"\"\n        Save the generated image overview with matplotlib.savefig.\n\n        Parameters\n        ----------\n        directory : str, optional\n            The directory to save the image overview. If not provided, the\n            current directory will be used.\n        filename : str, optional\n            The filename of the saved image overview. If not provided, a\n            default filename will be used.\n\n        \"\"\"\n        import pathlib\n\n        path_dir = pathlib.Path(directory)\n        path_dir.mkdir(parents=True, exist_ok=True)\n        filepath = path_dir / filename\n        self.fig.savefig(filepath)\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__","title":"__init__","text":"<pre><code>__init__(image_sets, fig_scale=(3, 3), fig_title='', scalebar=None, show=False)\n</code></pre> <p>Initialize an ImageOverivew object.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def __init__(\n    self,\n    image_sets: ImageSet | list[ImageSet] | dict | list[dict],\n    fig_scale: tuple[float, float] = (3, 3),\n    fig_title: str = '',\n    scalebar: float | dict | None = None,\n    show: bool = False,\n):\n    \"\"\"\n    Initialize an ImageOverivew object.\n\n    Parameters\n    ----------\n    image_sets : ImageSet, list of ImageSet, dict, or list of dict\n        A list of dictionaries, each containing an image set. Each image set\n        should be a dictionary containing the following keys:\n        - image (list): A list of images to display.\n        - title (list of str, optional): The title of the image set.\n        - colormap (list of str, optional): The colormap to use.\n            \"labels\" will display the image as labels.\n        - labels (list of bool, optional): Whether to display labels.\n        - **kwargs: Additional keyword arguments to pass to stackview.imshow.\n    fig_scale : tuple of float, optional\n        The scale of the plot. (Width, Height). Values lower than 2 are likely\n        to result in overlapping text. Increased values increase image size.\n        Defaults to (3, 3).\n    fig_title : str, optional\n        The title of the image overview. Default is an empty string.\n    scalebar : float or dict, optional\n        The scalebar to add to the image overview. If a float, it is used as\n        the dx parameter for the scalebar. If a dict, all **kwargs are passed\n        to the matplotlib_scalebar.scalebar.ScaleBar class. Defaults to None.\n    show : bool, optional\n        Whether to display the generated overview. Default is False.\n        Prevents memory leak when False.\n\n    \"\"\"\n    plt.ioff()\n    self.fig = image_overview(image_sets, fig_scale, fig_title, scalebar)\n    if show:\n        plt.show()\n    plt.close()\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(image_sets)","title":"<code>image_sets</code>","text":"(<code>ImageSet, list of ImageSet, dict, or list of dict</code>)           \u2013            <p>A list of dictionaries, each containing an image set. Each image set should be a dictionary containing the following keys: - image (list): A list of images to display. - title (list of str, optional): The title of the image set. - colormap (list of str, optional): The colormap to use.     \"labels\" will display the image as labels. - labels (list of bool, optional): Whether to display labels. - **kwargs: Additional keyword arguments to pass to stackview.imshow.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(fig_scale)","title":"<code>fig_scale</code>","text":"(<code>tuple of float</code>, default:                   <code>(3, 3)</code> )           \u2013            <p>The scale of the plot. (Width, Height). Values lower than 2 are likely to result in overlapping text. Increased values increase image size. Defaults to (3, 3).</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(fig_title)","title":"<code>fig_title</code>","text":"(<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The title of the image overview. Default is an empty string.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(scalebar)","title":"<code>scalebar</code>","text":"(<code>float or dict</code>, default:                   <code>None</code> )           \u2013            <p>The scalebar to add to the image overview. If a float, it is used as the dx parameter for the scalebar. If a dict, all **kwargs are passed to the matplotlib_scalebar.scalebar.ScaleBar class. Defaults to None.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.__init__(show)","title":"<code>show</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to display the generated overview. Default is False. Prevents memory leak when False.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.save","title":"save","text":"<pre><code>save(directory=None, filename=None)\n</code></pre> <p>Save the generated image overview with matplotlib.savefig.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def save(\n    self,\n    directory: str | None = None,\n    filename: str | None = None,\n):\n    \"\"\"\n    Save the generated image overview with matplotlib.savefig.\n\n    Parameters\n    ----------\n    directory : str, optional\n        The directory to save the image overview. If not provided, the\n        current directory will be used.\n    filename : str, optional\n        The filename of the saved image overview. If not provided, a\n        default filename will be used.\n\n    \"\"\"\n    import pathlib\n\n    path_dir = pathlib.Path(directory)\n    path_dir.mkdir(parents=True, exist_ok=True)\n    filepath = path_dir / filename\n    self.fig.savefig(filepath)\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.save(directory)","title":"<code>directory</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The directory to save the image overview. If not provided, the current directory will be used.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageOverview.save(filename)","title":"<code>filename</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The filename of the saved image overview. If not provided, a default filename will be used.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet","title":"ImageSet  <code>dataclass</code>","text":"<p>Image information passed to <code>stackview.imshow</code>.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>@dataclass\nclass ImageSet:\n    \"\"\"\n    Image information passed to `stackview.imshow`.\n\n    Parameters\n    ----------\n    image : list\n        A list of image data to display.\n    title : list of str, optional\n        The title of the image.\n    colormap : list of str, optional\n        The colormap to use. \"labels\" will display the image as labels.\n    labels : list of bool, optional\n        Whether to display image as a labels.\n    min_display_intensity : list of float, optional\n        The minimum display intensity, in the same units as the image.\n        Use `np.percentile(image, 0.1)` for 0.1th percentile.\n    max_display_intensity : list of float, optional\n        The maximum display intensity, in the same units as the image.\n        Use `np.percentile(image, 99.8)` for 99.9th percentile.\n\n    \"\"\"\n\n    image: list[ArrayLike]\n    title: list[str] | None = None\n    colormap: list[str] | None = None\n    labels: list[bool] | None = None\n    min_display_intensity: list[float] | None = None\n    max_display_intensity: list[float] | None = None\n\n    def __post_init__(self):\n        \"\"\"Set default values for colormap and labels if not provided.\"\"\"\n        if self.colormap is None:\n            self.colormap = [None] * len(self.image)\n        if self.labels is None:\n            self.labels = [False] * len(self.image)\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet(image)","title":"<code>image</code>","text":"(<code>list</code>)           \u2013            <p>A list of image data to display.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet(title)","title":"<code>title</code>","text":"(<code>list of str</code>, default:                   <code>None</code> )           \u2013            <p>The title of the image.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet(colormap)","title":"<code>colormap</code>","text":"(<code>list of str</code>, default:                   <code>None</code> )           \u2013            <p>The colormap to use. \"labels\" will display the image as labels.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet(labels)","title":"<code>labels</code>","text":"(<code>list of bool</code>, default:                   <code>None</code> )           \u2013            <p>Whether to display image as a labels.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet(min_display_intensity)","title":"<code>min_display_intensity</code>","text":"(<code>list of float</code>, default:                   <code>None</code> )           \u2013            <p>The minimum display intensity, in the same units as the image. Use <code>np.percentile(image, 0.1)</code> for 0.1th percentile.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet(max_display_intensity)","title":"<code>max_display_intensity</code>","text":"(<code>list of float</code>, default:                   <code>None</code> )           \u2013            <p>The maximum display intensity, in the same units as the image. Use <code>np.percentile(image, 99.8)</code> for 99.9th percentile.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.ImageSet.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Set default values for colormap and labels if not provided.</p> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Set default values for colormap and labels if not provided.\"\"\"\n    if self.colormap is None:\n        self.colormap = [None] * len(self.image)\n    if self.labels is None:\n        self.labels = [False] * len(self.image)\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview","title":"image_overview","text":"<pre><code>image_overview(image_sets, fig_scale=(3, 3), fig_title='', scalebar=None)\n</code></pre> <p>Create an overview of images.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>fig</code> (              <code>Figure</code> )          \u2013            <p>The matplotlib figure object containing the image overview.</p> </li> </ul> Source code in <code>src/napari_ndev/image_overview.py</code> <pre><code>def image_overview(\n    image_sets: ImageSet | list[ImageSet] | dict | list[dict],\n    fig_scale: tuple[float, float] = (3, 3),\n    fig_title: str = '',\n    scalebar: float | dict | None = None,\n):\n    \"\"\"\n    Create an overview of images.\n\n    Parameters\n    ----------\n    image_sets : ImageSet, list of ImageSet, dict, or list of dict\n        A list of `napari_ndev.image_overview.ImageSet objects containing\n        image information to display for `stackview.imshow`. Using a dict is\n        deprecated and will be removed in the future, but is supported by\n        passing the dictionary keys as arguments to the ImageSet constructor.\n        Will be removed in v1.0.0.\n    fig_scale : tuple of float, optional\n        The scale of the plot. (Width, Height). Values lower than 2 are likely\n        to result in overlapping text. Increased values increase image size.\n        Defaults to (3, 3).\n    fig_title : str, optional\n        The title of the plot. Defaults to an empty string.\n    scalebar : float or dict, optional\n        The scalebar to add to the image overview. If a float, it is used as\n        the dx parameter for the scalebar. If a dict, all **kwargs are passed\n        to the matplotlib_scalebar.scalebar.ScaleBar class. Defaults to None.\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The matplotlib figure object containing the image overview.\n\n    \"\"\"\n    # convert single image_set to list of image_set\n    image_sets = [image_sets] if isinstance(image_sets, (ImageSet, dict)) else image_sets\n\n    # if list of dicts convert to ImageSet, until deprecated\n    image_sets = _convert_dict_to_ImageSet(image_sets) if any(isinstance(image_set, dict) for image_set in image_sets) else image_sets\n\n    # create the subplot grid\n\n    # if only one image set, wrap rows and columns to get a nice aspect ratio\n    if len(image_sets) == 1:\n        num_images = len(image_sets[0].image)\n\n        if num_images &lt;= 3:\n            num_columns = num_images\n            num_rows = 1\n        # wrap so it is roughly a square aspect ratio\n        else:\n            num_columns = int(np.ceil(np.sqrt(num_images)))\n            num_rows = int(np.ceil(num_images / num_columns))\n\n    if len(image_sets) &gt; 1:\n        num_rows = len(image_sets)\n        num_columns = max([len(image_set.image) for image_set in image_sets])\n\n    # multiply scale of plot by number of columns and rows\n    fig, axs = plt.subplots(\n        num_rows,\n        num_columns,\n        figsize=(num_columns * fig_scale[0], num_rows * fig_scale[1]),\n    )\n\n    if num_rows == 1:\n        axs = [axs]\n    if num_columns == 1:\n        axs = [[ax] for ax in axs]\n\n    # iterate through the image sets\n    for image_set_idx, image_set in enumerate(image_sets):\n        for image_idx, image in enumerate(image_set.image):\n\n            # calculate the correct row and column for the subplot\n            if len(image_sets) == 1:\n                row =  image_idx // num_columns\n                col = image_idx % num_columns\n            if len(image_sets) &gt; 1:\n                row = image_set_idx\n                col = image_idx\n\n            # turn off the subplot and continue if there is no image\n            if image is None:\n                axs[row][col].axis('off')\n                continue\n\n            # set labels value to true, if its in the colormap\n            cmap = image_set.colormap[image_idx]\n            if cmap is not None and cmap.lower() == 'labels':\n                image_set.labels[image_idx] = True\n\n            stackview.imshow(\n                image = image,\n                title = image_set.title[image_idx] if image_set.title else None,\n                colormap = image_set.colormap[image_idx] if image_set.colormap else None,\n                labels = image_set.labels[image_idx] if image_set.labels else False,\n                min_display_intensity = image_set.min_display_intensity[image_idx] if image_set.min_display_intensity else None,\n                max_display_intensity = image_set.max_display_intensity[image_idx] if image_set.max_display_intensity else None,\n                plot=axs[row][col]\n            )\n\n            # add scalebar, if dict is present\n            if scalebar is not None:\n                _add_scalebar(axs[row][col], scalebar)\n\n    # remove empty subplots\n    for ax in fig.get_axes():\n        ax.axis('off') if not ax.get_images() else None\n\n    plt.suptitle(fig_title, fontsize=16)\n    plt.tight_layout(pad=0.3)\n\n    return fig\n</code></pre>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(image_sets)","title":"<code>image_sets</code>","text":"(<code>ImageSet, list of ImageSet, dict, or list of dict</code>)           \u2013            <p>A list of <code>napari_ndev.image_overview.ImageSet objects containing image information to display for</code>stackview.imshow`. Using a dict is deprecated and will be removed in the future, but is supported by passing the dictionary keys as arguments to the ImageSet constructor. Will be removed in v1.0.0.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(fig_scale)","title":"<code>fig_scale</code>","text":"(<code>tuple of float</code>, default:                   <code>(3, 3)</code> )           \u2013            <p>The scale of the plot. (Width, Height). Values lower than 2 are likely to result in overlapping text. Increased values increase image size. Defaults to (3, 3).</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(fig_title)","title":"<code>fig_title</code>","text":"(<code>str</code>, default:                   <code>''</code> )           \u2013            <p>The title of the plot. Defaults to an empty string.</p>"},{"location":"api/image_overview/#napari_ndev.image_overview.image_overview(scalebar)","title":"<code>scalebar</code>","text":"(<code>float or dict</code>, default:                   <code>None</code> )           \u2013            <p>The scalebar to add to the image overview. If a float, it is used as the dx parameter for the scalebar. If a dict, all **kwargs are passed to the matplotlib_scalebar.scalebar.ScaleBar class. Defaults to None.</p>"},{"location":"api/measure/","title":"Measure","text":""},{"location":"api/measure/#napari_ndev.measure","title":"napari_ndev.measure","text":"<p>Functions for measuring properties of labels.</p> <p>Measure properties of labels in images using sci-kit image's regionprops. It includes utilities for handling label and intensity images, extracting information from ID strings, renaming intensity columns, and mapping treatment dictionaries to DataFrame ID columns.</p> <p>Functions:</p> <ul> <li> <code>measure_regionprops : Measure properties of labels with sci-kit image regionprops.</code>             \u2013              </li> <li> <code>group_and_agg_measurements : Count and aggregate measurements by grouping IDs from measurement results.</code>             \u2013              </li> </ul>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements","title":"group_and_agg_measurements","text":"<pre><code>group_and_agg_measurements(\n    df, grouping_cols=\"id\", count_col=\"label\", agg_cols=None, agg_funcs=\"mean\"\n)\n</code></pre> <p>Count and aggregate measurements by grouping IDs from measurement results.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The DataFrame with grouped and aggregated measurements.</p> </li> </ul> Source code in <code>src/napari_ndev/measure.py</code> <pre><code>def group_and_agg_measurements(\n    df: pd.DataFrame,\n    grouping_cols: str | list[str] = 'id',\n    count_col: str = 'label',\n    agg_cols: str | list[str] | None = None,\n    agg_funcs: str | list[str] = 'mean',\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Count and aggregate measurements by grouping IDs from measurement results.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame with measurement properties, usually from measure_regionprops.\n    grouping_cols : str or list of str, optional\n        The columns to group by. By default, just the image ID.\n    count_col : str, optional\n        The column to count. By default, just the 'label' column.\n    agg_cols : list of str or None, optional\n        The columns to aggregate. By default, None.\n    agg_funcs : str or list of str, optional\n        The aggregating functions. By default, just the mean.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame with grouped and aggregated measurements.\n\n    \"\"\"\n    grouping_cols = _convert_to_list(grouping_cols)\n    agg_cols = _convert_to_list(agg_cols)\n    agg_funcs = _convert_to_list(agg_funcs)\n\n    # get count data\n    df_count = (\n            df.copy().groupby(grouping_cols)\n            .agg({count_col: 'count'}) # counts count_col\n            .rename(columns={count_col: f'{count_col}_count'})\n            .reset_index()\n        )\n\n    if agg_cols is None or agg_cols == []:\n        return df_count\n\n    # get aggregated data\n    agg_cols = df[agg_cols]\n    agg_dict = {col: agg_funcs for col in agg_cols}\n    df_agg = (\n            df.copy()\n            .groupby(grouping_cols)  # sw\n            .agg(agg_dict)\n            .reset_index()\n        )  # genereates a multi-index\n        # collapse multi index and combine columns names with '_' sep\n    df_agg.columns = [\n            f'{col[0]}_{col[1]}' if col[1] else col[0]\n            for col in df_agg.columns\n        ]\n\n    # insert label count column into df_agg after grouping columns\n    insert_pos = 1 if isinstance(grouping_cols, str) else len(grouping_cols)\n    df_agg.insert(insert_pos, 'label_count', df_count['label_count'])\n\n    return df_agg\n</code></pre>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(df)","title":"<code>df</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame with measurement properties, usually from measure_regionprops.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(grouping_cols)","title":"<code>grouping_cols</code>","text":"(<code>str or list of str</code>, default:                   <code>'id'</code> )           \u2013            <p>The columns to group by. By default, just the image ID.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(count_col)","title":"<code>count_col</code>","text":"(<code>str</code>, default:                   <code>'label'</code> )           \u2013            <p>The column to count. By default, just the 'label' column.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(agg_cols)","title":"<code>agg_cols</code>","text":"(<code>list of str or None</code>, default:                   <code>None</code> )           \u2013            <p>The columns to aggregate. By default, None.</p>"},{"location":"api/measure/#napari_ndev.measure.group_and_agg_measurements(agg_funcs)","title":"<code>agg_funcs</code>","text":"(<code>str or list of str</code>, default:                   <code>'mean'</code> )           \u2013            <p>The aggregating functions. By default, just the mean.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops","title":"measure_regionprops","text":"<pre><code>measure_regionprops(\n    label_images,\n    label_names=None,\n    intensity_images=None,\n    intensity_names=None,\n    properties=None,\n    scale=(1, 1),\n    id_string=None,\n    id_regex_dict=None,\n    tx_id=None,\n    tx_dict=None,\n    tx_n_well=None,\n    tx_leading_zeroes=False,\n    save_data_path=None,\n)\n</code></pre> <p>Measure properties of labels with sci-kit image regionprops.</p> <p>Optionally give a list of intensity_images to measure intensity properties of labels (i.e. 'intensity_mean', 'intensity_min', 'intensity_max', 'intensity_std'). If no label or intensity names are given, the names are automatically generated as a string of the input variable name. Choose from a list of properties to measure: [         \"label\",         \"area\",         \"area_convex\",         \"bbox\",         \"centroid\",         \"eccentricity\",         \"extent\",         \"feret_diameter_max\",         \"intensity_max\",         \"intensity_mean\",         \"intensity_min\",         \"intensity_std\",         \"num_pixels\",         \"orientation\",         \"perimeter\",         \"solidity\",     ].</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The DataFrame with measured properties.</p> </li> </ul> Source code in <code>src/napari_ndev/measure.py</code> <pre><code>def measure_regionprops(\n    label_images: list[ArrayLike] | ArrayLike,\n    label_names: list[str] | str | None = None,\n    intensity_images: list[ArrayLike] | ArrayLike | None = None,\n    intensity_names: list[str] | str | None = None,\n    properties: list[str] | None = None,\n    scale: tuple[float, float] | tuple[float, float, float] = (1, 1),\n    id_string: str | None = None,\n    id_regex_dict: dict | None = None,\n    tx_id: str | None = None,\n    tx_dict: dict | None = None,\n    tx_n_well: int | None = None,\n    tx_leading_zeroes: bool = False,\n    save_data_path: PathLike = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Measure properties of labels with sci-kit image regionprops.\n\n    Optionally give a list of intensity_images to measure intensity properties\n    of labels (i.e. 'intensity_mean', 'intensity_min', 'intensity_max',\n    'intensity_std'). If no label or intensity names are given, the names are\n    automatically generated as a string of the input variable name.\n    Choose from a list of properties to measure: [\n            \"label\",\n            \"area\",\n            \"area_convex\",\n            \"bbox\",\n            \"centroid\",\n            \"eccentricity\",\n            \"extent\",\n            \"feret_diameter_max\",\n            \"intensity_max\",\n            \"intensity_mean\",\n            \"intensity_min\",\n            \"intensity_std\",\n            \"num_pixels\",\n            \"orientation\",\n            \"perimeter\",\n            \"solidity\",\n        ].\n\n    Parameters\n    ----------\n    label_images : list of ArrayLike or ArrayLike\n        The label images.\n    label_names : list of str or str or None, optional\n        The names of the label images.\n    intensity_images : list of ArrayLike or ArrayLike or None, optional\n        The intensity images.\n    intensity_names : list of str or str or None, optional\n        The names of the intensity images.\n    properties : list of str or None, optional\n        The properties to measure.\n    scale : tuple of float, optional\n        The scale for the measurements.\n    id_string : str or None, optional\n        The ID string.\n    id_regex_dict : dict or None, optional\n        The regex dictionary for extracting information from the ID string.\n    tx_id : str or None, optional\n        The treatment ID.\n    tx_dict : dict or None, optional\n        The treatment dictionary.\n    tx_n_well : int or None, optional\n        The number of wells in the plate.\n    tx_leading_zeroes : bool, optional\n        Whether to use leading zeroes in the plate map.\n    save_data_path : PathLike or None, optional\n        The path to save the data.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame with measured properties.\n\n    \"\"\"\n    from skimage import measure\n\n    if properties is None:\n        properties = ['area']\n    measure_dict = _generate_measure_dict(\n        label_images, label_names, intensity_images, intensity_names\n    )\n\n    if intensity_images is not None:\n        if len(measure_dict['intensity_images']) == 1:\n            intensity_stack = measure_dict['intensity_images'][0]\n        else:\n            intensity_stack = np.stack(\n                measure_dict['intensity_images'], axis=-1\n            )\n    else:\n        intensity_stack = None\n\n    measure_df_list = []\n\n    for label_idx, label_image in enumerate(measure_dict['label_images']):\n        measure_props = measure.regionprops_table(\n            label_image=label_image,\n            intensity_image=intensity_stack,\n            properties=properties,\n            spacing=scale,\n        )\n\n        measure_df = pd.DataFrame(measure_props)\n        measure_df.insert(0, 'label_name', measure_dict['label_names'][label_idx])\n        measure_df_list.append(measure_df)\n\n    if len(measure_df_list) &gt; 1:\n        measure_df = pd.concat(measure_df_list, ignore_index=True)\n\n    if intensity_names is not None:\n        measure_df = _rename_intensity_columns(\n            measure_df, measure_dict['intensity_names']\n        )\n\n    measure_df.insert(1, 'id', id_string)\n\n    if id_regex_dict is not None:\n        id_dict = _extract_info_from_id_string(id_string, id_regex_dict)\n        for key, value in id_dict.items():\n            measure_df.insert(2, key, value)\n\n    if tx_id is not None and tx_dict is not None:\n        _map_tx_dict_to_df_id_col(tx_dict, tx_n_well, tx_leading_zeroes, measure_df, tx_id)\n\n    if save_data_path is not None:\n        measure_df.to_csv(save_data_path, index=False)\n\n    return measure_df\n</code></pre>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(label_images)","title":"<code>label_images</code>","text":"(<code>list of ArrayLike or ArrayLike</code>)           \u2013            <p>The label images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(label_names)","title":"<code>label_names</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the label images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(intensity_images)","title":"<code>intensity_images</code>","text":"(<code>list of ArrayLike or ArrayLike or None</code>, default:                   <code>None</code> )           \u2013            <p>The intensity images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(intensity_names)","title":"<code>intensity_names</code>","text":"(<code>list of str or str or None</code>, default:                   <code>None</code> )           \u2013            <p>The names of the intensity images.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(properties)","title":"<code>properties</code>","text":"(<code>list of str or None</code>, default:                   <code>None</code> )           \u2013            <p>The properties to measure.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(scale)","title":"<code>scale</code>","text":"(<code>tuple of float</code>, default:                   <code>(1, 1)</code> )           \u2013            <p>The scale for the measurements.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(id_string)","title":"<code>id_string</code>","text":"(<code>str or None</code>, default:                   <code>None</code> )           \u2013            <p>The ID string.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(id_regex_dict)","title":"<code>id_regex_dict</code>","text":"(<code>dict or None</code>, default:                   <code>None</code> )           \u2013            <p>The regex dictionary for extracting information from the ID string.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_id)","title":"<code>tx_id</code>","text":"(<code>str or None</code>, default:                   <code>None</code> )           \u2013            <p>The treatment ID.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_dict)","title":"<code>tx_dict</code>","text":"(<code>dict or None</code>, default:                   <code>None</code> )           \u2013            <p>The treatment dictionary.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_n_well)","title":"<code>tx_n_well</code>","text":"(<code>int or None</code>, default:                   <code>None</code> )           \u2013            <p>The number of wells in the plate.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(tx_leading_zeroes)","title":"<code>tx_leading_zeroes</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use leading zeroes in the plate map.</p>"},{"location":"api/measure/#napari_ndev.measure.measure_regionprops(save_data_path)","title":"<code>save_data_path</code>","text":"(<code>PathLike or None</code>, default:                   <code>None</code> )           \u2013            <p>The path to save the data.</p>"},{"location":"api/morphology/","title":"Morphology","text":""},{"location":"api/morphology/#napari_ndev.morphology","title":"napari_ndev.morphology","text":"<p>Functions for processing label morphology.</p> <p>Process labels with various functions using pyclesperanto and scikit-image. Intended to be compatible with workflow.yaml files, and will be incorporated into napari-workflows and napari-assistant in the future. Should accept both OCLArray and other ArrayLike types.</p> <p>Functions:</p> <ul> <li> <code>skeletonize_labels : Create skeletons with label identities from a label image.</code>             \u2013              </li> </ul>"},{"location":"api/morphology/#napari_ndev.morphology.connect_breaks_between_labels","title":"connect_breaks_between_labels","text":"<pre><code>connect_breaks_between_labels(label, connect_distance)\n</code></pre> <p>Connect breaks between labels in a label image.</p> <p>Return the input label image with new label identities connecting breaks between the original labels. The new labels have the original label dimensions, so this is intended to keep the overall morphology the same, just with new labels connecting the original labels if under the specified distance.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ArrayLike</code>           \u2013            <p>Label image with new labels connecting breaks between original labels.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def connect_breaks_between_labels(label: ArrayLike, connect_distance: float) -&gt; ArrayLike: # pragma: no cover\n    \"\"\"\n    Connect breaks between labels in a label image.\n\n    Return the input label image with new label identities connecting breaks\n    between the original labels. The new labels have the original label\n    dimensions, so this is intended to keep the overall morphology the same,\n    just with new labels connecting the original labels if under the specified\n    distance.\n\n    Parameters\n    ----------\n    label : ArrayLike\n        Label image.\n    connect_distance : float\n        Maximum distance to connect labels, in pixels.\n\n    Returns\n    -------\n    ArrayLike\n        Label image with new labels connecting breaks between original labels.\n\n    \"\"\"\n    import pyclesperanto_prototype as cle\n\n    label_dilated = cle.dilate_labels(label, radius=connect_distance/2)\n    label_merged = cle.merge_touching_labels(label_dilated)\n    # relabel original labels based on the merged labels\n    return (label_merged * (label &gt; 0)).astype(np.uint16)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.connect_breaks_between_labels(label)","title":"<code>label</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.connect_breaks_between_labels(connect_distance)","title":"<code>connect_distance</code>","text":"(<code>float</code>)           \u2013            <p>Maximum distance to connect labels, in pixels.</p>"},{"location":"api/morphology/#napari_ndev.morphology.convert_float_to_int","title":"convert_float_to_int","text":"<pre><code>convert_float_to_int(img)\n</code></pre> <p>Convert an image from float to integer.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ArrayLike</code>           \u2013            <p>Label image as integer.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def convert_float_to_int(img: ArrayLike) -&gt; ArrayLike:\n    \"\"\"\n    Convert an image from float to integer.\n\n    Parameters\n    ----------\n    img : ArrayLike\n        Label image.\n\n    Returns\n    -------\n    ArrayLike\n        Label image as integer.\n\n    \"\"\"\n    return img.astype(np.uint32)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.convert_float_to_int(img)","title":"<code>img</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.label_voronoi_based_on_intensity","title":"label_voronoi_based_on_intensity","text":"<pre><code>label_voronoi_based_on_intensity(label, intensity_image)\n</code></pre> <p>Create a voronoi label masks of labels based on an intensity image.</p> <p>Return a label image with Voronoi regions based on the intensity image. The intensity image should be the same shape as the label image, and the labels will be assigned to the Voronoi regions based on the intensity values.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ArrayLike</code>           \u2013            <p>Label image with Voronoi regions based on the intensity image.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def label_voronoi_based_on_intensity(label: ArrayLike, intensity_image: ArrayLike) -&gt; ArrayLike: # pragma: no cover\n    \"\"\"\n    Create a voronoi label masks of labels based on an intensity image.\n\n    Return a label image with Voronoi regions based on the intensity image.\n    The intensity image should be the same shape as the label image, and the\n    labels will be assigned to the Voronoi regions based on the intensity\n    values.\n\n    Parameters\n    ----------\n    label : ArrayLike\n        Label image.\n    intensity_image : ArrayLike\n        Intensity image.\n\n    Returns\n    -------\n    ArrayLike\n        Label image with Voronoi regions based on the intensity image.\n\n    \"\"\"\n    import pyclesperanto_prototype as cle\n\n    label_binary = cle.greater_constant(label, constant=0) # binarize\n    intensity_blur = cle.gaussian_blur(intensity_image, sigma_x=1, sigma_y=1)\n    intensity_peaks = cle.detect_maxima_box(intensity_blur, radius_x=0, radius_y=0)\n    select_peaks_on_binary = cle.binary_and(intensity_peaks, label_binary)\n    return cle.masked_voronoi_labeling(select_peaks_on_binary, label_binary)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.label_voronoi_based_on_intensity(label)","title":"<code>label</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.label_voronoi_based_on_intensity(intensity_image)","title":"<code>intensity_image</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Intensity image.</p>"},{"location":"api/morphology/#napari_ndev.morphology.skeletonize_labels","title":"skeletonize_labels","text":"<pre><code>skeletonize_labels(label)\n</code></pre> <p>Create skeletons and maintains label identities from a label image.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Skeletonized label image.</p> </li> </ul> Source code in <code>src/napari_ndev/morphology.py</code> <pre><code>def skeletonize_labels(label: ArrayLike) -&gt; np.ndarray:\n    \"\"\"\n    Create skeletons and maintains label identities from a label image.\n\n    Parameters\n    ----------\n    label : ArrayLike\n        Label image.\n\n    Returns\n    -------\n    np.ndarray\n        Skeletonized label image.\n\n    \"\"\"\n    import pyclesperanto_prototype as cle\n    from skimage.morphology import skeletonize\n\n    skeleton = skeletonize(cle.pull(label))\n    return (label * skeleton).astype(np.uint16)\n</code></pre>"},{"location":"api/morphology/#napari_ndev.morphology.skeletonize_labels(label)","title":"<code>label</code>","text":"(<code>ArrayLike</code>)           \u2013            <p>Label image.</p>"},{"location":"api/nimage/","title":"nImage","text":""},{"location":"api/nimage/#napari_ndev.nimage","title":"napari_ndev.nimage","text":"<p>Additional functionality for BioImage objects to be used in napari-ndev.</p>"},{"location":"api/nimage/#napari_ndev.nimage.nImage","title":"nImage","text":"<p>               Bases: <code>BioImage</code></p> <p>An nImage is a BioImage with additional functionality for napari-ndev.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>See BioImage for inherited attributes.</code>           \u2013            </li> </ul> <p>Methods:</p> <ul> <li> <code>get_napari_image_data</code>             \u2013              <p>Get the image data as a xarray, optionally loading it into memory.</p> </li> </ul> Source code in <code>src/napari_ndev/nimage.py</code> <pre><code>class nImage(BioImage):\n    \"\"\"\n    An nImage is a BioImage with additional functionality for napari-ndev.\n\n    Parameters\n    ----------\n    image : ImageLike\n        Image to be loaded. Can be a path to an image file, a numpy array,\n        or an xarray DataArray.\n    reader : Reader, optional\n        Reader to be used to load the image. If not provided, a reader will be\n        determined based on the image type.\n\n    Attributes\n    ----------\n    See BioImage for inherited attributes.\n\n    Methods\n    -------\n    get_napari_image_data(in_memory=None)\n        Get the image data as a xarray, optionally loading it into memory.\n\n\n    \"\"\"\n\n    def __init__(\n        self,\n        image: ImageLike,\n        reader: Reader | None = None\n    ) -&gt; None:\n        \"\"\"\n        Initialize an nImage with an image, and optionally a reader.\n\n        If a reader is not provided, a reader will be determined by bioio.\n        However, if the image is supported by bioio-ome-tiff, the reader\n        will be set to bioio_ome_tiff.Reader to override the softer decision\n        made by bioio.BioImage.determine_plugin().\n\n        Note: The issue here is that bioio.BioImage.determine_plugin() will\n        sort by install time and choose the first plugin that supports the\n        image. This is not always the desired behavior, because bioio-tifffile\n        can take precedence over bioio-ome-tiff, even if the image was saved\n        as an OME-TIFF via bioio.writers.OmeTiffWriter (which is the case\n        for napari-ndev).\n        \"\"\"\n        if reader is None:\n            from bioio import plugin_feasibility_report as pfr\n            fr = pfr(image)\n            if 'bioio-ome-tiff' in fr and fr['bioio-ome-tiff'].supported:\n                import bioio_ome_tiff\n                reader = bioio_ome_tiff.Reader\n\n        super().__init__(image, reader)\n        self.napari_data = None\n        self.napari_metadata = {}\n        self.path = image if isinstance(image, (str, Path)) else None\n\n    def _determine_in_memory(\n        self,\n        path=None,\n        max_in_mem_bytes: int = 4e9,\n        max_in_mem_percent: int = 0.3\n    ) -&gt; bool:\n        \"\"\"\n        Determine whether the image should be loaded into memory or not.\n\n        If the image is smaller than the maximum filesize or percentage of the\n        available memory, this will determine to load image in memory.\n        Otherwise, suggest to load as a dask array.\n\n        Parameters\n        ----------\n        path : str or Path\n            Path to the image file.\n        max_in_mem_bytes : int\n            Maximum number of bytes that can be loaded into memory.\n            Default is 4 GB (4e9 bytes)\n        max_in_mem_percent : float\n            Maximum percentage of memory that can be loaded into memory.\n            Default is 30% of available memory (0.3)\n\n        Returns\n        -------\n        bool\n            True if image should be loaded in memory, False otherwise.\n\n        \"\"\"\n        from bioio_base.io import pathlike_to_fs\n        from psutil import virtual_memory\n\n        if path is None:\n            path = self.path\n\n        fs, path = pathlike_to_fs(path)\n        filesize = fs.size(path)\n        available_mem = virtual_memory().available\n        return (\n            filesize &lt;= max_in_mem_bytes\n            and filesize &lt; max_in_mem_percent * available_mem\n        )\n\n    def get_napari_image_data(self, in_memory: bool | None = None) -&gt; xr.DataArray:\n        \"\"\"\n        Get the image data as a xarray DataArray.\n\n        From BioImage documentation:\n        If you do not want the image pre-stitched together, you can use the base reader\n        by either instantiating the reader independently or using the `.reader` property.\n\n        Parameters\n        ----------\n        in_memory : bool, optional\n            Whether to load the image in memory or not.\n            If None, will determine whether to load in memory based on the image size.\n\n        Returns\n        -------\n        xr.DataArray\n            Image data as a xarray DataArray.\n\n        \"\"\"\n        if in_memory is None:\n            in_memory = self._determine_in_memory()\n\n        if DimensionNames.MosaicTile in self.reader.dims.order:\n            try:\n                if in_memory:\n                    self.napari_data = self.reader.mosaic_xarray_data.squeeze()\n                else:\n                    self.napari_data = self.reader.mosaic_xarray_dask_data.squeeze()\n\n            except NotImplementedError:\n                logger.warning(\n                    \"Bioio: Mosaic tile switching not supported for this reader\"\n                )\n                return None\n        else:\n            if in_memory:\n                self.napari_data = self.reader.xarray_data.squeeze()\n            else:\n                self.napari_data = self.reader.xarray_dask_data.squeeze()\n\n        return self.napari_data\n\n    def get_napari_metadata(\n        self,\n        path: PathLike,\n    ) -&gt; dict:\n        \"\"\"\n        Get the metadata for the image to be displayed in napari.\n\n        Parameters\n        ----------\n        path : PathLike\n            Path to the image file.\n\n        Returns\n        -------\n        dict\n            Metadata for the image to be displayed in napari.\n\n        \"\"\"\n        if self.napari_data is None:\n            self.get_napari_image_data() # this also sets self.path\n\n        meta = {}\n        scene = self.current_scene\n        scene_idx = self.current_scene_index\n        single_no_scene = len(self.scenes) == 1 and self.current_scene == \"Image:0\"\n        channel_dim = DimensionNames.Channel\n\n        if channel_dim in self.napari_data.dims:\n            # use filename if single scene and no scene name available\n            if single_no_scene:\n                channels_with_scene_index = [\n                    f'{C}{LABEL_DELIMITER}{Path(path).stem}'\n                    for C in self.napari_data.coords[channel_dim].data.tolist()\n                ]\n            else:\n                channels_with_scene_index = [\n                    f'{C}{LABEL_DELIMITER}{scene_idx}{LABEL_DELIMITER}{scene}'\n                    for C in self.napari_data.coords[channel_dim].data.tolist()\n                ]\n            meta['name'] = channels_with_scene_index\n            meta['channel_axis'] = self.napari_data.dims.index(channel_dim)\n\n        # not multi-chnanel, use current scene as image name\n        else:\n            if single_no_scene:\n                meta['name'] = Path(path).stem\n            else:\n                meta['name'] = self.reader.current_scene\n\n        # Handle if RGB\n        if DimensionNames.Samples in self.reader.dims.order:\n            meta['rgb'] = True\n\n        # Handle scales\n        scale = [\n            getattr(self.physical_pixel_sizes, dim)\n            for dim in self.napari_data.dims\n            if dim in {DimensionNames.SpatialX, DimensionNames.SpatialY, DimensionNames.SpatialZ}\n            and getattr(self.physical_pixel_sizes, dim) is not None\n        ]\n\n        if scale:\n            meta['scale'] = tuple(scale)\n\n        # get all other metadata\n        img_meta = {'bioimage': self, 'raw_image_metadata': self.metadata}\n\n        with contextlib.suppress(NotImplementedError):\n            img_meta['metadata'] = self.ome_metadata\n\n        meta['metadata'] = img_meta\n        self.napari_metadata = meta\n        return self.napari_metadata\n</code></pre>"},{"location":"api/nimage/#napari_ndev.nimage.nImage(image)","title":"<code>image</code>","text":"(<code>ImageLike</code>)           \u2013            <p>Image to be loaded. Can be a path to an image file, a numpy array, or an xarray DataArray.</p>"},{"location":"api/nimage/#napari_ndev.nimage.nImage(reader)","title":"<code>reader</code>","text":"(<code>Reader</code>, default:                   <code>None</code> )           \u2013            <p>Reader to be used to load the image. If not provided, a reader will be determined based on the image type.</p>"},{"location":"api/nimage/#napari_ndev.nimage.nImage.__init__","title":"__init__","text":"<pre><code>__init__(image, reader=None)\n</code></pre> <p>Initialize an nImage with an image, and optionally a reader.</p> <p>If a reader is not provided, a reader will be determined by bioio. However, if the image is supported by bioio-ome-tiff, the reader will be set to bioio_ome_tiff.Reader to override the softer decision made by bioio.BioImage.determine_plugin().</p> <p>Note: The issue here is that bioio.BioImage.determine_plugin() will sort by install time and choose the first plugin that supports the image. This is not always the desired behavior, because bioio-tifffile can take precedence over bioio-ome-tiff, even if the image was saved as an OME-TIFF via bioio.writers.OmeTiffWriter (which is the case for napari-ndev).</p> Source code in <code>src/napari_ndev/nimage.py</code> <pre><code>def __init__(\n    self,\n    image: ImageLike,\n    reader: Reader | None = None\n) -&gt; None:\n    \"\"\"\n    Initialize an nImage with an image, and optionally a reader.\n\n    If a reader is not provided, a reader will be determined by bioio.\n    However, if the image is supported by bioio-ome-tiff, the reader\n    will be set to bioio_ome_tiff.Reader to override the softer decision\n    made by bioio.BioImage.determine_plugin().\n\n    Note: The issue here is that bioio.BioImage.determine_plugin() will\n    sort by install time and choose the first plugin that supports the\n    image. This is not always the desired behavior, because bioio-tifffile\n    can take precedence over bioio-ome-tiff, even if the image was saved\n    as an OME-TIFF via bioio.writers.OmeTiffWriter (which is the case\n    for napari-ndev).\n    \"\"\"\n    if reader is None:\n        from bioio import plugin_feasibility_report as pfr\n        fr = pfr(image)\n        if 'bioio-ome-tiff' in fr and fr['bioio-ome-tiff'].supported:\n            import bioio_ome_tiff\n            reader = bioio_ome_tiff.Reader\n\n    super().__init__(image, reader)\n    self.napari_data = None\n    self.napari_metadata = {}\n    self.path = image if isinstance(image, (str, Path)) else None\n</code></pre>"},{"location":"api/nimage/#napari_ndev.nimage.nImage.get_napari_image_data","title":"get_napari_image_data","text":"<pre><code>get_napari_image_data(in_memory=None)\n</code></pre> <p>Get the image data as a xarray DataArray.</p> <p>From BioImage documentation: If you do not want the image pre-stitched together, you can use the base reader by either instantiating the reader independently or using the <code>.reader</code> property.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataArray</code>           \u2013            <p>Image data as a xarray DataArray.</p> </li> </ul> Source code in <code>src/napari_ndev/nimage.py</code> <pre><code>def get_napari_image_data(self, in_memory: bool | None = None) -&gt; xr.DataArray:\n    \"\"\"\n    Get the image data as a xarray DataArray.\n\n    From BioImage documentation:\n    If you do not want the image pre-stitched together, you can use the base reader\n    by either instantiating the reader independently or using the `.reader` property.\n\n    Parameters\n    ----------\n    in_memory : bool, optional\n        Whether to load the image in memory or not.\n        If None, will determine whether to load in memory based on the image size.\n\n    Returns\n    -------\n    xr.DataArray\n        Image data as a xarray DataArray.\n\n    \"\"\"\n    if in_memory is None:\n        in_memory = self._determine_in_memory()\n\n    if DimensionNames.MosaicTile in self.reader.dims.order:\n        try:\n            if in_memory:\n                self.napari_data = self.reader.mosaic_xarray_data.squeeze()\n            else:\n                self.napari_data = self.reader.mosaic_xarray_dask_data.squeeze()\n\n        except NotImplementedError:\n            logger.warning(\n                \"Bioio: Mosaic tile switching not supported for this reader\"\n            )\n            return None\n    else:\n        if in_memory:\n            self.napari_data = self.reader.xarray_data.squeeze()\n        else:\n            self.napari_data = self.reader.xarray_dask_data.squeeze()\n\n    return self.napari_data\n</code></pre>"},{"location":"api/nimage/#napari_ndev.nimage.nImage.get_napari_image_data(in_memory)","title":"<code>in_memory</code>","text":"(<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>Whether to load the image in memory or not. If None, will determine whether to load in memory based on the image size.</p>"},{"location":"api/nimage/#napari_ndev.nimage.nImage.get_napari_metadata","title":"get_napari_metadata","text":"<pre><code>get_napari_metadata(path)\n</code></pre> <p>Get the metadata for the image to be displayed in napari.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>Metadata for the image to be displayed in napari.</p> </li> </ul> Source code in <code>src/napari_ndev/nimage.py</code> <pre><code>def get_napari_metadata(\n    self,\n    path: PathLike,\n) -&gt; dict:\n    \"\"\"\n    Get the metadata for the image to be displayed in napari.\n\n    Parameters\n    ----------\n    path : PathLike\n        Path to the image file.\n\n    Returns\n    -------\n    dict\n        Metadata for the image to be displayed in napari.\n\n    \"\"\"\n    if self.napari_data is None:\n        self.get_napari_image_data() # this also sets self.path\n\n    meta = {}\n    scene = self.current_scene\n    scene_idx = self.current_scene_index\n    single_no_scene = len(self.scenes) == 1 and self.current_scene == \"Image:0\"\n    channel_dim = DimensionNames.Channel\n\n    if channel_dim in self.napari_data.dims:\n        # use filename if single scene and no scene name available\n        if single_no_scene:\n            channels_with_scene_index = [\n                f'{C}{LABEL_DELIMITER}{Path(path).stem}'\n                for C in self.napari_data.coords[channel_dim].data.tolist()\n            ]\n        else:\n            channels_with_scene_index = [\n                f'{C}{LABEL_DELIMITER}{scene_idx}{LABEL_DELIMITER}{scene}'\n                for C in self.napari_data.coords[channel_dim].data.tolist()\n            ]\n        meta['name'] = channels_with_scene_index\n        meta['channel_axis'] = self.napari_data.dims.index(channel_dim)\n\n    # not multi-chnanel, use current scene as image name\n    else:\n        if single_no_scene:\n            meta['name'] = Path(path).stem\n        else:\n            meta['name'] = self.reader.current_scene\n\n    # Handle if RGB\n    if DimensionNames.Samples in self.reader.dims.order:\n        meta['rgb'] = True\n\n    # Handle scales\n    scale = [\n        getattr(self.physical_pixel_sizes, dim)\n        for dim in self.napari_data.dims\n        if dim in {DimensionNames.SpatialX, DimensionNames.SpatialY, DimensionNames.SpatialZ}\n        and getattr(self.physical_pixel_sizes, dim) is not None\n    ]\n\n    if scale:\n        meta['scale'] = tuple(scale)\n\n    # get all other metadata\n    img_meta = {'bioimage': self, 'raw_image_metadata': self.metadata}\n\n    with contextlib.suppress(NotImplementedError):\n        img_meta['metadata'] = self.ome_metadata\n\n    meta['metadata'] = img_meta\n    self.napari_metadata = meta\n    return self.napari_metadata\n</code></pre>"},{"location":"api/nimage/#napari_ndev.nimage.nImage.get_napari_metadata(path)","title":"<code>path</code>","text":"(<code>PathLike</code>)           \u2013            <p>Path to the image file.</p>"},{"location":"api/plate_mapper/","title":"PlateMapper","text":""},{"location":"api/plate_mapper/#napari_ndev._plate_mapper","title":"napari_ndev._plate_mapper","text":""},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper","title":"PlateMapper","text":"<p>A class for creating and manipulating plate maps.</p> <p>Attributes:</p> <ul> <li> <code>plate_size</code>               (<code>int</code>)           \u2013            <p>The size of the plate (e.g., 96, 384). Defaults to 96.</p> </li> <li> <code>leading_zeroes</code>               (<code>bool</code>)           \u2013            <p>Whether to include leading zeroes in the column labels. Defaults to False.</p> </li> <li> <code>treatments</code>               (<code>dict</code>)           \u2013            <p>A dictionary mapping treatments to conditions and well ranges.</p> </li> <li> <code>wells</code>               (<code>dict</code>)           \u2013            <p>A dictionary mapping plate sizes to the number of rows and columns.</p> </li> <li> <code>plate_map</code>               (<code>DataFrame</code>)           \u2013            <p>The plate map DataFrame with well labels.</p> </li> <li> <code>pivoted_plate_map</code>               (<code>DataFrame</code>)           \u2013            <p>The wide-formatted plate map DataFrame with treatments as columns. Pivots only one treatment at a time.</p> </li> <li> <code>styled_plate_map</code>               (<code>Styler</code>)           \u2013            <p>The styled pivoted plate map DataFrame with different background colors for each unique value.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>__init__</code>             \u2013              <p>Initializes a PlateMapper object.</p> </li> <li> <code>create_empty_plate_map</code>             \u2013              <p>Creates an empty plate map DataFrame for a given plate size.</p> </li> <li> <code>assign_treatments</code>             \u2013              <p>Assigns treatments to specific wells in a plate map.</p> </li> <li> <code>get_pivoted_plate_map</code>             \u2013              <p>Pivots a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.</p> </li> <li> <code>get_styled_plate_map</code>             \u2013              <p>Styles a plate map DataFrame with different background colors for each unique value.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>class PlateMapper:\n    \"\"\"\n    A class for creating and manipulating plate maps.\n\n    Attributes\n    ----------\n    plate_size : int\n        The size of the plate (e.g., 96, 384).\n        Defaults to 96.\n    leading_zeroes : bool\n        Whether to include leading zeroes in the column labels.\n        Defaults to False.\n    treatments : dict\n        A dictionary mapping treatments to conditions and well ranges.\n    wells : dict\n        A dictionary mapping plate sizes to the number of rows and columns.\n    plate_map : pandas.DataFrame\n        The plate map DataFrame with well labels.\n    pivoted_plate_map : pandas.DataFrame\n        The wide-formatted plate map DataFrame with treatments as columns.\n        Pivots only one treatment at a time.\n    styled_plate_map : pandas.io.formats.style.Styler\n        The styled pivoted plate map DataFrame with different background\n        colors for each unique value.\n\n    Methods\n    -------\n    __init__(plate_size=96)\n        Initializes a PlateMapper object.\n    create_empty_plate_map()\n        Creates an empty plate map DataFrame for a given plate size.\n    assign_treatments(treatments)\n        Assigns treatments to specific wells in a plate map.\n    get_pivoted_plate_map(treatment)\n        Pivots a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.\n    get_styled_plate_map(treatment, palette='colorblind')\n        Styles a plate map DataFrame with different background colors for each unique value.\n\n    \"\"\"\n\n    def __init__(self, plate_size=96, treatments=None, leading_zeroes=False, ):\n        \"\"\"\n        Initialize a PlateMapper object.\n\n        Parameters\n        ----------\n        plate_size : int, optional\n            The size of the plate. Defaults to 96.\n        leading_zeroes : bool, optional\n            Whether to include leading zeroes in the column labels.\n            Defaults to False.\n        treatments : dict, optional\n            A dictionary mapping treatments to conditions and well ranges.\n            If provided, the treatments will be assigned to the plate map.\n            Defaults to None.\n\n        \"\"\"\n        self.plate_size = plate_size\n        self.leading_zeroes = leading_zeroes\n        self.wells = {\n            6: (2, 3),\n            12: (3, 4),\n            24: (4, 6),\n            48: (6, 8),\n            96: (8, 12),\n            384: (16, 24),\n        }\n        self.plate_map = self.create_empty_plate_map()\n        self.pivoted_plate_map = None\n        self.styled_plate_map = None\n\n        if treatments:\n            self.assign_treatments(treatments)\n            # pivot the first key in treatments\n            self.get_styled_plate_map(next(iter(treatments.keys())))\n\n    def create_empty_plate_map(self):\n        \"\"\"\n        Create an empty plate map DataFrame for a given plate size.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The empty plate map DataFrame with well labels.\n\n        \"\"\"\n        num_rows, num_columns = self.wells[self.plate_size]\n\n        row_labels = list(string.ascii_uppercase)[:num_rows]\n        if self.leading_zeroes:\n            column_labels = [f'{i:02d}' for i in range(1, num_columns + 1)]\n        else:\n            column_labels = list(range(1, num_columns + 1))\n\n        well_rows = row_labels * num_columns\n        well_rows.sort()  # needed to sort the rows correctly\n        well_columns = column_labels * num_rows\n\n        well_labels_dict = {'row': well_rows, 'column': well_columns}\n\n        plate_map_df = pd.DataFrame(well_labels_dict)\n\n        plate_map_df['well_id'] = plate_map_df['row'] + plate_map_df[\n            'column'\n        ].astype(str)\n        self.plate_map = plate_map_df\n        return plate_map_df\n\n    def assign_treatments(self, treatments):\n        \"\"\"\n        Assign treatments to specific wells in a plate map.\n\n        Parameters\n        ----------\n        treatments : dict\n            A dictionary mapping treatments to conditions and well ranges.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The updated plate map with treatments assigned to specific wells.\n\n        \"\"\"\n        for treatment, conditions in treatments.items():\n            for condition, wells in conditions.items():\n                for well in wells:\n                    if ':' in well:\n                        start, end = well.split(':')\n                        start_row, start_col = start[0], int(start[1:])\n                        end_row, end_col = end[0], int(end[1:])\n                        well_condition = (\n                            (self.plate_map['row'] &gt;= start_row)\n                            &amp; (self.plate_map['row'] &lt;= end_row)\n                            &amp; (self.plate_map['column'].astype(int) &gt;= start_col)\n                            &amp; (self.plate_map['column'].astype(int) &lt;= end_col)\n                        )\n                    else:\n                        row, col = well[0], int(well[1:])\n                        well_condition = (\n                            (self.plate_map['row'] == row)\n                            &amp; (self.plate_map['column'] == col)\n                        )\n\n                    self.plate_map.loc[well_condition, treatment] = condition\n        return self.plate_map\n\n    def get_pivoted_plate_map(self, treatment):\n        \"\"\"\n        Pivot a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.\n\n        Parameters\n        ----------\n        treatment : str\n            The column name of the treatment variable in the plate map DataFrame.\n\n        Returns\n        -------\n        pandas.DataFrame\n            The wide-formatted plate map DataFrame with treatments as columns.\n\n        \"\"\"\n        plate_map_pivot = self.plate_map.pivot(\n            index='row', columns='column', values=treatment\n        )\n        self.pivoted_plate_map = plate_map_pivot\n        return plate_map_pivot\n\n    def get_styled_plate_map(self, treatment, palette='colorblind'):\n        \"\"\"\n        Style a plate map with background colors for each unique value.\n\n        Parameters\n        ----------\n        treatment : str\n            The column name of the treatment variable in the plate map DataFrame.\n        palette : str or list, optional\n            The color palette to use for styling. Defaults to 'colorblind'.\n\n        Returns\n        -------\n        pandas.io.formats.style.Styler\n            The styled plate map DataFrame with different background colors for each unique value.\n\n        \"\"\"\n        from seaborn import color_palette\n\n        self.pivoted_plate_map = self.get_pivoted_plate_map(treatment)\n\n        unique_values = pd.unique(self.pivoted_plate_map.values.flatten())\n        unique_values = unique_values[pd.notna(unique_values)]\n\n        color_palette_hex = color_palette(palette).as_hex()\n        # Create an infinite iterator that cycles through the palette\n        palette_cycle = itertools.cycle(color_palette_hex)\n        # Use next() to get the next color\n        color_dict = {value: next(palette_cycle) for value in unique_values}\n\n        def get_background_color(value): # pragma: no cover\n            if pd.isna(value):\n                return ''\n            return f'background-color: {color_dict[value]}'\n\n        plate_map_styled = (\n            self.pivoted_plate_map.style.applymap(get_background_color)\n            .set_caption(f'{treatment} Plate Map')\n            .format(lambda x: '' if pd.isna(x) else x)\n        )\n        self.styled_plate_map = plate_map_styled\n\n        return plate_map_styled\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.__init__","title":"__init__","text":"<pre><code>__init__(plate_size=96, treatments=None, leading_zeroes=False)\n</code></pre> <p>Initialize a PlateMapper object.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def __init__(self, plate_size=96, treatments=None, leading_zeroes=False, ):\n    \"\"\"\n    Initialize a PlateMapper object.\n\n    Parameters\n    ----------\n    plate_size : int, optional\n        The size of the plate. Defaults to 96.\n    leading_zeroes : bool, optional\n        Whether to include leading zeroes in the column labels.\n        Defaults to False.\n    treatments : dict, optional\n        A dictionary mapping treatments to conditions and well ranges.\n        If provided, the treatments will be assigned to the plate map.\n        Defaults to None.\n\n    \"\"\"\n    self.plate_size = plate_size\n    self.leading_zeroes = leading_zeroes\n    self.wells = {\n        6: (2, 3),\n        12: (3, 4),\n        24: (4, 6),\n        48: (6, 8),\n        96: (8, 12),\n        384: (16, 24),\n    }\n    self.plate_map = self.create_empty_plate_map()\n    self.pivoted_plate_map = None\n    self.styled_plate_map = None\n\n    if treatments:\n        self.assign_treatments(treatments)\n        # pivot the first key in treatments\n        self.get_styled_plate_map(next(iter(treatments.keys())))\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.__init__(plate_size)","title":"<code>plate_size</code>","text":"(<code>int</code>, default:                   <code>96</code> )           \u2013            <p>The size of the plate. Defaults to 96.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.__init__(leading_zeroes)","title":"<code>leading_zeroes</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to include leading zeroes in the column labels. Defaults to False.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.__init__(treatments)","title":"<code>treatments</code>","text":"(<code>dict</code>, default:                   <code>None</code> )           \u2013            <p>A dictionary mapping treatments to conditions and well ranges. If provided, the treatments will be assigned to the plate map. Defaults to None.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.assign_treatments","title":"assign_treatments","text":"<pre><code>assign_treatments(treatments)\n</code></pre> <p>Assign treatments to specific wells in a plate map.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The updated plate map with treatments assigned to specific wells.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def assign_treatments(self, treatments):\n    \"\"\"\n    Assign treatments to specific wells in a plate map.\n\n    Parameters\n    ----------\n    treatments : dict\n        A dictionary mapping treatments to conditions and well ranges.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The updated plate map with treatments assigned to specific wells.\n\n    \"\"\"\n    for treatment, conditions in treatments.items():\n        for condition, wells in conditions.items():\n            for well in wells:\n                if ':' in well:\n                    start, end = well.split(':')\n                    start_row, start_col = start[0], int(start[1:])\n                    end_row, end_col = end[0], int(end[1:])\n                    well_condition = (\n                        (self.plate_map['row'] &gt;= start_row)\n                        &amp; (self.plate_map['row'] &lt;= end_row)\n                        &amp; (self.plate_map['column'].astype(int) &gt;= start_col)\n                        &amp; (self.plate_map['column'].astype(int) &lt;= end_col)\n                    )\n                else:\n                    row, col = well[0], int(well[1:])\n                    well_condition = (\n                        (self.plate_map['row'] == row)\n                        &amp; (self.plate_map['column'] == col)\n                    )\n\n                self.plate_map.loc[well_condition, treatment] = condition\n    return self.plate_map\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.assign_treatments(treatments)","title":"<code>treatments</code>","text":"(<code>dict</code>)           \u2013            <p>A dictionary mapping treatments to conditions and well ranges.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.create_empty_plate_map","title":"create_empty_plate_map","text":"<pre><code>create_empty_plate_map()\n</code></pre> <p>Create an empty plate map DataFrame for a given plate size.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The empty plate map DataFrame with well labels.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def create_empty_plate_map(self):\n    \"\"\"\n    Create an empty plate map DataFrame for a given plate size.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The empty plate map DataFrame with well labels.\n\n    \"\"\"\n    num_rows, num_columns = self.wells[self.plate_size]\n\n    row_labels = list(string.ascii_uppercase)[:num_rows]\n    if self.leading_zeroes:\n        column_labels = [f'{i:02d}' for i in range(1, num_columns + 1)]\n    else:\n        column_labels = list(range(1, num_columns + 1))\n\n    well_rows = row_labels * num_columns\n    well_rows.sort()  # needed to sort the rows correctly\n    well_columns = column_labels * num_rows\n\n    well_labels_dict = {'row': well_rows, 'column': well_columns}\n\n    plate_map_df = pd.DataFrame(well_labels_dict)\n\n    plate_map_df['well_id'] = plate_map_df['row'] + plate_map_df[\n        'column'\n    ].astype(str)\n    self.plate_map = plate_map_df\n    return plate_map_df\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_pivoted_plate_map","title":"get_pivoted_plate_map","text":"<pre><code>get_pivoted_plate_map(treatment)\n</code></pre> <p>Pivot a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The wide-formatted plate map DataFrame with treatments as columns.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def get_pivoted_plate_map(self, treatment):\n    \"\"\"\n    Pivot a plate map DataFrame to create a wide-formatted DataFrame with a single treatment as columns.\n\n    Parameters\n    ----------\n    treatment : str\n        The column name of the treatment variable in the plate map DataFrame.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The wide-formatted plate map DataFrame with treatments as columns.\n\n    \"\"\"\n    plate_map_pivot = self.plate_map.pivot(\n        index='row', columns='column', values=treatment\n    )\n    self.pivoted_plate_map = plate_map_pivot\n    return plate_map_pivot\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_pivoted_plate_map(treatment)","title":"<code>treatment</code>","text":"(<code>str</code>)           \u2013            <p>The column name of the treatment variable in the plate map DataFrame.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_styled_plate_map","title":"get_styled_plate_map","text":"<pre><code>get_styled_plate_map(treatment, palette='colorblind')\n</code></pre> <p>Style a plate map with background colors for each unique value.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Styler</code>           \u2013            <p>The styled plate map DataFrame with different background colors for each unique value.</p> </li> </ul> Source code in <code>src/napari_ndev/_plate_mapper.py</code> <pre><code>def get_styled_plate_map(self, treatment, palette='colorblind'):\n    \"\"\"\n    Style a plate map with background colors for each unique value.\n\n    Parameters\n    ----------\n    treatment : str\n        The column name of the treatment variable in the plate map DataFrame.\n    palette : str or list, optional\n        The color palette to use for styling. Defaults to 'colorblind'.\n\n    Returns\n    -------\n    pandas.io.formats.style.Styler\n        The styled plate map DataFrame with different background colors for each unique value.\n\n    \"\"\"\n    from seaborn import color_palette\n\n    self.pivoted_plate_map = self.get_pivoted_plate_map(treatment)\n\n    unique_values = pd.unique(self.pivoted_plate_map.values.flatten())\n    unique_values = unique_values[pd.notna(unique_values)]\n\n    color_palette_hex = color_palette(palette).as_hex()\n    # Create an infinite iterator that cycles through the palette\n    palette_cycle = itertools.cycle(color_palette_hex)\n    # Use next() to get the next color\n    color_dict = {value: next(palette_cycle) for value in unique_values}\n\n    def get_background_color(value): # pragma: no cover\n        if pd.isna(value):\n            return ''\n        return f'background-color: {color_dict[value]}'\n\n    plate_map_styled = (\n        self.pivoted_plate_map.style.applymap(get_background_color)\n        .set_caption(f'{treatment} Plate Map')\n        .format(lambda x: '' if pd.isna(x) else x)\n    )\n    self.styled_plate_map = plate_map_styled\n\n    return plate_map_styled\n</code></pre>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_styled_plate_map(treatment)","title":"<code>treatment</code>","text":"(<code>str</code>)           \u2013            <p>The column name of the treatment variable in the plate map DataFrame.</p>"},{"location":"api/plate_mapper/#napari_ndev._plate_mapper.PlateMapper.get_styled_plate_map(palette)","title":"<code>palette</code>","text":"(<code>str or list</code>, default:                   <code>'colorblind'</code> )           \u2013            <p>The color palette to use for styling. Defaults to 'colorblind'.</p>"},{"location":"api/widgets/apoc_widget/","title":"Apoc widget","text":""},{"location":"api/widgets/apoc_widget/#napari_ndev.widgets._apoc_container","title":"napari_ndev.widgets._apoc_container","text":""},{"location":"api/widgets/apoc_widget/#napari_ndev.widgets._apoc_container.ApocContainer","title":"ApocContainer","text":"<p>               Bases: <code>Container</code></p> <p>Container class for managing the ApocContainer widget in napari.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>_viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_image_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the image directory.</p> </li> <li> <code>_label_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the label directory.</p> </li> <li> <code>_output_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the output directory.</p> </li> <li> <code>_classifier_file</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the classifier file.</p> </li> <li> <code>_classifier_type_mapping</code>               (<code>dict</code>)           \u2013            <p>Mapping of classifier types to their corresponding classes.</p> </li> <li> <code>_classifier_type</code>               (<code>RadioButtons</code>)           \u2013            <p>Widget for selecting the classifier type.</p> </li> <li> <code>_max_depth</code>               (<code>SpinBox</code>)           \u2013            <p>Widget for selecting the number of forests.</p> </li> <li> <code>_num_trees</code>               (<code>SpinBox</code>)           \u2013            <p>Widget for selecting the number of trees.</p> </li> <li> <code>_positive_class_id</code>               (<code>SpinBox</code>)           \u2013            <p>Widget for selecting the object label ID.</p> </li> <li> <code>_image_channels</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting the image channels.</p> </li> <li> <code>_channel_order_label</code>               (<code>Label</code>)           \u2013            <p>Label widget for displaying the selected channel order.</p> </li> <li> <code>_PDFS</code>               (<code>Enum</code>)           \u2013            <p>Enum for predefined feature sets.</p> </li> <li> <code>_predefined_features</code>               (<code>ComboBox</code>)           \u2013            <p>Widget for selecting the features.</p> </li> <li> <code>_custom_features</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering custom feature string.</p> </li> <li> <code>_open_custom_feature_generator</code>               (<code>PushButton</code>)           \u2013            <p>Button for opening the custom feature generator widget.</p> </li> <li> <code>_continue_training</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox for indicating whether to continue training.</p> </li> <li> <code>_batch_train_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for training the classifier on image-label pairs.</p> </li> <li> <code>_batch_predict_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for predicting labels with the classifier.</p> </li> <li> <code>_progress_bar</code>               (<code>ProgressBar</code>)           \u2013            <p>Progress bar widget.</p> </li> <li> <code>_image_layer</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting the image layers.</p> </li> <li> <code>_label_layer</code>               (<code>Widget</code>)           \u2013            <p>Widget for selecting the label layers.</p> </li> <li> <code>_train_image_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for training the classifier on selected layers using labels.</p> </li> <li> <code>_predict_image_layer</code>               (<code>PushButton</code>)           \u2013            <p>Button for predicting using the classifier on selected layers.</p> </li> <li> <code>_single_result_label</code>               (<code>Label</code>)           \u2013            <p>Label widget for displaying a single result.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_update_metadata_from_file</code>             \u2013              <p>Update the metadata from the selected image directory.</p> </li> <li> <code>_update_channel_order</code>             \u2013              <p>Update the channel order label based on the selected image channels.</p> </li> <li> <code>_set_value_from_pattern</code>             \u2013              <p>Set the value from a pattern in the content.</p> </li> <li> <code>_process_classifier_metadata</code>             \u2013              <p>Process the classifier metadata from the content.</p> </li> <li> <code>_update_classifier_metadata</code>             \u2013              <p>Update the classifier metadata based on the selected classifier file.</p> </li> <li> <code>_classifier_statistics_table</code>             \u2013              <p>Display the classifier statistics table.</p> </li> <li> <code>_get_feature_set</code>             \u2013              <p>Get the selected feature set.</p> </li> <li> <code>_get_training_classifier_instance</code>             \u2013              <p>Get the training classifier instance based on the selected classifier type.</p> </li> <li> <code>_get_channel_image</code>             \u2013              <p>Get the channel image based on the selected channel index list.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_apoc_container.py</code> <pre><code>class ApocContainer(Container):\n    \"\"\"\n    Container class for managing the ApocContainer widget in napari.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    Attributes\n    ----------\n    _viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    _image_directory : FileEdit\n        Widget for selecting the image directory.\n\n    _label_directory : FileEdit\n        Widget for selecting the label directory.\n\n    _output_directory : FileEdit\n        Widget for selecting the output directory.\n\n    _classifier_file : FileEdit\n        Widget for selecting the classifier file.\n\n    _classifier_type_mapping : dict\n        Mapping of classifier types to their corresponding classes.\n\n    _classifier_type : RadioButtons\n        Widget for selecting the classifier type.\n\n    _max_depth : SpinBox\n        Widget for selecting the number of forests.\n\n    _num_trees : SpinBox\n        Widget for selecting the number of trees.\n\n    _positive_class_id : SpinBox\n        Widget for selecting the object label ID.\n\n    _image_channels : Select\n        Widget for selecting the image channels.\n\n    _channel_order_label : Label\n        Label widget for displaying the selected channel order.\n\n    _PDFS : Enum\n        Enum for predefined feature sets.\n\n    _predefined_features : ComboBox\n        Widget for selecting the features.\n\n    _custom_features : LineEdit\n        Widget for entering custom feature string.\n\n    _open_custom_feature_generator : PushButton\n        Button for opening the custom feature generator widget.\n\n    _continue_training : CheckBox\n        Checkbox for indicating whether to continue training.\n\n    _batch_train_button : PushButton\n        Button for training the classifier on image-label pairs.\n\n    _batch_predict_button : PushButton\n        Button for predicting labels with the classifier.\n\n    _progress_bar : ProgressBar\n        Progress bar widget.\n\n    _image_layer : Select\n        Widget for selecting the image layers.\n\n    _label_layer : Widget\n        Widget for selecting the label layers.\n\n    _train_image_button : PushButton\n        Button for training the classifier on selected layers using labels.\n\n    _predict_image_layer : PushButton\n        Button for predicting using the classifier on selected layers.\n\n    _single_result_label : Label\n        Label widget for displaying a single result.\n\n    Methods\n    -------\n    _update_metadata_from_file()\n        Update the metadata from the selected image directory.\n\n    _update_channel_order()\n        Update the channel order label based on the selected image channels.\n\n    _set_value_from_pattern(pattern, content)\n        Set the value from a pattern in the content.\n\n    _process_classifier_metadata(content)\n        Process the classifier metadata from the content.\n\n    _update_classifier_metadata()\n        Update the classifier metadata based on the selected classifier file.\n\n    _classifier_statistics_table(custom_classifier)\n        Display the classifier statistics table.\n\n    _get_feature_set()\n        Get the selected feature set.\n\n    _get_training_classifier_instance()\n        Get the training classifier instance based on the selected classifier\n        type.\n\n    _get_channel_image(img, channel_index_list)\n        Get the channel image based on the selected channel index list.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        viewer: napari.viewer.Viewer = None,\n    ):\n        super().__init__(labels=False)\n        self.min_width = 500 # TODO: remove this hardcoded value\n        self._viewer = viewer if viewer is not None else None\n        self._lazy_imports()\n        self._initialize_cl_container()\n        self._initialize_batch_container()\n        self._initialize_viewer_container()\n        self._initialize_custom_apoc_container()\n        self._setup_widget_layout()\n        self._connect_events()\n\n    def _lazy_imports(self):\n        import apoc\n\n        self.apoc = apoc\n\n    def _filter_layers(self, layer_type):\n        # only do this if the viewer is not None\n        if self._viewer is None:\n            return []\n        return [x for x in self._viewer.layers if isinstance(x, layer_type)]\n\n    def _initialize_cl_container(self):\n        self._classifier_file = FileEdit(\n            label='Classifier File (.cl)',\n            mode='w',\n            tooltip='Create a .txt file and rename it to .cl ending.',\n        )\n\n        self._continue_training = CheckBox(\n            label='Continue Training?',\n            value=True,\n            tooltip=(\n                'Continue training only matters if classifier already exists.'\n            ),\n        )\n\n        self._classifier_type_mapping = {\n            'PixelClassifier': self.apoc.PixelClassifier,\n            'ObjectSegmenter': self.apoc.ObjectSegmenter,\n        }\n\n        self._classifier_type = RadioButtons(\n            label='Classifier Type',\n            value='ObjectSegmenter',\n            choices=['ObjectSegmenter', 'PixelClassifier'],\n            tooltip='Object Segmenter is used for detecting objects of one '\n            'class, including connected components. '\n            'Pixel Classifier is used to classify pixel-types.',\n        )\n        self._max_depth = SpinBox(\n            label='Num. of Forests',\n            value=2,\n            max=20,\n            step=1,\n            tooltip='Increases training time for each forest',\n        )\n        self._num_trees = SpinBox(\n            label='Num. of Trees',\n            value=100,\n            step=50,\n            tooltip='Increases computational requirements.',\n        )\n        self._positive_class_id = SpinBox(\n            label='Object Label ID',\n            value=2,\n            step=1,\n            tooltip='Only used with ObjectSegmenter, otherwise ignored.',\n        )\n\n        self._PDFS = Enum(\n            'PDFS', self.apoc.PredefinedFeatureSet._member_names_\n        )\n        self._predefined_features = ComboBox(\n            label='Features',\n            choices=self._PDFS,\n            nullable=True,\n            value=None,\n            tooltip=\"All featuresets except 'custom' are premade\",\n        )\n        self._feature_string = LineEdit(\n            label='Feature String',\n            tooltip=(\n                'A string in the form of ' \"'filter1=radius1 filter2=radius2'.\"\n            ),\n        )\n        self._cl_container = Container(\n            widgets=[\n                self._classifier_file,\n                self._continue_training,\n                self._classifier_type,\n                self._max_depth,\n                self._num_trees,\n                self._positive_class_id,\n                self._predefined_features,\n                self._feature_string,\n            ]\n        )\n\n    def _initialize_batch_container(self):\n        self._image_directory = FileEdit(label='Image Directory', mode='d')\n        self._label_directory = FileEdit(label='Label Directory', mode='d')\n        self._output_directory = FileEdit(label='Output Directory', mode='d')\n\n        self._image_channels = Select(\n            label='Image Channels',\n            choices=[],\n            tooltip=(\n                'Channel order should be same for training and prediction.'\n            ),\n        )\n        self._channel_order_label = Label(value='Select an Image Channel!')\n\n        self._batch_train_button = PushButton(label='Train')\n        self._batch_predict_button = PushButton(label='Predict')\n\n        self._batch_train_container = Container(\n            layout='horizontal',\n            widgets=[\n                self._label_directory,\n                self._batch_train_button,\n            ]\n        )\n\n        self._batch_predict_container = Container(\n            layout='horizontal',\n            widgets=[\n                self._output_directory,\n                self._batch_predict_button,\n            ]\n        )\n\n        self._progress_bar = ProgressBar(label='Progress:')\n\n        self._batch_container = Container(\n            layout='vertical',\n            label='Batch',\n            widgets=[\n                self._image_directory,\n                self._image_channels,\n                self._channel_order_label,\n                self._batch_train_container,\n                self._batch_predict_container,\n                self._progress_bar,\n            ]\n        )\n\n    def _initialize_viewer_container(self):\n        self._image_layers = Select(\n            choices=self._filter_layers(layers.Image),\n            label='Image Layers',\n        )\n        self._label_layer = ComboBox(\n            choices=self._filter_layers(layers.Labels),\n            label='Label Layer',\n        )\n        self._train_image_button = PushButton(\n            label='Train classifier on selected layers using label'\n        )\n        self._predict_image_layer = PushButton(\n            label='Predict using classifier on selected layers'\n        )\n        self._single_result_label = LineEdit()\n\n        self._viewer_container = Container(\n            widgets=[\n                self._image_layers,\n                self._label_layer,\n                self._train_image_button,\n                self._predict_image_layer,\n                self._single_result_label,\n            ],\n            layout='vertical',\n            label='Viewer'\n        )\n\n    def _initialize_custom_apoc_container(self):\n        from napari_ndev import ApocFeatureStack\n\n        self._custom_apoc_container = ApocFeatureStack(viewer=self._viewer)\n        self._custom_apoc_container.label = 'Custom Feature Set'\n\n    def _setup_widget_layout(self):\n        self.append(self._cl_container)\n        self._tabs = TabbedContainer(\n            widgets=[\n                self._batch_container,\n                self._viewer_container,\n                self._custom_apoc_container,\n            ],\n            label=None,\n            labels=None,\n        )\n        # self.append(self._tabs) # does not connect gui to native, but is scrollable\n        # self._scroll = ScrollableContainer(widgets=[self._tabs])\n        # from qtpy.QtCore import Qt\n        # self._scroll._widget._layout.setAlignment(Qt.AlignTop) # does not work\n        # self.append(self._scroll)\n        # the only way for _label_layer and _image_layers to stay connected is to attach it to native, not sure why\n        self.native.layout().addWidget(self._tabs.native) # connects and is scrollable, internally, but not in the main window\n        self.native.layout().addStretch() # resets the layout to squish to top\n\n    def _connect_events(self):\n        self._image_directory.changed.connect(self._update_metadata_from_file)\n        self._image_channels.changed.connect(self._update_channel_order)\n        self._classifier_file.changed.connect(self._update_classifier_metadata)\n\n        self._batch_train_button.clicked.connect(self.batch_train)\n        self._batch_predict_button.clicked.connect(self.batch_predict)\n        self._train_image_button.clicked.connect(self.image_train)\n        self._predict_image_layer.clicked.connect(self.image_predict)\n\n        self._custom_apoc_container._generate_string_button.clicked.connect(\n            self.insert_custom_feature_string\n        )\n        self._predefined_features.changed.connect(self._get_feature_set)\n\n        # when self._viewer.layers is updated, update the choices in the ComboBox\n        if self._viewer is not None:\n            self._viewer.layers.events.removed.connect(\n                self._update_layer_choices\n            )\n            self._viewer.layers.events.inserted.connect(\n                self._update_layer_choices\n            )\n\n    def _update_layer_choices(self):\n        self._label_layer.choices = self._filter_layers(layers.Labels)\n        self._image_layers.choices = self._filter_layers(layers.Image)\n\n    def _update_metadata_from_file(self):\n        from napari_ndev import nImage\n\n        _, files = helpers.get_directory_and_files(self._image_directory.value)\n        img = nImage(files[0])\n        self._image_channels.choices = helpers.get_channel_names(img)\n\n    def _update_channel_order(self):\n        self._channel_order_label.value = 'Selected Channel Order: ' + str(\n            self._image_channels.value\n        )\n\n    ##############################\n    # Classifier Related Functions\n    ##############################\n    def _set_value_from_pattern(self, pattern, content):\n        match = re.search(pattern, content)\n        return match.group(1) if match else None\n\n    def _process_classifier_metadata(self, content):\n        self._classifier_type.value = self._set_value_from_pattern(\n            r'classifier_class_name\\s*=\\s*([^\\n]+)', content\n        )\n        self._max_depth.value = self._set_value_from_pattern(\n            r'max_depth\\s*=\\s*(\\d+)', content\n        )\n        self._num_trees.value = self._set_value_from_pattern(\n            r'num_trees\\s*=\\s*(\\d+)', content\n        )\n        self._positive_class_id.value = (\n            self._set_value_from_pattern(\n                r'positive_class_identifier\\s*=\\s*(\\d+)', content\n            )\n            or 2\n        )\n\n    def _update_classifier_metadata(self):\n        file_path = self._classifier_file.value\n\n        # create file, if it doesn't exist\n        file_path.touch(exist_ok=True)\n        content = file_path.read_text()\n\n        # Ignore rest of function if file contents are empty\n        if not content.strip():\n            return\n\n        self._process_classifier_metadata(content)\n\n        if self._classifier_type.value in self._classifier_type_mapping:\n            classifier_class = self._classifier_type_mapping[\n                self._classifier_type.value\n            ]\n            custom_classifier = classifier_class(\n                opencl_filename=self._classifier_file.value\n            )\n        else:\n            custom_classifier = None\n\n        self._classifier_statistics_table(custom_classifier)\n\n    def _classifier_statistics_table(self, custom_classifier):\n        table, _ = custom_classifier.statistics()\n\n        trans_table = {'filter_name': [], 'radius': []}\n\n        for value in table:\n            filter_name, radius = (\n                value.split('=') if '=' in value else (value, 0)\n            )\n            trans_table['filter_name'].append(filter_name)\n            trans_table['radius'].append(float(radius))\n\n        for i in range(len(next(iter(table.values())))):\n            trans_table[str(i)] = [round(table[key][i], 2) for key in table]\n\n        table_df = pd.DataFrame.from_dict(trans_table)\n        if self._viewer is not None:\n            self._viewer.window.add_dock_widget(\n                Table(value=table_df),\n                name=os.path.basename(self._classifier_file.value),\n            )\n\n    def _get_feature_set(self):\n        if self._predefined_features.value.value == 1:\n            feature_set = ''\n        else:\n            feature_set = self.apoc.PredefinedFeatureSet[\n                self._predefined_features.value.name\n            ].value\n        self._feature_string.value = feature_set\n        self._custom_apoc_container._feature_string.value = (\n            feature_set  # &lt;- potentially deprecated in future\n        )\n        return feature_set\n\n    def _get_training_classifier_instance(self):\n        if self._classifier_type.value == 'PixelClassifier':\n            return self.apoc.PixelClassifier(\n                opencl_filename=self._classifier_file.value,\n                max_depth=self._max_depth.value,\n                num_ensembles=self._num_trees.value,\n            )\n\n        if self._classifier_type.value == 'ObjectSegmenter':\n            return self.apoc.ObjectSegmenter(\n                opencl_filename=self._classifier_file.value,\n                positive_class_identifier=self._positive_class_id.value,\n                max_depth=self._max_depth.value,\n                num_ensembles=self._num_trees.value,\n            )\n        return None\n\n    ##############################\n    # Training and Prediction\n    ##############################\n    def _get_channel_image(self, img, channel_index_list):\n        if 'S' in img.dims.order:\n            channel_img = img.get_image_data('TSZYX', S=channel_index_list)\n        else:\n            channel_img = img.get_image_data('TCZYX', C=channel_index_list)\n        return channel_img\n\n    def batch_train(self):\n        from pyclesperanto_prototype import set_wait_for_kernel_finish\n\n        from napari_ndev import nImage\n\n        image_directory, image_files = helpers.get_directory_and_files(\n            self._image_directory.value\n        )\n        label_directory, _ = helpers.get_directory_and_files(\n            self._label_directory.value\n        )\n        # missing_files = check_for_missing_files(image_files, label_directory)\n\n        log_loc = self._classifier_file.value.with_suffix('.log.txt')\n        logger, handler = helpers.setup_logger(log_loc)\n\n        logger.info(\n            \"\"\"\n        Classifier: %s\n        Channels: %s\n        Num. Files: %d\n        Image Directory: %s\n        Label Directory: %s\n        \"\"\",\n            self._classifier_file.value,\n            self._image_channels.value,\n            len(image_files),\n            image_directory,\n            label_directory,\n        )\n\n        # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n        set_wait_for_kernel_finish(True)\n\n        self._progress_bar.label = f'Training on {len(image_files)} Images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(image_files)\n\n        if not self._continue_training:\n            self.apoc.erase_classifier(self._classifier_file.value)\n\n        custom_classifier = self._get_training_classifier_instance()\n        feature_set = self._feature_string.value\n\n        channel_index_list = [\n            self._image_channels.choices.index(channel)\n            for channel in self._image_channels.value\n        ]\n\n        # Iterate over image files, only pulling label files with an identical\n        # name to the image file. Ensuring that files match by some other\n        # method would be much more complicated, so I'm leaving it up to the\n        # user at this point. In addition, the utilities widget saves with\n        # the same name, so this should be a non-issue, if staying within the\n        # same workflow.\n        for idx, image_file in enumerate(image_files):\n            if not (label_directory / image_file.name).exists():\n                logger.error('Label file missing for %s', image_file.name)\n                self._progress_bar.value = idx + 1\n                continue\n\n            logger.info('Training Image %d: %s', idx + 1, image_file.name)\n\n            img = nImage(image_directory / image_file.name)\n            channel_img = self._get_channel_image(img, channel_index_list)\n\n            lbl = nImage(label_directory / image_file.name)\n            label = lbl.get_image_data('TCZYX', C=0)\n\n            # &lt;- this is where setting up dask processing would be useful\n\n            try:\n                custom_classifier.train(\n                    features=feature_set,\n                    image=np.squeeze(channel_img),\n                    ground_truth=np.squeeze(label),\n                    continue_training=True,\n                )\n                self._progress_bar.value = idx + 1\n            except Exception:\n                logger.exception('Error training %s', image_file)\n                self._progress_bar.value = idx + 1\n                continue\n\n        self._classifier_statistics_table(custom_classifier)\n        self._progress_bar.label = f'Trained on {len(image_files)} Images'\n        logger.removeHandler(handler)\n\n    def _get_prediction_classifier_instance(self):\n        if self._classifier_type.value in self._classifier_type_mapping:\n            classifier_class = self._classifier_type_mapping[\n                self._classifier_type.value\n            ]\n            return classifier_class(\n                opencl_filename=self._classifier_file.value\n            )\n        return None\n\n    def batch_predict(self):\n        from bioio.writers import OmeTiffWriter\n        from pyclesperanto_prototype import set_wait_for_kernel_finish\n\n        from napari_ndev import nImage\n\n        image_directory, image_files = helpers.get_directory_and_files(\n            dir_path=self._image_directory.value,\n        )\n\n        log_loc = self._output_directory.value / 'log.txt'\n        logger, handler = helpers.setup_logger(log_loc)\n\n        logger.info(\n            \"\"\"\n        Classifier: %s\n        Channels: %s\n        Num. Files: %d\n        Image Directory: %s\n        Output Directory: %s\n        \"\"\",\n            self._classifier_file.value,\n            self._image_channels.value,\n            len(image_files),\n            image_directory,\n            self._output_directory.value,\n        )\n\n        # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n        set_wait_for_kernel_finish(True)\n\n        self._progress_bar.label = f'Predicting {len(image_files)} Images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(image_files)\n\n        custom_classifier = self._get_prediction_classifier_instance()\n\n        channel_index_list = [\n            self._image_channels.choices.index(channel)\n            for channel in self._image_channels.value\n        ]\n\n        for idx, file in enumerate(image_files):\n            logger.info('Predicting Image %d: %s', idx + 1, file.name)\n\n            img = nImage(file)\n            channel_img = self._get_channel_image(img, channel_index_list)\n            squeezed_dim_order = helpers.get_squeezed_dim_order(img)\n\n            # &lt;- this is where setting up dask processing would be useful\n\n            try:\n                result = custom_classifier.predict(\n                    image=np.squeeze(channel_img)\n                )\n            except Exception:\n                logger.exception('Error predicting %s', file)\n                self._progress_bar.value = idx + 1\n                continue\n\n            save_data = np.asarray(result)\n            if save_data.max() &gt; 65535:\n                save_data = save_data.astype(np.int32)\n            else:\n                save_data = save_data.astype(np.int16)\n\n            OmeTiffWriter.save(\n                data=save_data,\n                uri=self._output_directory.value / (file.stem + '.tiff'),\n                dim_order=squeezed_dim_order,\n                channel_names=['Labels'],\n                physical_pixel_sizes=img.physical_pixel_sizes,\n            )\n            del result\n\n            self._progress_bar.value = idx + 1\n\n        self._progress_bar.label = f'Predicted {len(image_files)} Images'\n        logger.removeHandler(handler)\n\n    def image_train(self):\n        from pyclesperanto_prototype import set_wait_for_kernel_finish\n        image_names = [image.name for image in self._image_layers.value]\n        label_name = self._label_layer.value.name\n        self._single_result_label.value = (\n            f'Training on {image_names} using {label_name}'\n        )\n\n        image_list = [image.data for image in self._image_layers.value]\n        image_stack = np.stack(image_list, axis=0)\n        label = self._label_layer.value.data\n\n        # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n        set_wait_for_kernel_finish(True)\n\n        if not self._continue_training:\n            self.apoc.erase_classifier(self._classifier_file.value)\n\n        custom_classifier = self._get_training_classifier_instance()\n        feature_set = self._feature_string.value\n\n        custom_classifier.train(\n            features=feature_set,\n            image=np.squeeze(image_stack),\n            ground_truth=np.squeeze(label),\n            continue_training=True,\n        )\n\n        self._single_result_label.value = (\n            f'Trained on {image_names} using {label_name}'\n        )\n\n    def image_predict(self):\n        from pyclesperanto_prototype import set_wait_for_kernel_finish\n        set_wait_for_kernel_finish(\n            True\n        )  # https://github.com/clEsperanto/pyclesperanto_prototype/issues/163\n\n        image_names = [image.name for image in self._image_layers.value]\n        self._single_result_label.value = f'Predicting {image_names}'\n        image_list = [image.data for image in self._image_layers.value]\n        image_stack = np.stack(image_list, axis=0)\n        scale = self._image_layers.value[0].scale\n\n        custom_classifier = self._get_prediction_classifier_instance()\n\n        result = custom_classifier.predict(image=np.squeeze(image_stack))\n\n        # sometimes, input layers may have shape with 1s, like (1,1,10,10)\n        # however, we are squeezing the input, so the reuslt will have shape\n        # (10,10), and therefore scale needs to accomodate dropped axes\n        result_dims = result.ndim\n        if len(scale) &gt; result_dims:\n            scale = scale[-result_dims:]\n\n        self._viewer.add_labels(\n            result,\n            scale=scale,\n            name=f'{self._classifier_file.value.stem} :: {image_names}'\n        )\n\n        self._single_result_label.value = f'Predicted {image_names}'\n\n        return result\n\n    def insert_custom_feature_string(self):\n        self._feature_string.value = (\n            self._custom_apoc_container._feature_string.value\n        )\n        return self._feature_string.value\n</code></pre>"},{"location":"api/widgets/apoc_widget/#napari_ndev.widgets._apoc_container.ApocContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/custom_apoc_feature_set/","title":"Custom apoc feature set","text":""},{"location":"api/widgets/custom_apoc_feature_set/#napari_ndev.widgets._apoc_feature_stack","title":"napari_ndev.widgets._apoc_feature_stack","text":""},{"location":"api/widgets/custom_apoc_feature_set/#napari_ndev.widgets._apoc_feature_stack.ApocFeatureStack","title":"ApocFeatureStack","text":"<p>               Bases: <code>Container</code></p> <p>Create and apply image features in the napari viewer.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>_viewer</code>               (<code>Viewer or None</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_original</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox to keep the original image.</p> </li> <li> <code>_gaussian_blur</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Gaussian Blur parameters.</p> </li> <li> <code>_DoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Difference of Gaussian parameters.</p> </li> <li> <code>_LoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Laplacian of Gaussian parameters.</p> </li> <li> <code>_SoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Sobel of Gaussian parameters.</p> </li> <li> <code>_sHoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Small Hessian of Gaussian parameters.</p> </li> <li> <code>_lHoG</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Large Hessian of Gaussian parameters.</p> </li> <li> <code>_median</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Median filter parameters.</p> </li> <li> <code>_tophat</code>               (<code>LineEdit</code>)           \u2013            <p>LineEdit for specifying Top Hat filter parameters.</p> </li> <li> <code>_generate_string_button</code>               (<code>PushButton</code>)           \u2013            <p>Button to generate the feature string.</p> </li> <li> <code>_feature_string</code>               (<code>TextEdit</code>)           \u2013            <p>TextEdit to display the custom feature string.</p> </li> <li> <code>_image_layer</code>               (<code>ComboBox</code>)           \u2013            <p>ComboBox to select the image layer.</p> </li> <li> <code>_apply_button</code>               (<code>PushButton</code>)           \u2013            <p>Button to apply the feature stack to the selected image.</p> </li> <li> <code>_progress_bar</code>               (<code>ProgressBar</code>)           \u2013            <p>Progress bar to display the progress of feature application.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_filter_layers</code>             \u2013              <p>Filters the layers in the viewer by the specified layer type.</p> </li> <li> <code>_update_layer_choices</code>             \u2013              <p>Updates the choices in the image layer ComboBox.</p> </li> <li> <code>generate_feature_string</code>             \u2013              <p>Generates a feature string based on the user inputs.</p> </li> <li> <code>layer_to_feature_stack</code>             \u2013              <p>Applies the generated feature stack to the selected image layer.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_apoc_feature_stack.py</code> <pre><code>class ApocFeatureStack(Container):\n    \"\"\"\n    Create and apply image features in the napari viewer.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer, optional\n        The napari viewer instance to which this feature stack is attached. Default is None.\n\n    Attributes\n    ----------\n    _viewer : napari.viewer.Viewer or None\n        The napari viewer instance.\n    _original : CheckBox\n        Checkbox to keep the original image.\n    _gaussian_blur : LineEdit\n        LineEdit for specifying Gaussian Blur parameters.\n    _DoG : LineEdit\n        LineEdit for specifying Difference of Gaussian parameters.\n    _LoG : LineEdit\n        LineEdit for specifying Laplacian of Gaussian parameters.\n    _SoG : LineEdit\n        LineEdit for specifying Sobel of Gaussian parameters.\n    _sHoG : LineEdit\n        LineEdit for specifying Small Hessian of Gaussian parameters.\n    _lHoG : LineEdit\n        LineEdit for specifying Large Hessian of Gaussian parameters.\n    _median : LineEdit\n        LineEdit for specifying Median filter parameters.\n    _tophat : LineEdit\n        LineEdit for specifying Top Hat filter parameters.\n    _generate_string_button : PushButton\n        Button to generate the feature string.\n    _feature_string : TextEdit\n        TextEdit to display the custom feature string.\n    _image_layer : ComboBox\n        ComboBox to select the image layer.\n    _apply_button : PushButton\n        Button to apply the feature stack to the selected image.\n    _progress_bar : ProgressBar\n        Progress bar to display the progress of feature application.\n\n    Methods\n    -------\n    _filter_layers(layer_type)\n        Filters the layers in the viewer by the specified layer type.\n    _update_layer_choices()\n        Updates the choices in the image layer ComboBox.\n    generate_feature_string()\n        Generates a feature string based on the user inputs.\n    layer_to_feature_stack()\n        Applies the generated feature stack to the selected image layer.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        viewer: 'napari.viewer.Viewer' = None,\n    ):\n        super().__init__()\n        self._viewer = viewer if viewer is not None else None\n\n        self._original = CheckBox(label='Keep Original Image')\n        self._gaussian_blur = LineEdit(label='Gaussian Blur')\n        self._DoG = LineEdit(label='Difference of Gauss.')\n        self._LoG = LineEdit(label='Laplacian of Gauss.')\n        self._SoG = LineEdit(label='Sobel of Gauss.')\n        self._sHoG = LineEdit(label='Small Hessian of Gauss.')\n        self._lHoG = LineEdit(label='Large Hessian of Gauss.')\n        self._median = LineEdit(label='Median')\n        self._tophat = LineEdit(label='Top Hat')\n\n        self._generate_string_button = PushButton(\n            label='Generate Feature String'\n        )\n        self._feature_string = LineEdit(label='Custom Feature String')\n\n        self._image_layer = ComboBox(\n            choices=self._filter_layers(layers.Image), label='Image Layer'\n        )\n        self._apply_button = PushButton(label='Apply to selected image')\n        self._progress_bar = ProgressBar(label='Progress: ')\n\n        self.extend(\n            [\n                self._original,\n                self._gaussian_blur,\n                self._DoG,\n                self._LoG,\n                self._SoG,\n                self._sHoG,\n                self._lHoG,\n                self._median,\n                self._tophat,\n                self._generate_string_button,\n                self._feature_string,\n                self._image_layer,\n                self._apply_button,\n                self._progress_bar,\n            ]\n        )\n\n        self._generate_string_button.clicked.connect(\n            self.generate_feature_string\n        )\n        self._apply_button.clicked.connect(self.layer_to_feature_stack)\n\n        if self._viewer is not None:\n            self._viewer.layers.events.removed.connect(\n                self._update_layer_choices\n            )\n            self._viewer.layers.events.inserted.connect(\n                self._update_layer_choices\n            )\n\n    def _filter_layers(self, layer_type):\n        if self._viewer is None:\n            return []\n        return [x for x in self._viewer.layers if isinstance(x, layer_type)]\n\n    def _update_layer_choices(self):\n        self._image_layer.choices = self._filter_layers(layers.Image)\n\n    def generate_feature_string(self):\n        def process_feature(prefix, input_str):\n            return [\n                prefix + num.strip()\n                for num in input_str.split(',')\n                if num.strip()\n            ]\n\n        feature_list = []\n        if self._original.value:\n            feature_list.append('original')\n        feature_list.extend(\n            process_feature('gaussian_blur=', self._gaussian_blur.value)\n        )\n        feature_list.extend(\n            process_feature('difference_of_gaussian=', self._DoG.value)\n        )\n        feature_list.extend(\n            process_feature('laplace_box_of_gaussian_blur=', self._LoG.value)\n        )\n        feature_list.extend(\n            process_feature('sobel_of_gaussian_blur=', self._SoG.value)\n        )\n        feature_list.extend(\n            process_feature(\n                'small_hessian_eigenvalue_of_gaussian_blur=', self._sHoG.value\n            )\n        )\n        feature_list.extend(\n            process_feature(\n                'large_hessian_eigenvalue_of_gaussian_blur=',\n                self._lHoG.value,\n            )\n        )\n        feature_list.extend(\n            process_feature('median_sphere=', self._median.value)\n        )\n        feature_list.extend(\n            process_feature('top_hat_sphere=', self._tophat.value)\n        )\n\n        self._feature_string.value = ' '.join(feature_list)\n\n    def layer_to_feature_stack(self):\n        from apoc import generate_feature_stack\n\n        image = self._image_layer.value.data\n        feature_stack = generate_feature_stack(\n            image, self._feature_string.value\n        )\n\n        feature_strings = self._feature_string.value.split()\n\n        self._progress_bar.max = len(feature_stack)\n        self._progress_bar.value = 0\n\n        for idx, (feature, string) in enumerate(\n            zip(reversed(feature_stack), reversed(feature_strings))\n        ):\n            self._viewer.add_image(data=feature, name=string)\n            self._progress_bar.value = idx + 1\n</code></pre>"},{"location":"api/widgets/custom_apoc_feature_set/#napari_ndev.widgets._apoc_feature_stack.ApocFeatureStack(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance to which this feature stack is attached. Default is None.</p>"},{"location":"api/widgets/image_utilities/","title":"Image utilities","text":""},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container","title":"napari_ndev.widgets._utilities_container","text":""},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer","title":"UtilitiesContainer","text":"<p>               Bases: <code>ScrollableContainer</code></p> <p>A widget to work with images and labels in the napari viewer.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>_viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_image_save_dims</code>               (<code>str or None</code>)           \u2013            <p>The dimension order for saving images.</p> </li> <li> <code>_label_save_dims</code>               (<code>str or None</code>)           \u2013            <p>The dimension order for saving labels.</p> </li> <li> <code>_p_sizes</code>               (<code>PhysicalPixelSizes</code>)           \u2013            <p>The physical pixel sizes for the image.</p> </li> <li> <code>_files</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting file(s).</p> </li> <li> <code>_open_image_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for opening images.</p> </li> <li> <code>_save_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting the save directory.</p> </li> <li> <code>_save_name</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering the file save name.</p> </li> <li> <code>_metadata_from_selected_layer</code>               (<code>PushButton</code>)           \u2013            <p>Button for updating metadata from the selected layer.</p> </li> <li> <code>_dim_order</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering the dimension order.</p> </li> <li> <code>_channel_names</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for entering the channel names.</p> </li> <li> <code>_physical_pixel_sizes_z</code>               (<code>FloatSpinBox</code>)           \u2013            <p>Widget for entering the Z pixel size in micrometers.</p> </li> <li> <code>_physical_pixel_sizes_y</code>               (<code>FloatSpinBox</code>)           \u2013            <p>Widget for entering the Y pixel size in micrometers.</p> </li> <li> <code>_physical_pixel_sizes_x</code>               (<code>FloatSpinBox</code>)           \u2013            <p>Widget for entering the X pixel size in micrometers.</p> </li> <li> <code>_image_layer</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting the image layer.</p> </li> <li> <code>_concatenate_image_files</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox for concatenating image files.</p> </li> <li> <code>_concatenate_image_layers</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox for concatenating image layers.</p> </li> <li> <code>_save_image_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for saving images.</p> </li> <li> <code>_labels_layer</code>               (<code>Widget</code>)           \u2013            <p>Widget for working with labels layer.</p> </li> <li> <code>_save_labels_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for saving labels.</p> </li> <li> <code>_shapes_layer</code>               (<code>Widget</code>)           \u2013            <p>Widget for working with shapes layer.</p> </li> <li> <code>_save_shapes_button</code>               (<code>PushButton</code>)           \u2013            <p>Button for saving shapes as labels.</p> </li> <li> <code>_results</code>               (<code>TextEdit</code>)           \u2013            <p>Widget for displaying information.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_update_metadata</code>             \u2013              <p>Update the metadata based on the given image.</p> </li> <li> <code>update_metadata_from_file</code>             \u2013              <p>Update the metadata from the selected file.</p> </li> <li> <code>update_metadata_from_layer</code>             \u2013              <p>Update the metadata from the selected layer.</p> </li> <li> <code>open_images</code>             \u2013              <p>Open the selected images in the napari viewer.</p> </li> <li> <code>concatenate_images</code>             \u2013              <p>Concatenate the image data based on the selected options.</p> </li> <li> <code>p_sizes</code>             \u2013              <p>Get the physical pixel sizes.</p> </li> <li> <code>_get_save_loc</code>             \u2013              <p>Get the save location based on the parent directory.</p> </li> <li> <code>_common_save_logic</code>             \u2013              <p>Common logic for saving data as OME-TIFF.</p> </li> <li> <code>save_ome_tiff</code>             \u2013              <p>Save the concatenated image data as OME-TIFF.</p> </li> <li> <code>save_labels</code>             \u2013              <p>Save the labels data.</p> </li> <li> <code>save_shapes_as_labels</code>             \u2013              <p>Save the shapes data as labels.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>class UtilitiesContainer(ScrollableContainer):\n    \"\"\"\n    A widget to work with images and labels in the napari viewer.\n\n    Parameters\n    ----------\n    viewer: napari.viewer.Viewer, optional\n        The napari viewer instance.\n\n    Attributes\n    ----------\n    _viewer: napari.viewer.Viewer\n        The napari viewer instance.\n    _image_save_dims: str or None\n        The dimension order for saving images.\n    _label_save_dims: str or None\n        The dimension order for saving labels.\n    _p_sizes: PhysicalPixelSizes\n        The physical pixel sizes for the image.\n    _files: FileEdit\n        Widget for selecting file(s).\n    _open_image_button: PushButton\n        Button for opening images.\n    _save_directory: FileEdit\n        Widget for selecting the save directory.\n    _save_name: LineEdit\n        Widget for entering the file save name.\n    _metadata_from_selected_layer: PushButton\n        Button for updating metadata from the selected layer.\n    _dim_order: LineEdit\n        Widget for entering the dimension order.\n    _channel_names: LineEdit\n        Widget for entering the channel names.\n    _physical_pixel_sizes_z: FloatSpinBox\n        Widget for entering the Z pixel size in micrometers.\n    _physical_pixel_sizes_y: FloatSpinBox\n        Widget for entering the Y pixel size in micrometers.\n    _physical_pixel_sizes_x: FloatSpinBox\n        Widget for entering the X pixel size in micrometers.\n    _image_layer: Select\n        Widget for selecting the image layer.\n    _concatenate_image_files: CheckBox\n        Checkbox for concatenating image files.\n    _concatenate_image_layers: CheckBox\n        Checkbox for concatenating image layers.\n    _save_image_button: PushButton\n        Button for saving images.\n    _labels_layer: Widget\n        Widget for working with labels layer.\n    _save_labels_button: PushButton\n        Button for saving labels.\n    _shapes_layer: Widget\n        Widget for working with shapes layer.\n    _save_shapes_button: PushButton\n        Button for saving shapes as labels.\n    _results: TextEdit\n        Widget for displaying information.\n\n    Methods\n    -------\n    _update_metadata(img)\n        Update the metadata based on the given image.\n    update_metadata_from_file()\n        Update the metadata from the selected file.\n    update_metadata_from_layer()\n        Update the metadata from the selected layer.\n    open_images()\n        Open the selected images in the napari viewer.\n    concatenate_images(concatenate_files, files, concatenate_layers, layers)\n        Concatenate the image data based on the selected options.\n    p_sizes()\n        Get the physical pixel sizes.\n    _get_save_loc(parent)\n        Get the save location based on the parent directory.\n    _common_save_logic(data, uri, dim_order, channel_names, layer)\n        Common logic for saving data as OME-TIFF.\n    save_ome_tiff()\n        Save the concatenated image data as OME-TIFF.\n    save_labels()\n        Save the labels data.\n    save_shapes_as_labels()\n        Save the shapes data as labels.\n\n    \"\"\"\n\n    def __init__(self, viewer: napari.viewer.Viewer = None):\n        \"\"\"\n        Initialize the UtilitiesContainer widget.\n\n        Parameters\n        ----------\n        viewer : napari.viewer.Viewer, optional\n            The napari viewer instance.\n\n        \"\"\"\n        super().__init__(labels=False)\n\n        self.min_width = 500 # TODO: remove this hardcoded value\n        self._viewer = viewer if viewer is not None else None\n        self._squeezed_dims = None\n\n        self._init_widgets()\n        self._init_save_name_container()\n        self._init_file_options_container()\n        self._init_open_image_container()\n        self._init_metadata_container()\n        self._init_concatenate_files_container()\n        self._init_save_layers_container()\n        self._init_scene_container()\n        # self._init_figure_options_container() # TODO: add figure saving\n        self._init_layout()\n        self._connect_events()\n\n    def _init_layout(self):\n        \"\"\"Initialize the layout of the widget.\"\"\"\n        self.extend(\n            [\n                self._save_directory,\n                self._save_name_container,\n                self._files,\n                self._open_image_container,\n                self._file_options_container,\n                self._metadata_container,\n                self._concatenate_files_container,\n                self._scene_container,\n                # self._figure_options_container,\n                self._save_layers_container,\n                self._results,\n            ]\n        )\n\n    def _init_widgets(self):\n        \"\"\"Initialize widgets.\"\"\"\n        self._save_directory = FileEdit(\n            mode='d',\n            tooltip='Directory where images will be saved.',\n        )\n        self._files = FileEdit(\n            mode='rm',\n            tooltip='Select file(s) to load.',\n        )\n\n        self._results = TextEdit(label='Info')\n\n    def _init_save_name_container(self):\n        \"\"\"Initialize the save name container.\"\"\"\n        self._save_name_container = Container(layout='horizontal')\n        self._save_name = LineEdit(\n            label='Save Name',\n            tooltip='Name of the saved file. '\n            'Proper extension will be added when saved.',\n        )\n        self._append_scene_button = PushButton(\n            label='Append Scene to Name',\n        )\n        self._save_name_container.extend([\n            self._save_name,\n            self._append_scene_button\n        ])\n\n\n    def _init_file_options_container(self):\n        \"\"\"Initialize the file options collapsible container.\"\"\"\n        self._file_options_container = CollapsibleContainer(\n            layout='vertical',\n            text='File Options',\n            collapsed=True,\n        )\n        self._update_scale = CheckBox(\n            value=True,\n            label='Update Scale on File Select',\n            tooltip='Update the scale when files are selected.',\n        )\n        self._update_channel_names = CheckBox(\n            value=True,\n            label='Update Channel Names on File Select',\n            tooltip='Update the channel names when files are selected.',\n        )\n        self._save_directory_prefix = LineEdit(\n            label='Save Directory Prefix',\n            tooltip='Prefix for the save directories.',\n        )\n\n        self._file_options_container.extend([\n            self._update_scale,\n            self._update_channel_names,\n            self._save_directory_prefix,\n        ])\n\n    def _init_open_image_container(self):\n        \"\"\"Initialize the open image container.\"\"\"\n        self._open_image_container = Container(layout='horizontal')\n        self._open_image_button = PushButton(label='Open File(s)')\n        self._select_next_image_button = PushButton(\n            label='Select Next',\n            tooltip='Select the next file(s) in the directory. \\n'\n            'Note that the files are sorted alphabetically and numerically.'\n        )\n        self._open_image_container.append(self._open_image_button)\n        self._open_image_container.append(self._select_next_image_button)\n\n    def _init_concatenate_files_container(self):\n        self._concatenate_files_container = Container(\n            layout='horizontal',\n        )\n        self._concatenate_files_button = PushButton(label='Concat. Files')\n        self._concatenate_batch_button = PushButton(\n            label='Batch Concat.',\n            tooltip='Concatenate files in the selected directory by iterating'\n            ' over the remaing files in the directory based on the number of'\n            ' files selected. The files are sorted '\n            'alphabetically and numerically, which may not be consistent '\n            'with your file viewer. But, opening related consecutive files '\n            'should work as expected.',\n        )\n        self._concatenate_files_container.extend([\n            self._concatenate_files_button,\n            self._concatenate_batch_button,\n        ])\n\n\n    def _init_metadata_container(self):\n        self._metadata_container = CollapsibleContainer(\n            layout='vertical',  # label='Update Metadata from',\n            text='Metadata',\n            collapsed=True,\n        )\n        self._layer_metadata_update = PushButton(\n            label='Update Metadata from Selected Layer'\n        )\n\n        self._dim_order = Label(\n            label='Dimension Order: ',\n            tooltip='Sanity check for available dimensions.',\n        )\n        self._num_scenes = Label(\n            label='Number of Scenes: ',\n        )\n\n        self._channel_names = LineEdit(\n            label='Channel Name(s)',\n            tooltip='Enter channel names as a list. If left blank or the '\n            'channel names are not the proper length, then default channel '\n            'names will be used.',\n        )\n\n        self._scale_tuple = TupleEdit(\n            label='Scale, ZYX',\n            tooltip='Pixel size, usually in \u03bcm',\n            value=(0.0000, 1.0000, 1.0000),\n            options={'step': 0.0001},\n        )\n        self._scale_layers_button = PushButton(\n            label='Scale Layer(s)',\n            tooltip='Scale the selected layer(s) based on the given scale.',\n        )\n\n\n        self._metadata_container.extend([\n            # self._file_metadata_update,\n            self._layer_metadata_update,\n            self._dim_order,\n            self._num_scenes,\n            self._channel_names,\n            self._scale_tuple,\n            self._scale_layers_button,\n        ])\n\n    def _init_scene_container(self):\n        \"\"\"Initialize the scene container, allowing scene saving.\"\"\"\n        self._scene_container = Container(\n            layout='horizontal',\n            tooltip='Must be in list index format. Ex: [0, 1, 2] or [5:10]',\n        )\n        self._scenes_to_extract = LineEdit(\n            # label=\"Scenes to Extract\",\n            tooltip='Enter the scenes to extract as a list. If left blank '\n            'then all scenes will be extracted.',\n        )\n        self._extract_scenes = PushButton(\n            label='Extract and Save Scenes',\n            tooltip='Extract scenes from a single selected file.',\n        )\n        self._scene_container.append(self._scenes_to_extract)\n        self._scene_container.append(self._extract_scenes)\n\n    def _init_save_layers_container(self):\n        \"\"\"Initialize the container to save images, labels, and shapes.\"\"\"\n        self._save_layers_container = Container(\n            layout='horizontal',\n            label='Save Selected Layers',\n        )\n        self._save_layers_button = PushButton(\n            label='Save Selected Layers',\n            tooltip='Concatenate and save all selected layers as OME-TIFF.'\n            'Layers will save to corresponding directories based on the layer'\n            'type, e.g. Images, Labels, ShapesAsLabels. Shapes are saved as'\n            'labels based on the selected image layer dimensions. If multiple'\n            'layer types are selected, then the image will save to Layers.',\n        )\n        # self._export_figure_button = PushButton(\n        #     label='Export Figure',\n        #     tooltip='Export the current canvas figure to the save directory. '\n        #     'Saves image as a PNG to Figures directory.',\n        # )\n        self._save_layers_container.extend([\n            self._save_layers_button,\n            # self._export_figure_button,\n        ])\n\n    def _init_figure_options_container(self):\n        \"\"\"Initialize the container for figure options.\"\"\"\n        self._figure_options_container = CollapsibleContainer(\n            layout='vertical',\n            text='Figure Options',\n            collapsed=True,\n        )\n        self._figure_scale_factor = SpinBox(\n            label='Scale Factor',\n            min=0,\n            step=1,\n            value=1,\n        )\n        self._use_current_canvas_size = CheckBox(\n            label='Use current canvas dimensions',\n            value=True\n        )\n        self._current_canvas_dims = Label(label='Canvas Dimensions: ')\n        self._canvas_size = TupleEdit(\n            label='Canvas Size',\n            value=(0, 0),\n        )\n        # use this to automatically change the camera parameters\n        self._camera_zoom = SpinBox(\n            label='Camera Zoom',\n            min=0,\n            step=0.1,\n            value=self._viewer.camera.zoom,\n        )\n        self._camera_angle = TupleEdit(\n            label='Camera Angle',\n            value=(0, 0, 90),\n            options={'step': 1},\n        )\n        self._figure_options_container.extend([\n            self._figure_scale_factor,\n            self._use_current_canvas_size,\n            self._current_canvas_dims,\n            self._canvas_size,\n            self._camera_zoom,\n            self._camera_angle,\n        ])\n\n    def _connect_events(self):\n        \"\"\"Connect the events of the widgets to respective methods.\"\"\"\n        self._files.changed.connect(self.update_metadata_on_file_select)\n        self._append_scene_button.clicked.connect(self.append_scene_to_name)\n        self._open_image_button.clicked.connect(self.open_images)\n        self._select_next_image_button.clicked.connect(self.select_next_images)\n\n        self._layer_metadata_update.clicked.connect(\n            self.update_metadata_from_layer\n        )\n        self._scale_layers_button.clicked.connect(self.rescale_by)\n\n        self._concatenate_files_button.clicked.connect(self.save_files_as_ome_tiff)\n        self._concatenate_batch_button.clicked.connect(self.batch_concatenate_files)\n        self._extract_scenes.clicked.connect(self.save_scenes_ome_tiff)\n        self._save_layers_button.clicked.connect(self.save_layers_as_ome_tiff)\n        # self._export_figure_button.clicked.connect(self.export_figure)\n        self._results._on_value_change()\n\n    @property\n    def p_sizes(self):\n        \"\"\"\n        Get the physical pixel sizes.\n\n        Returns\n        -------\n        PhysicalPixelSizes\n            The physical pixel sizes.\n\n        \"\"\"\n        from bioio_base.types import PhysicalPixelSizes\n\n        return PhysicalPixelSizes(\n            self._scale_tuple.value[0],\n            self._scale_tuple.value[1],\n            self._scale_tuple.value[2],\n        )\n\n    # Converted\n    def _update_metadata_from_Image(\n        self,\n        img: BioImage,\n        update_channel_names: bool = True,\n        update_scale: bool = True,\n    ):\n        \"\"\"\n        Update the metadata based on the given image.\n\n        Parameters\n        ----------\n        img : BioImage\n            The image from which to update the metadata.\n        update_channel_names : bool, optional\n            Update the channel names, by default True.\n        update_scale : bool, optional\n            Update the scale, by default True.\n\n        \"\"\"\n        self._dim_order.value = img.dims.order\n        self._num_scenes.value = str(len(img.scenes))\n\n        self._squeezed_dims = helpers.get_squeezed_dim_order(img)\n\n        if update_channel_names:\n            self._channel_names.value = helpers.get_channel_names(img)\n        if update_scale:\n            self._scale_tuple.value = (\n                img.physical_pixel_sizes.Z or 1,\n                img.physical_pixel_sizes.Y or 1,\n                img.physical_pixel_sizes.X or 1,\n            )\n\n    # Converted\n    def update_metadata_on_file_select(self):\n        \"\"\"Update self._save_name.value and metadata if selected.\"\"\"\n        # TODO: get true stem of file, in case .ome.tiff\n        self._save_name.value = str(self._files.value[0].stem)\n        img = nImage(self._files.value[0])\n\n        self._update_metadata_from_Image(\n            img,\n            update_channel_names=self._update_channel_names.value,\n            update_scale=self._update_scale.value,\n        )\n\n    # Added\n    def append_scene_to_name(self):\n        \"\"\"Append the scene to the save name.\"\"\"\n        if self._viewer.layers.selection.active is not None:\n            try:\n                img = self._viewer.layers.selection.active.metadata['bioimage']\n                # remove bad characters from scene name\n                scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n                self._save_name.value = f'{self._save_name.value}_{scene}'\n            except AttributeError:\n                self._results.value = (\n                    'Tried to append scene to name, but layer not opened with'\n                    ' nDev reader.'\n                )\n        else:\n            self._results.value = (\n                'Tried to append scene to name, but no layer selected.'\n                ' So the first scene from the first file will be appended.'\n            )\n            img = nImage(self._files.value[0])\n            scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n            self._save_name.value = f'{self._save_name.value}_{scene}'\n\n    # Converted\n    def update_metadata_from_layer(self):\n        \"\"\"\n        Update metadata from the selected layer.\n\n        Expects images to be opened with napari-ndev reader.\n\n        Note:\n        ----\n        This should also support napari-bioio in the future, when released.\n\n        \"\"\"\n        selected_layer = self._viewer.layers.selection.active\n        try:\n            img = selected_layer.metadata['bioimage']\n            self._update_metadata_from_Image(img)\n\n        except AttributeError:\n            self._results.value = (\n                'Tried to update metadata, but no layer selected.'\n                f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n            )\n        except KeyError:\n            scale = selected_layer.scale\n            self._scale_tuple.value = (\n                scale[-3] if len(scale) &gt;= 3 else 1,\n                scale[-2],\n                scale[-1],\n            )\n            self._results.value = (\n                'Tried to update metadata, but could only update scale'\n                ' because layer not opened with nDev reader.'\n                f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n            )\n\n    # Converted\n    def open_images(self):\n        \"\"\"Open the selected images in the napari viewer with napari-ndev.\"\"\"\n        self._viewer.open(self._files.value, plugin='napari-ndev')\n\n    @staticmethod\n    def _natural_sort_key(s):\n        return [\n            int(text) if text.isdigit() else text.lower()\n            for text in re.split(r'(\\d+)', s)\n        ]\n\n    # Converted\n    def select_next_images(self):\n        from natsort import os_sorted\n        \"\"\"Open the next set of images in the directyory.\"\"\"\n        num_files = self._files.value.__len__()\n\n        # get the parent directory of the first file\n        first_file = self._files.value[0]\n        parent_dir = first_file.parent\n\n        # get the list of files in the parent directory\n        files = list(parent_dir.glob(f'*{first_file.suffix}'))\n        # sort the files naturally (case-insensitive and numbers in order)\n        # like would be scene in windows file explorer default sorting\n        # https://pypi.org/project/natsort/#sort-paths-like-my-file-browser-e-g-windows-explorer-on-windows\n\n        files = os_sorted(files)\n\n        # get the index of the first file in the list and then the next files\n        idx = files.index(first_file)\n        next_files = files[idx + num_files : idx + num_files + num_files]\n\n        # if there are no more files, then return\n        if not next_files:\n            self._results.value = (\n                'No more file sets to select.'\n            )\n            return\n        # set the nwe save names, and update the file value\n        img = nImage(next_files[0])\n\n        self._save_name.value = helpers.create_id_string(img, next_files[0].stem)\n        self._files.value = next_files\n\n        self.update_metadata_on_file_select()\n\n    # Converted\n    def rescale_by(self):\n        \"\"\"Rescale the selected layers based on the given scale.\"\"\"\n        layers = self._viewer.layers.selection\n        scale_tup = self._scale_tuple.value\n\n        for layer in layers:\n            scale_len = len(layer.scale)\n            # get the scale_tup from the back of the tuple first, in case dims\n            # are missing in the new layer\n            layer.scale = scale_tup[-scale_len:]\n\n    def concatenate_files(\n        self,\n        files: str | Path | list[str | Path],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Concatenate the image data from the selected files.\n\n        Removes \"empty\" channels, which are channels with no values above 0.\n        This is present in some microscope formats where it will image in RGB,\n        and then leave empty channels not represented by the color channels.\n\n        Does not currently handle scenes.\n\n        Parameters\n        ----------\n        files : str or Path or list of str or Path\n            The file(s) to concatenate.\n\n        Returns\n        -------\n        numpy.ndarray\n            The concatenated image data.\n\n        \"\"\"\n        array_list = []\n\n        for file in files:\n            img = nImage(file)\n\n            if 'S' in img.dims.order:\n                img_data = img.get_image_data('TSZYX')\n            else:\n                img_data = img.data\n\n            # iterate over all channels and only keep if not blank\n            for idx in range(img_data.shape[1]):\n                array = img_data[:, [idx], :, :, :]\n                if array.max() &gt; 0:\n                    array_list.append(array)\n        return np.concatenate(array_list, axis=1)\n\n    def concatenate_layers(\n        self,\n        layers: Layer | list[Layer],\n    ) -&gt; np.ndarray:\n        \"\"\"\n        Concatenate the image data from the selected layers.\n\n        Adapts all layers to 5D arrays for compatibility with image dims.\n        If the layer is a shapes layer, it will look for a corresponding image\n        layer to get the dimensions for the shapes layer.\n\n        Parameters\n        ----------\n        layers : napari.layers.Image or list of napari.layers.Image\n            The selected image layers.\n\n        Returns\n        -------\n        numpy.ndarray\n            The concatenated image data.\n\n        \"\"\"\n        if any(isinstance(layer, ShapesLayer) for layer in layers):\n            label_dim = self._get_dims_for_shape_layer(layers)\n\n        array_list = []\n\n        for layer in layers:\n            if isinstance(layer, ShapesLayer):\n                layer_data = layer.to_labels(labels_shape=label_dim)\n                layer_data = layer_data.astype(np.int16)\n            else:\n                layer_data = layer.data\n\n            # convert to 5D array for compatability with image dims\n            while len(layer_data.shape) &lt; 5:\n                layer_data = np.expand_dims(layer_data, axis=0)\n            array_list.append(layer_data)\n\n        return np.concatenate(array_list, axis=1)\n\n    def _get_dims_for_shape_layer(self, layers) -&gt; tuple[int]:\n        # TODO: Fix this not getting the first instance of the image layer\n        # get first instance of a napari.layers.Image or napari.layers.Labels\n        dim_layer = next(\n                (layer for layer in layers if isinstance(layer, (ImageLayer, LabelsLayer))),\n                None,\n            )\n        # if none of these layers is selected, get it from the first instance in the viewer\n        if dim_layer is None:\n            dim_layer = next(\n                    (layer for layer in self._viewer.layers if isinstance(layer, (ImageLayer, LabelsLayer))),\n                    None,\n                )\n        if dim_layer is None:\n            raise ValueError('No image or labels present to convert shapes layer.')\n        label_dim = dim_layer.data.shape\n            # drop last axis if represents RGB image\n        label_dim = label_dim[:-1] if label_dim[-1] == 3 else label_dim\n        return label_dim\n\n    def _get_save_loc(\n        self, root_dir: Path, parent: str, file_name: str\n    ) -&gt; Path:\n        \"\"\"\n        Get the save location based on the parent directory.\n\n        Parameters\n        ----------\n        root_dir : Path\n            The root directory.\n        parent : str\n            The parent directory. eg. 'Image', 'Labels', 'ShapesAsLabels'\n        file_name : str\n            The file name.\n\n        Returns\n        -------\n        Path\n            The save location. root_dir / parent / file_name\n\n        \"\"\"\n        save_directory = root_dir / parent\n        save_directory.mkdir(parents=False, exist_ok=True)\n        return save_directory / file_name\n\n    def _common_save_logic(\n        self,\n        data: np.ndarray,\n        uri: Path,\n        dim_order: str,\n        channel_names: list[str],\n        image_name: str | list[str | None] | None,\n        result_str: str,\n    ) -&gt; None:\n        \"\"\"\n        Save data as OME-TIFF with bioio based on common logic.\n\n        Converts labels to np.int32 if np.int64 is detected, due to bioio\n        not supporting np.int64 labels, even though napari and other libraries\n        generate np.int64 labels.\n\n        Parameters\n        ----------\n        data : np.ndarray\n            The data to save.\n        uri : Path\n            The URI to save the data to.\n        dim_order : str\n            The dimension order.\n        channel_names : list[str]\n            The channel names saved to OME metadata\n        image_name : str | list[str | None] | None\n            The image name saved to OME metadata\n        result_str : str\n            The string used for the result widget.\n\n        \"\"\"\n        # TODO: add image_name to save method\n        from bioio.writers import OmeTiffWriter\n\n        # BioImage does not allow saving labels as np.int64\n        # napari generates labels differently depending on the OS\n        # so we need to convert to np.int32 in case np.int64 generated\n        # see: https://github.com/napari/napari/issues/5545\n        # This is a failsafe\n        if data.dtype == np.int64:\n            data = data.astype(np.int32)\n\n        try:\n            OmeTiffWriter.save(\n                data=data,\n                uri=uri,\n                dim_order=dim_order or None,\n                channel_names=channel_names or None,\n                image_name=image_name or None,\n                physical_pixel_sizes=self.p_sizes,\n            )\n            self._results.value = f'Saved {result_str}: ' + str(\n                self._save_name.value\n            ) + f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        # if ValueError is raised, save with default channel names\n        except ValueError as e:\n            OmeTiffWriter.save(\n                data=data,\n                uri=uri,\n                dim_order=dim_order,\n                image_name=image_name or None,\n                physical_pixel_sizes=self.p_sizes,\n            )\n            self._results.value = (\n                'ValueError: '\n                + str(e)\n                + '\\nSo, saved with default channel names: \\n'\n                + str(self._save_name.value)\n                + f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n            )\n        return\n\n    def _determine_save_directory(self, save_dir: str | None = None) -&gt; str:\n        if self._save_directory_prefix.value != '':\n            save_dir = f'{self._save_directory_prefix.value}_{save_dir}'\n        else:\n            save_dir = f'{save_dir}'\n        return save_dir\n\n    def save_files_as_ome_tiff(self) -&gt; np.ndarray:\n        \"\"\"Save the selected files as OME-TIFF using BioImage.\"\"\"\n        img_data = self.concatenate_files(self._files.value)\n        save_dir = self._determine_save_directory('ConcatenatedImages')\n        img_save_name = f'{self._save_name.value}.tiff'\n        img_save_loc = self._get_save_loc(\n            self._save_directory.value,\n            save_dir,\n            img_save_name,\n        )\n\n        cnames = self._channel_names.value\n        channel_names = ast.literal_eval(cnames) if cnames else None\n\n        self._common_save_logic(\n            data=img_data,\n            uri=img_save_loc,\n            dim_order='TCZYX',\n            channel_names=channel_names,\n            image_name=self._save_name.value,\n            result_str='Concatenated Image',\n        )\n\n        return img_data\n\n    def batch_concatenate_files(self) -&gt; None:\n        \"\"\"\n        Concatenate files in the selected directory.\n\n        Save the concatenated files as OME-TIFF, then select the next set of\n        files in the directory to be concatenated. This is done by iterating\n        over the remaining files in the directory based on the number of files\n        selected. The files are sorted alphabetically and numerically. The\n        files will be concatenated until no more files are left in the parent\n        directory.\n        \"\"\"\n        # get total number of sets of files in the directory\n        parent_dir = self._files.value[0].parent\n        total_num_files = len(list(parent_dir.glob(f'*{self._files.value[0].suffix}')))\n        num_files = self._files.value.__len__()\n        num_file_sets = total_num_files // num_files\n\n        # check if channel names and scale are different than in the first file\n        # if so, turn off the update options\n        first_image = nImage(self._files.value[0])\n        if first_image.channel_names != self._channel_names.value:\n            self._update_channel_names.value = False\n        if first_image.physical_pixel_sizes != self.p_sizes:\n            self._update_scale.value = False\n\n\n        # save first set of files\n        self.save_files_as_ome_tiff()\n        # iterate through the remaining sets of files in the directory\n        for _ in range(num_file_sets):\n            self.select_next_images()\n            self.save_files_as_ome_tiff()\n\n        self._results.value = (\n            'Batch concatenated files in directory.'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n\n    def save_scenes_ome_tiff(self) -&gt; None:\n        \"\"\"\n        Save selected scenes as OME-TIFF.\n\n        This method is intended to save scenes from a single file. The scenes\n        are extracted based on the scenes_to_extract widget value, which is a\n        list of scene indices. If the widget is left blank, then all scenes\n        will be extracted.\n\n        \"\"\"\n        img = nImage(self._files.value[0])\n\n        scenes = self._scenes_to_extract.value\n        scenes_list = ast.literal_eval(scenes) if scenes else img.scenes\n        save_dir = self._determine_save_directory('ExtractedScenes')\n        save_directory = self._save_directory.value / save_dir\n        save_directory.mkdir(parents=False, exist_ok=True)\n\n        for scene in scenes_list:\n            # TODO: fix this to not have an issue if there are identical scenes\n            # presented as strings, though the asssumption is most times the\n            # user will input a list of integers.\n            img.set_scene(scene)\n\n            base_save_name = self._save_name.value.split('.')[0]\n            image_id = helpers.create_id_string(img, base_save_name)\n\n            img_save_name = f'{image_id}.tiff'\n            img_save_loc = save_directory / img_save_name\n\n            # get channel names from widget if truthy\n            cnames = self._channel_names.value\n            channel_names = ast.literal_eval(cnames) if cnames else None\n\n            self._common_save_logic(\n                data=img.data,\n                uri=img_save_loc,\n                dim_order='TCZYX',\n                channel_names=channel_names,\n                image_name=image_id,\n                result_str=f'Scene: {img.current_scene}',\n            )\n\n        self._results.value = (\n            f'Saved extracted scenes: {scenes_list}'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n        return\n\n    def save_layers_as_ome_tiff(self) -&gt; np.ndarray:\n        \"\"\"\n        Save the selected layers as OME-TIFF.\n\n        Determines types of layers and saves to corresponding directories.\n        \"\"\"\n        layer_data = self.concatenate_layers(\n            list(self._viewer.layers.selection)\n        )\n        # get the types of layers, to know where to save the image\n        layer_types = [\n            type(layer).__name__ for layer in self._viewer.layers.selection\n        ]\n\n        # if there are multiple layer types, save to Layers directory\n        layer_save_type = 'Layers' if len(set(layer_types)) &gt; 1 else layer_types[0]\n        layer_save_dir = self._determine_save_directory(layer_save_type)\n        layer_save_name = f'{self._save_name.value}.tiff'\n        layer_save_loc = self._get_save_loc(\n            self._save_directory.value, layer_save_dir, layer_save_name\n        )\n\n        # only get channel names if layer_save_type is not shapes or labels layer\n        if layer_save_type not in ['Shapes', 'Labels']:\n            cnames = self._channel_names.value\n            channel_names = ast.literal_eval(cnames) if cnames else None\n        else:\n            channel_names = [layer_save_type]\n\n        if layer_save_type == 'Shapes':\n            layer_data = layer_data.astype(np.int16)\n\n        elif layer_save_type == 'Labels':\n            if layer_data.max() &gt; 65535:\n                layer_data = layer_data.astype(np.int32)\n            else:\n                layer_data = layer_data.astype(np.int16)\n\n        self._common_save_logic(\n            data=layer_data,\n            uri=layer_save_loc,\n            dim_order='TCZYX',\n            channel_names=channel_names,\n            image_name=self._save_name.value,\n            result_str=layer_save_type,\n        )\n\n        return layer_data\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.p_sizes","title":"p_sizes  <code>property</code>","text":"<pre><code>p_sizes\n</code></pre> <p>Get the physical pixel sizes.</p> <p>Returns:</p> <ul> <li> <code>PhysicalPixelSizes</code>           \u2013            <p>The physical pixel sizes.</p> </li> </ul>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.__init__","title":"__init__","text":"<pre><code>__init__(viewer=None)\n</code></pre> <p>Initialize the UtilitiesContainer widget.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def __init__(self, viewer: napari.viewer.Viewer = None):\n    \"\"\"\n    Initialize the UtilitiesContainer widget.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer, optional\n        The napari viewer instance.\n\n    \"\"\"\n    super().__init__(labels=False)\n\n    self.min_width = 500 # TODO: remove this hardcoded value\n    self._viewer = viewer if viewer is not None else None\n    self._squeezed_dims = None\n\n    self._init_widgets()\n    self._init_save_name_container()\n    self._init_file_options_container()\n    self._init_open_image_container()\n    self._init_metadata_container()\n    self._init_concatenate_files_container()\n    self._init_save_layers_container()\n    self._init_scene_container()\n    # self._init_figure_options_container() # TODO: add figure saving\n    self._init_layout()\n    self._connect_events()\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.__init__(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.append_scene_to_name","title":"append_scene_to_name","text":"<pre><code>append_scene_to_name()\n</code></pre> <p>Append the scene to the save name.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def append_scene_to_name(self):\n    \"\"\"Append the scene to the save name.\"\"\"\n    if self._viewer.layers.selection.active is not None:\n        try:\n            img = self._viewer.layers.selection.active.metadata['bioimage']\n            # remove bad characters from scene name\n            scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n            self._save_name.value = f'{self._save_name.value}_{scene}'\n        except AttributeError:\n            self._results.value = (\n                'Tried to append scene to name, but layer not opened with'\n                ' nDev reader.'\n            )\n    else:\n        self._results.value = (\n            'Tried to append scene to name, but no layer selected.'\n            ' So the first scene from the first file will be appended.'\n        )\n        img = nImage(self._files.value[0])\n        scene = re.sub(r'[^\\w\\s]', '-', img.current_scene)\n        self._save_name.value = f'{self._save_name.value}_{scene}'\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.batch_concatenate_files","title":"batch_concatenate_files","text":"<pre><code>batch_concatenate_files()\n</code></pre> <p>Concatenate files in the selected directory.</p> <p>Save the concatenated files as OME-TIFF, then select the next set of files in the directory to be concatenated. This is done by iterating over the remaining files in the directory based on the number of files selected. The files are sorted alphabetically and numerically. The files will be concatenated until no more files are left in the parent directory.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def batch_concatenate_files(self) -&gt; None:\n    \"\"\"\n    Concatenate files in the selected directory.\n\n    Save the concatenated files as OME-TIFF, then select the next set of\n    files in the directory to be concatenated. This is done by iterating\n    over the remaining files in the directory based on the number of files\n    selected. The files are sorted alphabetically and numerically. The\n    files will be concatenated until no more files are left in the parent\n    directory.\n    \"\"\"\n    # get total number of sets of files in the directory\n    parent_dir = self._files.value[0].parent\n    total_num_files = len(list(parent_dir.glob(f'*{self._files.value[0].suffix}')))\n    num_files = self._files.value.__len__()\n    num_file_sets = total_num_files // num_files\n\n    # check if channel names and scale are different than in the first file\n    # if so, turn off the update options\n    first_image = nImage(self._files.value[0])\n    if first_image.channel_names != self._channel_names.value:\n        self._update_channel_names.value = False\n    if first_image.physical_pixel_sizes != self.p_sizes:\n        self._update_scale.value = False\n\n\n    # save first set of files\n    self.save_files_as_ome_tiff()\n    # iterate through the remaining sets of files in the directory\n    for _ in range(num_file_sets):\n        self.select_next_images()\n        self.save_files_as_ome_tiff()\n\n    self._results.value = (\n        'Batch concatenated files in directory.'\n        f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n    )\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_files","title":"concatenate_files","text":"<pre><code>concatenate_files(files)\n</code></pre> <p>Concatenate the image data from the selected files.</p> <p>Removes \"empty\" channels, which are channels with no values above 0. This is present in some microscope formats where it will image in RGB, and then leave empty channels not represented by the color channels.</p> <p>Does not currently handle scenes.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The concatenated image data.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def concatenate_files(\n    self,\n    files: str | Path | list[str | Path],\n) -&gt; np.ndarray:\n    \"\"\"\n    Concatenate the image data from the selected files.\n\n    Removes \"empty\" channels, which are channels with no values above 0.\n    This is present in some microscope formats where it will image in RGB,\n    and then leave empty channels not represented by the color channels.\n\n    Does not currently handle scenes.\n\n    Parameters\n    ----------\n    files : str or Path or list of str or Path\n        The file(s) to concatenate.\n\n    Returns\n    -------\n    numpy.ndarray\n        The concatenated image data.\n\n    \"\"\"\n    array_list = []\n\n    for file in files:\n        img = nImage(file)\n\n        if 'S' in img.dims.order:\n            img_data = img.get_image_data('TSZYX')\n        else:\n            img_data = img.data\n\n        # iterate over all channels and only keep if not blank\n        for idx in range(img_data.shape[1]):\n            array = img_data[:, [idx], :, :, :]\n            if array.max() &gt; 0:\n                array_list.append(array)\n    return np.concatenate(array_list, axis=1)\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_files(files)","title":"<code>files</code>","text":"(<code>str or Path or list of str or Path</code>)           \u2013            <p>The file(s) to concatenate.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_layers","title":"concatenate_layers","text":"<pre><code>concatenate_layers(layers)\n</code></pre> <p>Concatenate the image data from the selected layers.</p> <p>Adapts all layers to 5D arrays for compatibility with image dims. If the layer is a shapes layer, it will look for a corresponding image layer to get the dimensions for the shapes layer.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The concatenated image data.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def concatenate_layers(\n    self,\n    layers: Layer | list[Layer],\n) -&gt; np.ndarray:\n    \"\"\"\n    Concatenate the image data from the selected layers.\n\n    Adapts all layers to 5D arrays for compatibility with image dims.\n    If the layer is a shapes layer, it will look for a corresponding image\n    layer to get the dimensions for the shapes layer.\n\n    Parameters\n    ----------\n    layers : napari.layers.Image or list of napari.layers.Image\n        The selected image layers.\n\n    Returns\n    -------\n    numpy.ndarray\n        The concatenated image data.\n\n    \"\"\"\n    if any(isinstance(layer, ShapesLayer) for layer in layers):\n        label_dim = self._get_dims_for_shape_layer(layers)\n\n    array_list = []\n\n    for layer in layers:\n        if isinstance(layer, ShapesLayer):\n            layer_data = layer.to_labels(labels_shape=label_dim)\n            layer_data = layer_data.astype(np.int16)\n        else:\n            layer_data = layer.data\n\n        # convert to 5D array for compatability with image dims\n        while len(layer_data.shape) &lt; 5:\n            layer_data = np.expand_dims(layer_data, axis=0)\n        array_list.append(layer_data)\n\n    return np.concatenate(array_list, axis=1)\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.concatenate_layers(layers)","title":"<code>layers</code>","text":"(<code>napari.layers.Image or list of napari.layers.Image</code>)           \u2013            <p>The selected image layers.</p>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.open_images","title":"open_images","text":"<pre><code>open_images()\n</code></pre> <p>Open the selected images in the napari viewer with napari-ndev.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def open_images(self):\n    \"\"\"Open the selected images in the napari viewer with napari-ndev.\"\"\"\n    self._viewer.open(self._files.value, plugin='napari-ndev')\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.rescale_by","title":"rescale_by","text":"<pre><code>rescale_by()\n</code></pre> <p>Rescale the selected layers based on the given scale.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def rescale_by(self):\n    \"\"\"Rescale the selected layers based on the given scale.\"\"\"\n    layers = self._viewer.layers.selection\n    scale_tup = self._scale_tuple.value\n\n    for layer in layers:\n        scale_len = len(layer.scale)\n        # get the scale_tup from the back of the tuple first, in case dims\n        # are missing in the new layer\n        layer.scale = scale_tup[-scale_len:]\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.save_files_as_ome_tiff","title":"save_files_as_ome_tiff","text":"<pre><code>save_files_as_ome_tiff()\n</code></pre> <p>Save the selected files as OME-TIFF using BioImage.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def save_files_as_ome_tiff(self) -&gt; np.ndarray:\n    \"\"\"Save the selected files as OME-TIFF using BioImage.\"\"\"\n    img_data = self.concatenate_files(self._files.value)\n    save_dir = self._determine_save_directory('ConcatenatedImages')\n    img_save_name = f'{self._save_name.value}.tiff'\n    img_save_loc = self._get_save_loc(\n        self._save_directory.value,\n        save_dir,\n        img_save_name,\n    )\n\n    cnames = self._channel_names.value\n    channel_names = ast.literal_eval(cnames) if cnames else None\n\n    self._common_save_logic(\n        data=img_data,\n        uri=img_save_loc,\n        dim_order='TCZYX',\n        channel_names=channel_names,\n        image_name=self._save_name.value,\n        result_str='Concatenated Image',\n    )\n\n    return img_data\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.save_layers_as_ome_tiff","title":"save_layers_as_ome_tiff","text":"<pre><code>save_layers_as_ome_tiff()\n</code></pre> <p>Save the selected layers as OME-TIFF.</p> <p>Determines types of layers and saves to corresponding directories.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def save_layers_as_ome_tiff(self) -&gt; np.ndarray:\n    \"\"\"\n    Save the selected layers as OME-TIFF.\n\n    Determines types of layers and saves to corresponding directories.\n    \"\"\"\n    layer_data = self.concatenate_layers(\n        list(self._viewer.layers.selection)\n    )\n    # get the types of layers, to know where to save the image\n    layer_types = [\n        type(layer).__name__ for layer in self._viewer.layers.selection\n    ]\n\n    # if there are multiple layer types, save to Layers directory\n    layer_save_type = 'Layers' if len(set(layer_types)) &gt; 1 else layer_types[0]\n    layer_save_dir = self._determine_save_directory(layer_save_type)\n    layer_save_name = f'{self._save_name.value}.tiff'\n    layer_save_loc = self._get_save_loc(\n        self._save_directory.value, layer_save_dir, layer_save_name\n    )\n\n    # only get channel names if layer_save_type is not shapes or labels layer\n    if layer_save_type not in ['Shapes', 'Labels']:\n        cnames = self._channel_names.value\n        channel_names = ast.literal_eval(cnames) if cnames else None\n    else:\n        channel_names = [layer_save_type]\n\n    if layer_save_type == 'Shapes':\n        layer_data = layer_data.astype(np.int16)\n\n    elif layer_save_type == 'Labels':\n        if layer_data.max() &gt; 65535:\n            layer_data = layer_data.astype(np.int32)\n        else:\n            layer_data = layer_data.astype(np.int16)\n\n    self._common_save_logic(\n        data=layer_data,\n        uri=layer_save_loc,\n        dim_order='TCZYX',\n        channel_names=channel_names,\n        image_name=self._save_name.value,\n        result_str=layer_save_type,\n    )\n\n    return layer_data\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.save_scenes_ome_tiff","title":"save_scenes_ome_tiff","text":"<pre><code>save_scenes_ome_tiff()\n</code></pre> <p>Save selected scenes as OME-TIFF.</p> <p>This method is intended to save scenes from a single file. The scenes are extracted based on the scenes_to_extract widget value, which is a list of scene indices. If the widget is left blank, then all scenes will be extracted.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def save_scenes_ome_tiff(self) -&gt; None:\n    \"\"\"\n    Save selected scenes as OME-TIFF.\n\n    This method is intended to save scenes from a single file. The scenes\n    are extracted based on the scenes_to_extract widget value, which is a\n    list of scene indices. If the widget is left blank, then all scenes\n    will be extracted.\n\n    \"\"\"\n    img = nImage(self._files.value[0])\n\n    scenes = self._scenes_to_extract.value\n    scenes_list = ast.literal_eval(scenes) if scenes else img.scenes\n    save_dir = self._determine_save_directory('ExtractedScenes')\n    save_directory = self._save_directory.value / save_dir\n    save_directory.mkdir(parents=False, exist_ok=True)\n\n    for scene in scenes_list:\n        # TODO: fix this to not have an issue if there are identical scenes\n        # presented as strings, though the asssumption is most times the\n        # user will input a list of integers.\n        img.set_scene(scene)\n\n        base_save_name = self._save_name.value.split('.')[0]\n        image_id = helpers.create_id_string(img, base_save_name)\n\n        img_save_name = f'{image_id}.tiff'\n        img_save_loc = save_directory / img_save_name\n\n        # get channel names from widget if truthy\n        cnames = self._channel_names.value\n        channel_names = ast.literal_eval(cnames) if cnames else None\n\n        self._common_save_logic(\n            data=img.data,\n            uri=img_save_loc,\n            dim_order='TCZYX',\n            channel_names=channel_names,\n            image_name=image_id,\n            result_str=f'Scene: {img.current_scene}',\n        )\n\n    self._results.value = (\n        f'Saved extracted scenes: {scenes_list}'\n        f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n    )\n    return\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.update_metadata_from_layer","title":"update_metadata_from_layer","text":"<pre><code>update_metadata_from_layer()\n</code></pre> <p>Update metadata from the selected layer.</p> <p>Expects images to be opened with napari-ndev reader.</p> Note: <p>This should also support napari-bioio in the future, when released.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def update_metadata_from_layer(self):\n    \"\"\"\n    Update metadata from the selected layer.\n\n    Expects images to be opened with napari-ndev reader.\n\n    Note:\n    ----\n    This should also support napari-bioio in the future, when released.\n\n    \"\"\"\n    selected_layer = self._viewer.layers.selection.active\n    try:\n        img = selected_layer.metadata['bioimage']\n        self._update_metadata_from_Image(img)\n\n    except AttributeError:\n        self._results.value = (\n            'Tried to update metadata, but no layer selected.'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n    except KeyError:\n        scale = selected_layer.scale\n        self._scale_tuple.value = (\n            scale[-3] if len(scale) &gt;= 3 else 1,\n            scale[-2],\n            scale[-1],\n        )\n        self._results.value = (\n            'Tried to update metadata, but could only update scale'\n            ' because layer not opened with nDev reader.'\n            f'\\nAt {time.strftime(\"%H:%M:%S\")}'\n        )\n</code></pre>"},{"location":"api/widgets/image_utilities/#napari_ndev.widgets._utilities_container.UtilitiesContainer.update_metadata_on_file_select","title":"update_metadata_on_file_select","text":"<pre><code>update_metadata_on_file_select()\n</code></pre> <p>Update self._save_name.value and metadata if selected.</p> Source code in <code>src/napari_ndev/widgets/_utilities_container.py</code> <pre><code>def update_metadata_on_file_select(self):\n    \"\"\"Update self._save_name.value and metadata if selected.\"\"\"\n    # TODO: get true stem of file, in case .ome.tiff\n    self._save_name.value = str(self._files.value[0].stem)\n    img = nImage(self._files.value[0])\n\n    self._update_metadata_from_Image(\n        img,\n        update_channel_names=self._update_channel_names.value,\n        update_scale=self._update_scale.value,\n    )\n</code></pre>"},{"location":"api/widgets/measure_widget/","title":"Measure widget","text":""},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container","title":"napari_ndev.widgets._measure_container","text":""},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer","title":"MeasureContainer","text":"<p>               Bases: <code>Container</code></p> <p>Widget to measure labels from folders.</p> <p>This class provides functionality to measure labels and compare them against intensity images, which can be microscopic images or other labels. It initializes various widgets and containers for user input and interaction, and connects events to handle user actions.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>_label_choices</code>               (<code>list</code>)           \u2013            <p>List of label choices.</p> </li> <li> <code>_intensity_choices</code>               (<code>list</code>)           \u2013            <p>List of intensity image choices.</p> </li> <li> <code>_p_sizes</code>               (<code>None</code>)           \u2013            <p>Placeholder for pixel sizes.</p> </li> <li> <code>_squeezed_dims</code>               (<code>None</code>)           \u2013            <p>Placeholder for squeezed dimensions.</p> </li> <li> <code>_prop</code>               (<code>object</code>)           \u2013            <p>Dynamic object to hold region properties checkboxes.</p> </li> <li> <code>_label_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting label directory.</p> </li> <li> <code>_image_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting image directory.</p> </li> <li> <code>_region_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting region directory.</p> </li> <li> <code>_output_directory</code>               (<code>FileEdit</code>)           \u2013            <p>Widget for selecting output directory.</p> </li> <li> <code>_label_image</code>               (<code>ComboBox</code>)           \u2013            <p>Widget for selecting label image.</p> </li> <li> <code>_intensity_images</code>               (<code>Select</code>)           \u2013            <p>Widget for selecting intensity images.</p> </li> <li> <code>_scale_tuple</code>               (<code>TupleEdit</code>)           \u2013            <p>Widget for setting physical pixel sizes.</p> </li> <li> <code>_measure_button</code>               (<code>PushButton</code>)           \u2013            <p>Button to start measurement.</p> </li> <li> <code>_progress_bar</code>               (<code>ProgressBar</code>)           \u2013            <p>Progress bar to show measurement progress.</p> </li> <li> <code>_props_container</code>               (<code>Container</code>)           \u2013            <p>Container for region properties checkboxes.</p> </li> <li> <code>_sk_props</code>               (<code>list</code>)           \u2013            <p>List of region properties.</p> </li> <li> <code>_id_regex_container</code>               (<code>Container</code>)           \u2013            <p>Container for ID regex settings.</p> </li> <li> <code>_example_id_string</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for example ID string.</p> </li> <li> <code>_id_regex_dict</code>               (<code>TextEdit</code>)           \u2013            <p>Widget for ID regex dictionary.</p> </li> <li> <code>_tx_map_container</code>               (<code>Container</code>)           \u2013            <p>Container for treatment map settings.</p> </li> <li> <code>_tx_id</code>               (<code>LineEdit</code>)           \u2013            <p>Widget for treatment ID.</p> </li> <li> <code>_tx_n_well</code>               (<code>ComboBox</code>)           \u2013            <p>Widget for number of wells.</p> </li> <li> <code>_tx_dict</code>               (<code>TextEdit</code>)           \u2013            <p>Widget for treatment dictionary.</p> </li> <li> <code>_grouping_container</code>               (<code>Container</code>)           \u2013            <p>Container for grouping settings.</p> </li> <li> <code>_create_grouped</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox to create grouped data.</p> </li> <li> <code>_group_by_sample_id</code>               (<code>CheckBox</code>)           \u2013            <p>Checkbox to group by sample ID.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>_init_widgets</code>             \u2013              <p>Initializes the widgets for user input.</p> </li> <li> <code>_init_regionprops_container</code>             \u2013              <p>Initializes the container for region properties checkboxes.</p> </li> <li> <code>_init_id_regex_container</code>             \u2013              <p>Initializes the container for ID regex settings.</p> </li> <li> <code>_init_tx_map_container</code>             \u2013              <p>Initializes the container for treatment map settings.</p> </li> <li> <code>_init_grouping_container</code>             \u2013              <p>Initializes the container for grouping settings.</p> </li> <li> <code>_init_layout</code>             \u2013              <p>Initializes the layout of the container.</p> </li> <li> <code>_connect_events</code>             \u2013              <p>Connects events to handle user actions.</p> </li> <li> <code>_get_0th_img_from_dir</code>             \u2013              <p>Gets the first image from a directory.</p> </li> <li> <code>_update_dim_and_scales</code>             \u2013              <p>Updates the dimensions and scales based on the image.</p> </li> <li> <code>_update_choices</code>             \u2013              <p>Updates the choices for labels and intensity images.</p> </li> <li> <code>_update_image_choices</code>             \u2013              <p>Updates the choices for intensity images.</p> </li> <li> <code>_update_label_choices</code>             \u2013              <p>Updates the choices for label images.</p> </li> <li> <code>_update_region_choices</code>             \u2013              <p>Updates the choices for region images.</p> </li> <li> <code>_safe_dict_eval</code>             \u2013              <p>Safely evaluates a dictionary string.</p> </li> <li> <code>batch_measure</code>             \u2013              <p>Performs batch measurement of labels and intensity images, and returns the measurement results as a DataFrame.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>class MeasureContainer(Container):\n    \"\"\"\n    Widget to measure labels from folders.\n\n    This class provides functionality to measure labels and compare them against intensity images, which can be microscopic images or other labels. It initializes various widgets and containers for user input and interaction, and connects events to handle user actions.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance. Optional.\n\n    Attributes\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    _label_choices : list\n        List of label choices.\n    _intensity_choices : list\n        List of intensity image choices.\n    _p_sizes : None\n        Placeholder for pixel sizes.\n    _squeezed_dims : None\n        Placeholder for squeezed dimensions.\n    _prop : object\n        Dynamic object to hold region properties checkboxes.\n    _label_directory : FileEdit\n        Widget for selecting label directory.\n    _image_directory : FileEdit\n        Widget for selecting image directory.\n    _region_directory : FileEdit\n        Widget for selecting region directory.\n    _output_directory : FileEdit\n        Widget for selecting output directory.\n    _label_image : ComboBox\n        Widget for selecting label image.\n    _intensity_images : Select\n        Widget for selecting intensity images.\n    _scale_tuple : TupleEdit\n        Widget for setting physical pixel sizes.\n    _measure_button : PushButton\n        Button to start measurement.\n    _progress_bar : ProgressBar\n        Progress bar to show measurement progress.\n    _props_container : Container\n        Container for region properties checkboxes.\n    _sk_props : list\n        List of region properties.\n    _id_regex_container : Container\n        Container for ID regex settings.\n    _example_id_string : LineEdit\n        Widget for example ID string.\n    _id_regex_dict : TextEdit\n        Widget for ID regex dictionary.\n    _tx_map_container : Container\n        Container for treatment map settings.\n    _tx_id : LineEdit\n        Widget for treatment ID.\n    _tx_n_well : ComboBox\n        Widget for number of wells.\n    _tx_dict : TextEdit\n        Widget for treatment dictionary.\n    _grouping_container : Container\n        Container for grouping settings.\n    _create_grouped : CheckBox\n        Checkbox to create grouped data.\n    _group_by_sample_id : CheckBox\n        Checkbox to group by sample ID.\n\n    Methods\n    -------\n    _init_widgets()\n        Initializes the widgets for user input.\n    _init_regionprops_container()\n        Initializes the container for region properties checkboxes.\n    _init_id_regex_container()\n        Initializes the container for ID regex settings.\n    _init_tx_map_container()\n        Initializes the container for treatment map settings.\n    _init_grouping_container()\n        Initializes the container for grouping settings.\n    _init_layout()\n        Initializes the layout of the container.\n    _connect_events()\n        Connects events to handle user actions.\n    _get_0th_img_from_dir(directory)\n        Gets the first image from a directory.\n    _update_dim_and_scales(img)\n        Updates the dimensions and scales based on the image.\n    _update_choices(directory, prefix, update_label=False)\n        Updates the choices for labels and intensity images.\n    _update_image_choices()\n        Updates the choices for intensity images.\n    _update_label_choices()\n        Updates the choices for label images.\n    _update_region_choices()\n        Updates the choices for region images.\n    _safe_dict_eval(dict_string, dict_name=None)\n        Safely evaluates a dictionary string.\n    batch_measure()\n        Performs batch measurement of labels and intensity images, and returns the measurement results as a DataFrame.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        viewer: napari.viewer.Viewer = None,\n    ):\n        \"\"\"\n        Initialize the MeasureContainer.\n\n        Parameters\n        ----------\n        viewer : napari.viewer.Viewer\n            The napari viewer instance. Optional.\n\n        \"\"\"\n        super().__init__()\n\n        self.viewer = viewer if viewer is not None else None\n        self._label_choices = []\n        self._intensity_choices = []\n        self._p_sizes = None\n        self._squeezed_dims = None\n        self._prop = type('', (), {})()\n\n        self._init_widgets()\n        self._init_regionprops_container()\n        self._init_id_regex_container()\n        self._init_tx_map_container()\n        self._init_grouping_container()\n        self._init_layout()\n        self._connect_events()\n\n    def _init_widgets(self):\n        \"\"\"Initialize non-container widgets.\"\"\"\n        self._label_directory = FileEdit(label='Label directory', mode='d')\n        self._image_directory = FileEdit(\n            label='Image directory', mode='d', nullable=True\n        )\n        self._region_directory = FileEdit(\n            label='Region directory', mode='d', nullable=True\n        )\n        self._output_directory = FileEdit(label='Output directory', mode='d')\n\n        self._label_images = Select(\n            label='Label image',\n            choices=self._label_choices,\n            allow_multiple=True,\n            nullable=False,\n            tooltip='Select label images to measure',\n        )\n        self._intensity_images = Select(\n            label='Intensity images',\n            choices=self._intensity_choices,\n            allow_multiple=True,\n            nullable=True,\n            tooltip='Select intensity images to compare against labels',\n        )\n        self._scale_tuple = TupleEdit(\n            value=(0.0000, 1.0000, 1.0000),\n            label='Physical Pixel Sizes, ZYX',\n            tooltip='Pixel size, usually in \u03bcm/px',\n            options={'step': 0.0001},\n        )\n        self._measure_button = PushButton(label='Measure')\n\n        self._progress_bar = ProgressBar(label='Progress:')\n\n    def _init_regionprops_container(self):\n        \"\"\"Initialize the container for region properties checkboxes.\"\"\"\n        self._props_container = Container(layout='vertical')\n\n        self._sk_props = [\n            'label',\n            'area',\n            'area_convex',\n            'bbox',\n            'centroid',\n            'eccentricity',\n            'extent',\n            'feret_diameter_max',\n            'intensity_max',\n            'intensity_mean',\n            'intensity_min',\n            'intensity_std',\n            'orientation',\n            'perimeter',\n            'solidity',\n        ]\n\n        for feature in self._sk_props:\n            setattr(self._prop, feature, CheckBox(label=feature))\n            self._props_container.extend([getattr(self._prop, feature)])\n\n        self._prop.label.value = True\n        self._prop.area.value = True\n\n    def _init_id_regex_container(self):\n        \"\"\"Initialize the container for ID regex settings.\"\"\"\n        self._id_regex_container = Container(layout='vertical')\n        self._example_id_string = LineEdit(\n            label='Example ID String',\n            value=None,\n            nullable=True,\n        )\n        self._id_regex_dict = TextEdit(\n            label='ID Regex Dict',\n            value='{\\n\\n}',\n        )\n        self._id_regex_container.extend(\n            [self._example_id_string, self._id_regex_dict]\n        )\n\n    def _init_tx_map_container(self):\n        \"\"\"Initialize the container for treatment map settings.\"\"\"\n        self._tx_map_container = Container(layout='vertical')\n        self._update_tx_id_choices_button = PushButton(label='Update Treatment ID Choices')\n        self._tx_id = ComboBox(\n            label='Treatment ID',\n            choices=['id'],\n            value=None,\n            nullable=True,\n            tooltip='Usually, the treatment ID is the well ID or a unique identifier for each sample'\n            \"The treatment dict will be looked up against whatever this value is. If it is 'file', then will match against the filename\",\n        )\n        self._tx_n_well = ComboBox(\n            label='Number of Wells',\n            value=None,\n            choices=[6, 12, 24, 48, 96, 384],\n            nullable=True,\n            tooltip='By default, treatments must be verbosely defined for each condition and sample id '\n            'If you have a known plate map, then selecting wells will allow a sparse treatment map to be passed to PlateMapper',\n        )\n        self._tx_dict = TextEdit(label='Treatment Dict', value='{\\n\\n}')\n        # TODO: Add example treatment regex result widget when example id string or id regex dict is changed\n\n        self._tx_map_container.extend(\n            [\n                self._update_tx_id_choices_button,\n                self._tx_id,\n                self._tx_n_well,\n                self._tx_dict,\n            ]\n        )\n\n    def _init_grouping_container(self):\n        \"\"\"Initialize the container for grouping settings.\"\"\"\n        self._grouping_container = Container(layout='vertical')\n\n        self._measured_data_path = FileEdit(\n            label='Measured Data Path',\n            tooltip='Path to the measured data',\n        )\n        self._grouping_cols = Select(\n            label='Grouping Columns',\n            choices=[],\n            allow_multiple=True,\n            tooltip='Select columns to group the data by',\n        )\n        self._count_col = ComboBox(\n            label='Count Column',\n            choices=[],\n            tooltip='Select column that will be counted',\n        )\n        self._agg_cols = Select(\n            label='Aggregation Columns',\n            choices=[],\n            allow_multiple=True,\n            nullable=True,\n            value=None,\n            tooltip='Select columns to aggregate with functions',\n        )\n        self._agg_funcs = Select(\n            label='Aggregation Functions',\n            choices=[\n                'mean', 'median',\n                'std', 'sem',\n                'min', 'max',\n                'sum', 'nunique'\n            ],\n            value=['mean'],\n            allow_multiple=True,\n            tooltip='Select functions performed on aggregation columns',\n        )\n        self._pivot_wider = CheckBox(label='Pivot Wider', value=True)\n        self._group_measurements_button = PushButton(label='Group Measurements')\n\n\n        self._grouping_container.extend([\n            self._measured_data_path,\n            self._grouping_cols,\n            self._count_col,\n            self._agg_cols,\n            self._agg_funcs,\n            self._pivot_wider,\n            self._group_measurements_button,\n        ])\n\n    def _init_layout(self):\n        \"\"\"Initialize the layout of the container.\"\"\"\n        self.extend(\n            [\n                self._label_directory,\n                self._image_directory,\n                self._region_directory,\n                self._output_directory,\n                self._label_images,\n                self._intensity_images,\n                self._scale_tuple,\n                self._measure_button,\n                self._progress_bar,\n            ]\n        )\n\n        tabs = QTabWidget()\n        tabs.addTab(self._props_container.native, 'Region Props')\n        tabs.addTab(self._id_regex_container.native, 'ID Regex')\n        tabs.addTab(self._tx_map_container.native, 'Tx Map')\n        tabs.addTab(self._grouping_container.native, 'Grouping')\n        self.native.layout().addWidget(tabs)\n\n    def _connect_events(self):\n        \"\"\"Connect events to handle user actions.\"\"\"\n        self._image_directory.changed.connect(self._update_image_choices)\n        self._label_directory.changed.connect(self._update_label_choices)\n        self._region_directory.changed.connect(self._update_region_choices)\n        self._update_tx_id_choices_button.clicked.connect(self._update_tx_id_choices)\n        self._measure_button.clicked.connect(self.batch_measure)\n        self._measured_data_path.changed.connect(self._update_grouping_cols)\n        self._group_measurements_button.clicked.connect(self.group_measurements)\n\n    def _update_tx_id_choices(self):\n        \"\"\"Update the choices for treatment ID.\"\"\"\n        id_regex_dict = self._safe_dict_eval(self._id_regex_dict.value)\n        if id_regex_dict is None:\n            return\n        # add the keys to a list which already contains 'id'\n        regex_choices = list(id_regex_dict.keys())\n        self._tx_id.choices = ['id'] + regex_choices\n\n    def _update_grouping_cols(self):\n        \"\"\"Update the columns for grouping.\"\"\"\n        if self._measured_data_path.value is None:\n            return\n\n        df = pd.read_csv(self._measured_data_path.value)\n        self._grouping_cols.choices = df.columns\n        self._count_col.choices = df.columns\n        self._agg_cols.choices = df.columns\n\n        # set default value to label_name and id if exists\n        grouping_cols = []\n        if 'label_name' in df.columns:\n            grouping_cols.append('label_name')\n        if 'id' in df.columns:\n            grouping_cols.append('id')\n        self._grouping_cols.value = grouping_cols\n\n        if 'label' in df.columns:\n            self._count_col.value = 'label'\n\n        return\n\n    def _get_0th_img_from_dir(\n        self, directory: str | None = None\n    ) -&gt; tuple[BioImage, pathlib.Path]:\n        \"\"\"Get the first image from a directory.\"\"\"\n        from napari_ndev import nImage\n\n        _, files = helpers.get_directory_and_files(directory)\n        return nImage(files[0]), files[0]\n\n    def _update_dim_and_scales(self, img):\n        \"\"\"Update the dimensions and scales based on the image.\"\"\"\n        self._squeezed_dims = helpers.get_squeezed_dim_order(img)\n        self._scale_tuple.value = (\n            img.physical_pixel_sizes.Z or 1,\n            img.physical_pixel_sizes.Y or 1,\n            img.physical_pixel_sizes.X or 1,\n        )\n\n    def _update_choices(self, directory, prefix, update_label=False):\n        \"\"\"Update the choices for labels and intensity images.\"\"\"\n        img, _ = self._get_0th_img_from_dir(directory)\n        img_channels = helpers.get_channel_names(img)\n        img_channels = [f'{prefix}: {channel}' for channel in img_channels]\n\n        if update_label:\n            self._update_dim_and_scales(img)\n            self._label_choices.extend(img_channels)\n            self._label_images.choices = self._label_choices\n\n        self._intensity_choices.extend(img_channels)\n        self._intensity_images.choices = self._intensity_choices\n\n    def _update_image_choices(self):\n        \"\"\"Update the choices for intensity images.\"\"\"\n        self._update_choices(self._image_directory.value, 'Intensity')\n\n    def _update_label_choices(self):\n        \"\"\"Update the choices for label images.\"\"\"\n        self._update_choices(\n            self._label_directory.value, 'Labels', update_label=True\n        )\n        img, file_id = self._get_0th_img_from_dir(self._label_directory.value)\n        id_string = helpers.create_id_string(img, file_id.stem)\n        self._example_id_string.value = id_string\n\n    def _update_region_choices(self):\n        \"\"\"Update the choices for region images.\"\"\"\n        self._update_choices(self._region_directory.value, 'Region')\n\n    def _safe_dict_eval(self, dict_string, dict_name=None):\n        \"\"\"Safely evaluate a string as a dictionary.\"\"\"\n        if dict_string is None:\n            return None\n\n        stripped_string = dict_string.strip()\n        if stripped_string == '{}' or not stripped_string:\n            return None\n        try:\n            return ast.literal_eval(stripped_string)\n        except (ValueError, SyntaxError):\n            return None\n\n    def batch_measure(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Perform batch measurement of labels and intensity images.\n\n        Use scikit-image's regionprops to measure properties of labels and\n        intensity images. The measurements are saved to a CSV file in the\n        output directory.\n\n        Returns\n        -------\n        pd.DataFrame\n            The measurement results as a DataFrame.\n\n        \"\"\"\n        from napari_ndev import measure as ndev_measure, nImage\n\n        # get all the files in the label directory\n        label_dir, label_files = helpers.get_directory_and_files(\n            self._label_directory.value\n        )\n        image_dir, image_files = helpers.get_directory_and_files(\n            self._image_directory.value\n        )\n        region_dir, region_files = helpers.get_directory_and_files(\n            self._region_directory.value\n        )\n\n        log_loc = self._output_directory.value / 'measure.log.txt'\n        logger, handler = helpers.setup_logger(log_loc)\n\n        logger.info(\n            \"\"\"\n            Label Images: %s\n            Intensity Channels: %s\n            Num. Files: %d\n            Label Directory: %s\n            Image Directory: %s\n            Region Directory: %s\n            Output Directory: %s\n            ID Example: %s\n            ID Regex Dict: %s\n            Tx ID: %s\n            Tx N Well: %s\n            Tx Dict: %s\n            \"\"\",\n            self._label_images.value,\n            self._intensity_images.value,\n            len(label_files),\n            label_dir,\n            image_dir,\n            region_dir,\n            self._output_directory.value,\n            self._example_id_string.value,\n            self._id_regex_dict.value,\n            self._tx_id.value,\n            self._tx_n_well.value,\n            self._tx_dict.value,\n        )\n\n        # check if the label files are the same as the image files\n        if self._image_directory.value is not None and len(label_files) != len(image_files):\n            logger.error(\n                'Number of label files (%s) and image files (%s) do not match',\n                len(label_files), len(image_files),\n            )\n        if self._region_directory.value is not None and len(label_files) != len(region_files):\n            logger.error(\n                'Number of label files (%s) and region files (%s) do not match',\n                len(label_files), len(region_files),\n            )\n\n        self._progress_bar.label = f'Measuring {len(label_files)} Images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(label_files)\n        # get the relevant spacing for regionprops, depending on length\n        props_scale = self._scale_tuple.value\n        props_scale = props_scale[-len(self._squeezed_dims) :]\n        # get the properties list\n        properties = [\n            prop.label for prop in self._props_container if prop.value\n        ]\n\n        id_regex_dict = self._safe_dict_eval(\n            self._id_regex_dict.value, 'ID Regex Dict'\n        )\n        tx_dict = self._safe_dict_eval(self._tx_dict.value, 'Tx Dict')\n        measure_props_concat = []\n\n        for idx, file in enumerate(label_files):\n            # TODO: Add scene processing\n            logger.info('Processing file %s', file.name)\n            lbl = nImage(label_dir / file.name)\n            id_string = helpers.create_id_string(lbl, file.stem)\n\n            # get the itnensity image only if the image directory is not empty\n            if self._image_directory.value:\n                image_path = image_dir / file.name\n                if not image_path.exists():\n                    logger.error(\n                        'Image file %s not found in intensity directory',\n                        file.name,\n                    )\n                    self._progress_bar.value = idx + 1\n                    continue\n                img = nImage(image_path)\n            if self._region_directory.value:\n                region_path = region_dir / file.name\n                if not region_path.exists():\n                    logger.error(\n                        'Region file %s not found in region directory',\n                        file.name,\n                    )\n                    self._progress_bar.value = idx + 1\n                    continue\n                reg = nImage(region_path)\n\n            for scene_idx, scene in enumerate(lbl.scenes):\n                logger.info('Processing scene: %s :: %s', scene_idx, scene)\n                lbl.set_scene(scene_idx)\n\n                label_images = []\n                label_names = []\n\n                # iterate through each channel in the label image\n                for label_chan in self._label_images.value:\n                    label_chan = label_chan[8:]\n                    label_names.append(label_chan)\n\n                    lbl_C = lbl.channel_names.index(label_chan)\n                    label = lbl.get_image_data(self._squeezed_dims, C=lbl_C)\n                    label_images.append(label)\n\n                intensity_images = []\n                intensity_names = []\n\n                # id_string = helpers.create_id_string(lbl, file.stem)\n\n                # Get stack of intensity images if there are any selected\n                if self._intensity_images.value and not None:\n                    for channel in self._intensity_images.value:\n                        if channel.startswith('Labels: '):\n                            chan = channel[8:]\n                            lbl_C = lbl.channel_names.index(chan)\n                            lbl.set_scene(scene_idx)\n                            inten_img = lbl.get_image_data(\n                                self._squeezed_dims, C=lbl_C\n                            )\n                        elif channel.startswith('Intensity: '):\n                            chan = channel[11:]\n                            img_C = img.channel_names.index(chan)\n                            img.set_scene(scene_idx)\n                            inten_img = img.get_image_data(\n                                self._squeezed_dims, C=img_C\n                            )\n                        elif channel.startswith('Region: '):\n                            chan = channel[8:]\n                            reg_C = reg.channel_names.index(chan)\n                            reg.set_scene(scene_idx)\n                            inten_img = reg.get_image_data(\n                                self._squeezed_dims, C=reg_C\n                            )\n                        intensity_names.append(chan)\n                        intensity_images.append(inten_img)\n\n                    # the last dim is the multi-channel dim for regionprops\n                    intensity_stack = np.stack(intensity_images, axis=-1)\n\n                else:\n                    intensity_stack = None\n                    intensity_names = None\n\n                # start the measuring here\n                # TODO: Add optional scaling, in case images have different scales?\n                measure_props_df = ndev_measure.measure_regionprops(\n                    label_images=label_images,\n                    label_names=label_names,\n                    intensity_images=intensity_stack,\n                    intensity_names=intensity_names,\n                    properties=properties,\n                    scale=props_scale,\n                    id_string=id_string,\n                    id_regex_dict=id_regex_dict,\n                    tx_id=self._tx_id.value,\n                    tx_dict=tx_dict,\n                    tx_n_well=self._tx_n_well.value,\n                    save_data_path=None,\n                )\n\n                measure_props_concat.append(measure_props_df)\n                self._progress_bar.value = idx + 1\n\n        measure_props_df = pd.concat(measure_props_concat)\n        labels_string = '_'.join(label_names)\n        save_loc = self._output_directory.value / f'measure_props_{labels_string}.csv'\n        measure_props_df.to_csv(save_loc, index=False)\n\n        logger.removeHandler(handler)\n\n        return measure_props_df\n\n    def group_measurements(self):\n        \"\"\"\n        Group measurements based on user input.\n\n        Uses the values in the Grouping Container of the Widget and passes them\n        to the group_and_agg_measurements function in the measure module. The\n        grouped measurements are saved to a CSV file in the same directory as\n        the measured data with '_grouped' appended.\n\n        Returns\n        -------\n        pd.DataFrame\n            The grouped measurements as a DataFrame.\n\n        \"\"\"\n        from napari_ndev import measure as ndev_measure\n\n        self._progress_bar.label = 'Grouping Measurements'\n        self._progress_bar.value = 0\n        self._progress_bar.max = 1\n\n        df = pd.read_csv(self._measured_data_path.value)\n\n        # Filter out None values from agg_cols\n        agg_cols = [col for col in self._agg_cols.value if col is not None]\n\n        grouped_df = ndev_measure.group_and_agg_measurements(\n            df=df,\n            grouping_cols=self._grouping_cols.value,\n            count_col=self._count_col.value,\n            agg_cols=agg_cols,\n            agg_funcs=self._agg_funcs.value,\n        )\n        # use the label_name column to make the dataframe wider\n        if self._pivot_wider.value:\n            # get grouping calls without label name\n            index_cols = [col for col in self._grouping_cols.value if col != 'label_name']\n\n            # alternatively, pivot every values column that is not present in index or columns\n            value_cols = [col for col in grouped_df.columns if col not in self._grouping_cols.value]\n\n            pivot_df = grouped_df.pivot(\n                index=index_cols,\n                columns='label_name',\n                values=value_cols,\n            )\n            # # flatten the multiindex columns\n            # pivot_df.columns = [f'{col[1]}_{col[0]}' for col in pivot_df.columns]\n\n            # reset index so that it is saved in the csv\n            pivot_df.reset_index(inplace=True)\n\n            grouped_df = pivot_df\n\n        save_loc = (\n            self._measured_data_path.value.parent /\n            f'{self._measured_data_path.value.stem}_grouped.csv'\n        )\n        grouped_df.to_csv(save_loc, index=False)\n\n        self._progress_bar.value = 1\n        return grouped_df\n</code></pre>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance. Optional.</p>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.__init__","title":"__init__","text":"<pre><code>__init__(viewer=None)\n</code></pre> <p>Initialize the MeasureContainer.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>def __init__(\n    self,\n    viewer: napari.viewer.Viewer = None,\n):\n    \"\"\"\n    Initialize the MeasureContainer.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance. Optional.\n\n    \"\"\"\n    super().__init__()\n\n    self.viewer = viewer if viewer is not None else None\n    self._label_choices = []\n    self._intensity_choices = []\n    self._p_sizes = None\n    self._squeezed_dims = None\n    self._prop = type('', (), {})()\n\n    self._init_widgets()\n    self._init_regionprops_container()\n    self._init_id_regex_container()\n    self._init_tx_map_container()\n    self._init_grouping_container()\n    self._init_layout()\n    self._connect_events()\n</code></pre>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.__init__(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance. Optional.</p>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.batch_measure","title":"batch_measure","text":"<pre><code>batch_measure()\n</code></pre> <p>Perform batch measurement of labels and intensity images.</p> <p>Use scikit-image's regionprops to measure properties of labels and intensity images. The measurements are saved to a CSV file in the output directory.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The measurement results as a DataFrame.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>def batch_measure(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Perform batch measurement of labels and intensity images.\n\n    Use scikit-image's regionprops to measure properties of labels and\n    intensity images. The measurements are saved to a CSV file in the\n    output directory.\n\n    Returns\n    -------\n    pd.DataFrame\n        The measurement results as a DataFrame.\n\n    \"\"\"\n    from napari_ndev import measure as ndev_measure, nImage\n\n    # get all the files in the label directory\n    label_dir, label_files = helpers.get_directory_and_files(\n        self._label_directory.value\n    )\n    image_dir, image_files = helpers.get_directory_and_files(\n        self._image_directory.value\n    )\n    region_dir, region_files = helpers.get_directory_and_files(\n        self._region_directory.value\n    )\n\n    log_loc = self._output_directory.value / 'measure.log.txt'\n    logger, handler = helpers.setup_logger(log_loc)\n\n    logger.info(\n        \"\"\"\n        Label Images: %s\n        Intensity Channels: %s\n        Num. Files: %d\n        Label Directory: %s\n        Image Directory: %s\n        Region Directory: %s\n        Output Directory: %s\n        ID Example: %s\n        ID Regex Dict: %s\n        Tx ID: %s\n        Tx N Well: %s\n        Tx Dict: %s\n        \"\"\",\n        self._label_images.value,\n        self._intensity_images.value,\n        len(label_files),\n        label_dir,\n        image_dir,\n        region_dir,\n        self._output_directory.value,\n        self._example_id_string.value,\n        self._id_regex_dict.value,\n        self._tx_id.value,\n        self._tx_n_well.value,\n        self._tx_dict.value,\n    )\n\n    # check if the label files are the same as the image files\n    if self._image_directory.value is not None and len(label_files) != len(image_files):\n        logger.error(\n            'Number of label files (%s) and image files (%s) do not match',\n            len(label_files), len(image_files),\n        )\n    if self._region_directory.value is not None and len(label_files) != len(region_files):\n        logger.error(\n            'Number of label files (%s) and region files (%s) do not match',\n            len(label_files), len(region_files),\n        )\n\n    self._progress_bar.label = f'Measuring {len(label_files)} Images'\n    self._progress_bar.value = 0\n    self._progress_bar.max = len(label_files)\n    # get the relevant spacing for regionprops, depending on length\n    props_scale = self._scale_tuple.value\n    props_scale = props_scale[-len(self._squeezed_dims) :]\n    # get the properties list\n    properties = [\n        prop.label for prop in self._props_container if prop.value\n    ]\n\n    id_regex_dict = self._safe_dict_eval(\n        self._id_regex_dict.value, 'ID Regex Dict'\n    )\n    tx_dict = self._safe_dict_eval(self._tx_dict.value, 'Tx Dict')\n    measure_props_concat = []\n\n    for idx, file in enumerate(label_files):\n        # TODO: Add scene processing\n        logger.info('Processing file %s', file.name)\n        lbl = nImage(label_dir / file.name)\n        id_string = helpers.create_id_string(lbl, file.stem)\n\n        # get the itnensity image only if the image directory is not empty\n        if self._image_directory.value:\n            image_path = image_dir / file.name\n            if not image_path.exists():\n                logger.error(\n                    'Image file %s not found in intensity directory',\n                    file.name,\n                )\n                self._progress_bar.value = idx + 1\n                continue\n            img = nImage(image_path)\n        if self._region_directory.value:\n            region_path = region_dir / file.name\n            if not region_path.exists():\n                logger.error(\n                    'Region file %s not found in region directory',\n                    file.name,\n                )\n                self._progress_bar.value = idx + 1\n                continue\n            reg = nImage(region_path)\n\n        for scene_idx, scene in enumerate(lbl.scenes):\n            logger.info('Processing scene: %s :: %s', scene_idx, scene)\n            lbl.set_scene(scene_idx)\n\n            label_images = []\n            label_names = []\n\n            # iterate through each channel in the label image\n            for label_chan in self._label_images.value:\n                label_chan = label_chan[8:]\n                label_names.append(label_chan)\n\n                lbl_C = lbl.channel_names.index(label_chan)\n                label = lbl.get_image_data(self._squeezed_dims, C=lbl_C)\n                label_images.append(label)\n\n            intensity_images = []\n            intensity_names = []\n\n            # id_string = helpers.create_id_string(lbl, file.stem)\n\n            # Get stack of intensity images if there are any selected\n            if self._intensity_images.value and not None:\n                for channel in self._intensity_images.value:\n                    if channel.startswith('Labels: '):\n                        chan = channel[8:]\n                        lbl_C = lbl.channel_names.index(chan)\n                        lbl.set_scene(scene_idx)\n                        inten_img = lbl.get_image_data(\n                            self._squeezed_dims, C=lbl_C\n                        )\n                    elif channel.startswith('Intensity: '):\n                        chan = channel[11:]\n                        img_C = img.channel_names.index(chan)\n                        img.set_scene(scene_idx)\n                        inten_img = img.get_image_data(\n                            self._squeezed_dims, C=img_C\n                        )\n                    elif channel.startswith('Region: '):\n                        chan = channel[8:]\n                        reg_C = reg.channel_names.index(chan)\n                        reg.set_scene(scene_idx)\n                        inten_img = reg.get_image_data(\n                            self._squeezed_dims, C=reg_C\n                        )\n                    intensity_names.append(chan)\n                    intensity_images.append(inten_img)\n\n                # the last dim is the multi-channel dim for regionprops\n                intensity_stack = np.stack(intensity_images, axis=-1)\n\n            else:\n                intensity_stack = None\n                intensity_names = None\n\n            # start the measuring here\n            # TODO: Add optional scaling, in case images have different scales?\n            measure_props_df = ndev_measure.measure_regionprops(\n                label_images=label_images,\n                label_names=label_names,\n                intensity_images=intensity_stack,\n                intensity_names=intensity_names,\n                properties=properties,\n                scale=props_scale,\n                id_string=id_string,\n                id_regex_dict=id_regex_dict,\n                tx_id=self._tx_id.value,\n                tx_dict=tx_dict,\n                tx_n_well=self._tx_n_well.value,\n                save_data_path=None,\n            )\n\n            measure_props_concat.append(measure_props_df)\n            self._progress_bar.value = idx + 1\n\n    measure_props_df = pd.concat(measure_props_concat)\n    labels_string = '_'.join(label_names)\n    save_loc = self._output_directory.value / f'measure_props_{labels_string}.csv'\n    measure_props_df.to_csv(save_loc, index=False)\n\n    logger.removeHandler(handler)\n\n    return measure_props_df\n</code></pre>"},{"location":"api/widgets/measure_widget/#napari_ndev.widgets._measure_container.MeasureContainer.group_measurements","title":"group_measurements","text":"<pre><code>group_measurements()\n</code></pre> <p>Group measurements based on user input.</p> <p>Uses the values in the Grouping Container of the Widget and passes them to the group_and_agg_measurements function in the measure module. The grouped measurements are saved to a CSV file in the same directory as the measured data with '_grouped' appended.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>The grouped measurements as a DataFrame.</p> </li> </ul> Source code in <code>src/napari_ndev/widgets/_measure_container.py</code> <pre><code>def group_measurements(self):\n    \"\"\"\n    Group measurements based on user input.\n\n    Uses the values in the Grouping Container of the Widget and passes them\n    to the group_and_agg_measurements function in the measure module. The\n    grouped measurements are saved to a CSV file in the same directory as\n    the measured data with '_grouped' appended.\n\n    Returns\n    -------\n    pd.DataFrame\n        The grouped measurements as a DataFrame.\n\n    \"\"\"\n    from napari_ndev import measure as ndev_measure\n\n    self._progress_bar.label = 'Grouping Measurements'\n    self._progress_bar.value = 0\n    self._progress_bar.max = 1\n\n    df = pd.read_csv(self._measured_data_path.value)\n\n    # Filter out None values from agg_cols\n    agg_cols = [col for col in self._agg_cols.value if col is not None]\n\n    grouped_df = ndev_measure.group_and_agg_measurements(\n        df=df,\n        grouping_cols=self._grouping_cols.value,\n        count_col=self._count_col.value,\n        agg_cols=agg_cols,\n        agg_funcs=self._agg_funcs.value,\n    )\n    # use the label_name column to make the dataframe wider\n    if self._pivot_wider.value:\n        # get grouping calls without label name\n        index_cols = [col for col in self._grouping_cols.value if col != 'label_name']\n\n        # alternatively, pivot every values column that is not present in index or columns\n        value_cols = [col for col in grouped_df.columns if col not in self._grouping_cols.value]\n\n        pivot_df = grouped_df.pivot(\n            index=index_cols,\n            columns='label_name',\n            values=value_cols,\n        )\n        # # flatten the multiindex columns\n        # pivot_df.columns = [f'{col[1]}_{col[0]}' for col in pivot_df.columns]\n\n        # reset index so that it is saved in the csv\n        pivot_df.reset_index(inplace=True)\n\n        grouped_df = pivot_df\n\n    save_loc = (\n        self._measured_data_path.value.parent /\n        f'{self._measured_data_path.value.stem}_grouped.csv'\n    )\n    grouped_df.to_csv(save_loc, index=False)\n\n    self._progress_bar.value = 1\n    return grouped_df\n</code></pre>"},{"location":"api/widgets/napari_reader/","title":"Napari reader","text":""},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader","title":"napari_ndev._napari_reader","text":""},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_get_reader","title":"napari_get_reader","text":"<pre><code>napari_get_reader(path, in_memory=None, open_first_scene_only=False)\n</code></pre> <p>Get the appropriate reader function for a single given path.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>ReaderFunction</code>           \u2013            <p>The reader function for the given path</p> </li> </ul> Source code in <code>src/napari_ndev/_napari_reader.py</code> <pre><code>def napari_get_reader(\n    path: PathLike,\n    in_memory: bool | None = None,\n    open_first_scene_only: bool = False,\n) -&gt; ReaderFunction | None:\n    \"\"\"\n    Get the appropriate reader function for a single given path.\n\n    Parameters\n    ----------\n    path : PathLike\n        Path to the file to be read\n    in_memory : bool, optional\n        Whether to read the file in memory, by default None\n    open_first_scene_only : bool, optional\n        Whether to ignore multi-scene files and just open the first scene,\n        by default False\n\n\n    Returns\n    -------\n    ReaderFunction\n        The reader function for the given path\n\n    \"\"\"\n    if isinstance(path, list):\n        logger.info(\"Bioio: Expected a single path, got a list of paths.\")\n        return None\n\n    try:\n        # TODO: Test this if else functionality.\n        from bioio import plugin_feasibility_report as pfr\n        fr = pfr(path)\n        if 'bioio-ome-tiff' in fr and fr['bioio-ome-tiff'].supported:\n            import bioio_ome_tiff\n            reader = bioio_ome_tiff.Reader\n        else:\n            plugin = nImage.determine_plugin(path)\n            reader = plugin.metadata.get_reader()\n        # return napari_reader_function(path, reader, in_memory)\n        return partial(\n            napari_reader_function,\n            reader=reader,\n            in_memory=in_memory,\n            open_first_scene_only=open_first_scene_only\n        )\n    except UnsupportedFileFormatError:\n        logger.warning(\"Bioio: Unsupported file format\")\n        return None\n    except Exception as e:  # noqa: BLE001\n        logger.warning(\"Bioio: Error reading file\")\n        logger.warning(e)\n        return None\n</code></pre>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_get_reader(path)","title":"<code>path</code>","text":"(<code>PathLike</code>)           \u2013            <p>Path to the file to be read</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_get_reader(in_memory)","title":"<code>in_memory</code>","text":"(<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>Whether to read the file in memory, by default None</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_get_reader(open_first_scene_only)","title":"<code>open_first_scene_only</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to ignore multi-scene files and just open the first scene, by default False</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_reader_function","title":"napari_reader_function","text":"<pre><code>napari_reader_function(\n    path,\n    reader,\n    in_memory=None,\n    open_first_scene_only=False,\n    layer_type=\"image\",\n)\n</code></pre> <p>Read a file using the given reader function.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>List containing image data, metadata, and layer type</p> </li> </ul> Source code in <code>src/napari_ndev/_napari_reader.py</code> <pre><code>def napari_reader_function(\n    path: PathLike,\n    reader: Callable,\n    in_memory: bool | None = None,\n    open_first_scene_only: bool = False,\n    layer_type: str = 'image'\n) -&gt; list[LayerData] | None:\n    \"\"\"\n    Read a file using the given reader function.\n\n    Parameters\n    ----------\n    path : PathLike\n        Path to the file to be read\n    reader : None\n        Bioio Reader function to be used to read the file, by default None.\n    in_memory : bool, optional\n        Whether to read the file in memory, by default None.\n    layer_type : str, optional\n        Type of layer to be created in napari, by default 'image'.\n    open_first_scene_only : bool, optional\n        Whether to ignore multi-scene files and just open the first scene,\n        by default False.\n\n    Returns\n    -------\n    list\n        List containing image data, metadata, and layer type\n\n    \"\"\"\n    if isinstance(path, list):\n        logger.info(\"Bioio: Expected a single path, got a list of paths.\")\n        return None\n\n    img = nImage(path, reader=reader)\n    in_memory = img._determine_in_memory(path) if in_memory is None else in_memory\n    logger.info('Bioio: Reading in-memory: %s', in_memory)\n\n    if len(img.scenes) &gt; 1 and not open_first_scene_only:\n        _get_scenes(path=path, img=img, in_memory=in_memory)\n        return [(None,)]\n\n    # TODO: why should I return the squeezed data and not the full data\n    # is it because napari squeezes it anyway?\n    img_data = img.get_napari_image_data(in_memory=in_memory)\n    img_meta = img.get_napari_metadata(path)\n\n    return [(img_data.data, img_meta, layer_type)]\n</code></pre>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_reader_function(path)","title":"<code>path</code>","text":"(<code>PathLike</code>)           \u2013            <p>Path to the file to be read</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_reader_function(reader)","title":"<code>reader</code>","text":"(<code>None</code>)           \u2013            <p>Bioio Reader function to be used to read the file, by default None.</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_reader_function(in_memory)","title":"<code>in_memory</code>","text":"(<code>bool</code>, default:                   <code>None</code> )           \u2013            <p>Whether to read the file in memory, by default None.</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_reader_function(layer_type)","title":"<code>layer_type</code>","text":"(<code>str</code>, default:                   <code>'image'</code> )           \u2013            <p>Type of layer to be created in napari, by default 'image'.</p>"},{"location":"api/widgets/napari_reader/#napari_ndev._napari_reader.napari_reader_function(open_first_scene_only)","title":"<code>open_first_scene_only</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to ignore multi-scene files and just open the first scene, by default False.</p>"},{"location":"api/widgets/workflow_widget/","title":"Workflow widget","text":""},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container","title":"napari_ndev.widgets._workflow_container","text":""},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer","title":"WorkflowContainer","text":"<p>               Bases: <code>Container</code></p> <p>Container class for managing the workflow functionality in napari-ndev.</p> <p>Parameters:</p> <p>Attributes:</p> <ul> <li> <code>viewer</code>               (<code>Viewer</code>)           \u2013            <p>The napari viewer instance.</p> </li> <li> <code>roots</code>               (<code>list</code>)           \u2013            <p>List of ComboBox widgets representing the workflow roots.</p> </li> <li> <code>_channel_names</code>               (<code>list</code>)           \u2013            <p>List of channel names extracted from the image data.</p> </li> <li> <code>_img_dims</code>               (<code>str</code>)           \u2013            <p>The dimensions of the image data.</p> </li> </ul> Widgets: <p>image_directory : FileEdit     Widget for selecting the image directory. result_directory : FileEdit     Widget for selecting the result directory. workflow_file : FileEdit     Widget for selecting the workflow file. _keep_original_images : CheckBox     Checkbox widget for specifying whether to keep original images. batch_button : PushButton     Button widget for triggering the batch workflow. _progress_bar : ProgressBar     Progress bar widget for displaying the progress of the workflow. _workflow_roots : Label     Label widget for displaying the workflow roots.</p> Events: <p>image_directory.changed : Signal     Signal emitted when the image directory is changed. workflow_file.changed : Signal     Signal emitted when the workflow file is changed. batch_button.clicked : Signal     Signal emitted when the batch button is clicked.</p> Source code in <code>src/napari_ndev/widgets/_workflow_container.py</code> <pre><code>class WorkflowContainer(Container):\n    \"\"\"\n    Container class for managing the workflow functionality in napari-ndev.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n\n    Attributes\n    ----------\n    viewer : napari.viewer.Viewer\n        The napari viewer instance.\n    roots : list\n        List of ComboBox widgets representing the workflow roots.\n    _channel_names : list\n        List of channel names extracted from the image data.\n    _img_dims : str\n        The dimensions of the image data.\n\n    Widgets:\n    --------\n    image_directory : FileEdit\n        Widget for selecting the image directory.\n    result_directory : FileEdit\n        Widget for selecting the result directory.\n    workflow_file : FileEdit\n        Widget for selecting the workflow file.\n    _keep_original_images : CheckBox\n        Checkbox widget for specifying whether to keep original images.\n    batch_button : PushButton\n        Button widget for triggering the batch workflow.\n    _progress_bar : ProgressBar\n        Progress bar widget for displaying the progress of the workflow.\n    _workflow_roots : Label\n        Label widget for displaying the workflow roots.\n\n    Events:\n    -------\n    image_directory.changed : Signal\n        Signal emitted when the image directory is changed.\n    workflow_file.changed : Signal\n        Signal emitted when the workflow file is changed.\n    batch_button.clicked : Signal\n        Signal emitted when the batch button is clicked.\n\n    \"\"\"\n\n    def __init__(self, viewer: napari.viewer.Viewer = None):\n        \"\"\"\n        Initialize the WorkflowContainer widget.\n\n        Parameters\n        ----------\n        viewer : napari.viewer.Viewer, optional\n            The napari viewer instance.\n\n        \"\"\"\n        super().__init__()\n        self.viewer = viewer if viewer is not None else None\n        self.roots = []\n        self._channel_names = []\n        self._img_dims = ''\n\n        self._init_widgets()\n        self._roots_container()\n        self._tasks_container()\n        self._init_layout()\n        self._connect_events()\n\n    def _init_widgets(self):\n        \"\"\"Initialize non-Container widgets.\"\"\"\n        self.image_directory = FileEdit(label='Image Directory', mode='d')\n        self.result_directory = FileEdit(label='Result Directory', mode='d')\n\n        self.workflow_file = FileEdit(\n            label='Workflow File',\n            filter='*.yaml',\n            tooltip='Select a workflow file to load',\n        )\n        self._keep_original_images = CheckBox(\n            label='Keep Original Images',\n            value=False,\n            tooltip='If checked, the original images will be '\n            'concatenated with the results',\n        )\n        self.batch_button = PushButton(label='Batch Workflow')\n\n        self._progress_bar = ProgressBar(label='Progress:')\n        self._workflow_roots = Label(label='Workflow Roots:')\n\n    def _roots_container(self):\n        \"\"\"Initialize the roots container.\"\"\"\n        self._roots_container = Container(layout='vertical')\n        # TODO: Qt AlignTop\n        self._roots_container.native.layout().addStretch() # this resets the additions to the top of the container (the name is confusing)\n\n    def _tasks_container(self):\n        \"\"\"Initialize the tasks container.\"\"\"\n        self._tasks_select = Select(\n            choices=[],\n            nullable=False,\n            allow_multiple=True,\n        )\n        self._tasks_container = Container(\n            layout='vertical',\n            widgets=[self._tasks_select],\n        )\n\n    def _init_layout(self):\n        \"\"\"Initialize the layout of the widgets.\"\"\"\n        self.extend(\n            [\n                self.image_directory,\n                self.result_directory,\n                self.workflow_file,\n                self._keep_original_images,\n                self.batch_button,\n                self._progress_bar,\n                self._workflow_roots,\n            ]\n        )\n\n        tabs = QTabWidget()\n        tabs.addTab(self._roots_container.native, 'Roots')\n        tabs.addTab(self._tasks_container.native, 'Tasks')\n        self.native.layout().addWidget(tabs)\n\n    def _connect_events(self):\n        \"\"\"Connect the events of the widgets to respective methods.\"\"\"\n        self.image_directory.changed.connect(self._get_image_info)\n        self.workflow_file.changed.connect(self._get_workflow_info)\n        self.batch_button.clicked.connect(self.batch_workflow)\n\n    def _get_image_info(self):\n        \"\"\"Get channels and dims from first image in the directory.\"\"\"\n        self.image_dir, self.image_files = helpers.get_directory_and_files(\n            self.image_directory.value,\n        )\n        img = nImage(self.image_files[0])\n\n        self._channel_names = helpers.get_channel_names(img)\n\n        for widget in self._roots_container:\n            widget.choices = self._channel_names\n\n        self._squeezed_img_dims = helpers.get_squeezed_dim_order(img)\n        return self._squeezed_img_dims\n\n    def _update_roots(self):\n        \"\"\"Get the roots from the workflow and update the ComboBox widgets.\"\"\"\n        self._roots_container.clear()\n\n        for idx, root in enumerate(self.workflow.roots()):\n            root_combo = ComboBox(\n                label=f'Root {idx}: {root}',\n                choices=self._channel_names,\n                nullable=True,\n                value=None,\n            )\n            self._roots_container.append(root_combo)\n            # self.append(root_combo)\n        return\n\n    def _update_task_choices(self, workflow):\n        \"\"\"Update the choices of the tasks with the workflow tasks.\"\"\"\n        self._tasks_select.choices = list(workflow._tasks.keys())\n        self._tasks_select.value = workflow.leafs()\n\n    def _get_workflow_info(self):\n        \"\"\"Load the workflow file and update the roots and leafs.\"\"\"\n        from napari_workflows._io_yaml_v1 import load_workflow\n\n        self.workflow = load_workflow(self.workflow_file.value)\n        self._workflow_roots.value = self.workflow.roots()\n        self._update_roots()\n        self._update_task_choices(self.workflow)\n        return\n\n    def batch_workflow(self):\n        \"\"\"Run the workflow on all images in the image directory.\"\"\"\n        import dask.array as da\n        from bioio.writers import OmeTiffWriter\n        from bioio_base import transforms\n\n        result_dir = self.result_directory.value\n        image_files = self.image_files\n        workflow = self.workflow\n\n        # get indexes of channel names, in case not all images have\n        # the same channel names, the index should be in the same order\n        root_list = [widget.value for widget in self._roots_container]\n        root_index_list = [self._channel_names.index(r) for r in root_list]\n\n        # Setting up Logging File\n        log_loc = result_dir / 'workflow.log.txt'\n        logger, handler = helpers.setup_logger(log_loc)\n        logger.info(\n            \"\"\"\n            Image Directory: %s\n            Result Directory: %s\n            Workflow File: %s\n            Roots: %s\n            Tasks: %s\n            \"\"\",\n            self.image_directory.value,\n            result_dir,\n            self.workflow_file.value,\n            root_list,\n            self._tasks_select.value,\n        )\n\n        self._progress_bar.label = f'Workflow on {len(image_files)} images'\n        self._progress_bar.value = 0\n        self._progress_bar.max = len(image_files)\n\n        for idx_file, image_file in enumerate(image_files):\n            logger.info('Processing %d: %s', idx_file + 1, image_file.name)\n            img = nImage(image_file)\n\n            root_stack = []\n            # get image corresponding to each root, and set it to the workflow\n            for idx, root_index in enumerate(root_index_list):\n                if 'S' in img.dims.order:\n                    root_img = img.get_image_data('TSZYX', S=root_index)\n                else:\n                    root_img = img.get_image_data('TCZYX', C=root_index)\n                # stack the TCZYX images for later stacking with results\n                root_stack.append(root_img)\n                # squeeze the root image for workflow\n                root_squeeze = np.squeeze(root_img)\n                # set the root image to the index of the root in the workflow\n                workflow.set(\n                    name=workflow.roots()[idx], func_or_data=root_squeeze\n                )\n\n            task_names = self._tasks_select.value\n            result = workflow.get(name=task_names)\n\n            result_stack = np.asarray(\n                result\n            )  # cle.pull stacks the results on the 0th axis as \"C\"\n            # transform result_stack to TCZYX\n            result_stack = transforms.reshape_data(\n                data=result_stack,\n                given_dims='C' + self._squeezed_img_dims,\n                return_dims='TCZYX',\n            )\n\n            if result_stack.dtype == np.int64:\n                result_stack = result_stack.astype(np.int32)\n\n            # &lt;- should I add a check for the result_stack to be a dask array?\n            # &lt;- should this be done using dask or numpy?\n            if self._keep_original_images.value:\n                dask_images = da.concatenate(root_stack, axis=1)  # along \"C\"\n                result_stack = da.concatenate(\n                    [dask_images, result_stack], axis=1\n                )\n                result_names = root_list + task_names\n            else:\n                result_names = task_names\n\n            OmeTiffWriter.save(\n                data=result_stack,\n                uri=result_dir / (image_file.stem + '.tiff'),\n                dim_order='TCZYX',\n                channel_names=result_names,\n                image_name=image_file.stem,\n                physical_pixel_sizes=img.physical_pixel_sizes,\n            )\n\n            self._progress_bar.value = idx_file + 1\n\n        logger.removeHandler(handler)\n        return\n</code></pre>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer.__init__","title":"__init__","text":"<pre><code>__init__(viewer=None)\n</code></pre> <p>Initialize the WorkflowContainer widget.</p> <p>Parameters:</p> Source code in <code>src/napari_ndev/widgets/_workflow_container.py</code> <pre><code>def __init__(self, viewer: napari.viewer.Viewer = None):\n    \"\"\"\n    Initialize the WorkflowContainer widget.\n\n    Parameters\n    ----------\n    viewer : napari.viewer.Viewer, optional\n        The napari viewer instance.\n\n    \"\"\"\n    super().__init__()\n    self.viewer = viewer if viewer is not None else None\n    self.roots = []\n    self._channel_names = []\n    self._img_dims = ''\n\n    self._init_widgets()\n    self._roots_container()\n    self._tasks_container()\n    self._init_layout()\n    self._connect_events()\n</code></pre>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer.__init__(viewer)","title":"<code>viewer</code>","text":"(<code>Viewer</code>, default:                   <code>None</code> )           \u2013            <p>The napari viewer instance.</p>"},{"location":"api/widgets/workflow_widget/#napari_ndev.widgets._workflow_container.WorkflowContainer.batch_workflow","title":"batch_workflow","text":"<pre><code>batch_workflow()\n</code></pre> <p>Run the workflow on all images in the image directory.</p> Source code in <code>src/napari_ndev/widgets/_workflow_container.py</code> <pre><code>def batch_workflow(self):\n    \"\"\"Run the workflow on all images in the image directory.\"\"\"\n    import dask.array as da\n    from bioio.writers import OmeTiffWriter\n    from bioio_base import transforms\n\n    result_dir = self.result_directory.value\n    image_files = self.image_files\n    workflow = self.workflow\n\n    # get indexes of channel names, in case not all images have\n    # the same channel names, the index should be in the same order\n    root_list = [widget.value for widget in self._roots_container]\n    root_index_list = [self._channel_names.index(r) for r in root_list]\n\n    # Setting up Logging File\n    log_loc = result_dir / 'workflow.log.txt'\n    logger, handler = helpers.setup_logger(log_loc)\n    logger.info(\n        \"\"\"\n        Image Directory: %s\n        Result Directory: %s\n        Workflow File: %s\n        Roots: %s\n        Tasks: %s\n        \"\"\",\n        self.image_directory.value,\n        result_dir,\n        self.workflow_file.value,\n        root_list,\n        self._tasks_select.value,\n    )\n\n    self._progress_bar.label = f'Workflow on {len(image_files)} images'\n    self._progress_bar.value = 0\n    self._progress_bar.max = len(image_files)\n\n    for idx_file, image_file in enumerate(image_files):\n        logger.info('Processing %d: %s', idx_file + 1, image_file.name)\n        img = nImage(image_file)\n\n        root_stack = []\n        # get image corresponding to each root, and set it to the workflow\n        for idx, root_index in enumerate(root_index_list):\n            if 'S' in img.dims.order:\n                root_img = img.get_image_data('TSZYX', S=root_index)\n            else:\n                root_img = img.get_image_data('TCZYX', C=root_index)\n            # stack the TCZYX images for later stacking with results\n            root_stack.append(root_img)\n            # squeeze the root image for workflow\n            root_squeeze = np.squeeze(root_img)\n            # set the root image to the index of the root in the workflow\n            workflow.set(\n                name=workflow.roots()[idx], func_or_data=root_squeeze\n            )\n\n        task_names = self._tasks_select.value\n        result = workflow.get(name=task_names)\n\n        result_stack = np.asarray(\n            result\n        )  # cle.pull stacks the results on the 0th axis as \"C\"\n        # transform result_stack to TCZYX\n        result_stack = transforms.reshape_data(\n            data=result_stack,\n            given_dims='C' + self._squeezed_img_dims,\n            return_dims='TCZYX',\n        )\n\n        if result_stack.dtype == np.int64:\n            result_stack = result_stack.astype(np.int32)\n\n        # &lt;- should I add a check for the result_stack to be a dask array?\n        # &lt;- should this be done using dask or numpy?\n        if self._keep_original_images.value:\n            dask_images = da.concatenate(root_stack, axis=1)  # along \"C\"\n            result_stack = da.concatenate(\n                [dask_images, result_stack], axis=1\n            )\n            result_names = root_list + task_names\n        else:\n            result_names = task_names\n\n        OmeTiffWriter.save(\n            data=result_stack,\n            uri=result_dir / (image_file.stem + '.tiff'),\n            dim_order='TCZYX',\n            channel_names=result_names,\n            image_name=image_file.stem,\n            physical_pixel_sizes=img.physical_pixel_sizes,\n        )\n\n        self._progress_bar.value = idx_file + 1\n\n    logger.removeHandler(handler)\n    return\n</code></pre>"},{"location":"examples/skimage_workflow/","title":"Skimage workflow","text":"In\u00a0[43]: Copied! <pre>import napari_segment_blobs_and_things_with_membranes as nsbatwm\nimport numpy as np\nimport stackview\nfrom napari_workflows import Workflow\nfrom napari_workflows._io_yaml_v1 import load_workflow, save_workflow\n\nfrom napari_ndev import nImage\n</pre> import napari_segment_blobs_and_things_with_membranes as nsbatwm import numpy as np import stackview from napari_workflows import Workflow from napari_workflows._io_yaml_v1 import load_workflow, save_workflow  from napari_ndev import nImage  In\u00a0[53]: Copied! <pre>wf = Workflow()\n\nwf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1)\nwf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb')\nwf.set('membrane-label', nsbatwm.label, 'membrane-threshold')\n\nwf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1)\nwf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb')\nwf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')\n\nsave_workflow('cpu_workflow-2roots-2leafs.yaml', wf)\n</pre> wf = Workflow()  wf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1) wf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb') wf.set('membrane-label', nsbatwm.label, 'membrane-threshold')  wf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1) wf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb') wf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')  save_workflow('cpu_workflow-2roots-2leafs.yaml', wf)  In\u00a0[54]: Copied! <pre>wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')\n\nimg = nImage(r'images\\cells3d2ch.tiff')\nmembrane = img.get_image_data('TCZYX', C=0)\nmembrane = np.squeeze(membrane)\n\nnuclei = img.get_image_data('TCZYX', C=1)\nnuclei = np.squeeze(nuclei)\n\nwf.set('membrane', membrane)\nwf.set('nucleus', nuclei)\nmembrane_label = wf.get('nucleus-label')\n\nstackview.imshow(membrane_label)\n</pre> wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')  img = nImage(r'images\\cells3d2ch.tiff') membrane = img.get_image_data('TCZYX', C=0) membrane = np.squeeze(membrane)  nuclei = img.get_image_data('TCZYX', C=1) nuclei = np.squeeze(nuclei)  wf.set('membrane', membrane) wf.set('nucleus', nuclei) membrane_label = wf.get('nucleus-label')  stackview.imshow(membrane_label) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/measure/measure_widget/","title":"Measure Widget","text":"In\u00a0[3]: Copied! <pre>import napari\nfrom napari.utils import nbscreenshot\n\nviewer = napari.Viewer()\nviewer.window.resize(1000,700) # w x h\nviewer.window.add_plugin_dock_widget('napari-ndev', 'Measure Widget')\nnbscreenshot(viewer)\n</pre> import napari from napari.utils import nbscreenshot  viewer = napari.Viewer() viewer.window.resize(1000,700) # w x h viewer.window.add_plugin_dock_widget('napari-ndev', 'Measure Widget') nbscreenshot(viewer) <pre>WARNING: QWindowsWindow::setGeometry: Unable to set geometry 1920x1310+1280+550 (frame: 1942x1366+1269+505) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 2882x1968+1283+564 (frame: 2904x2024+1272+519) margins: 11, 45, 11, 11 minimum size: 385x492 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1040 maxtrack=0,0)\n21-Sep-24 11:32:12 - vispy    - WARNING  - QWindowsWindow::setGeometry: Unable to set geometry 1920x1310+1280+550 (frame: 1942x1366+1269+505) on QWidgetWindow/\"_QtMainWindowClassWindow\" on \"\\\\.\\DISPLAY1\". Resulting geometry: 2882x1968+1283+564 (frame: 2904x2024+1272+519) margins: 11, 45, 11, 11 minimum size: 385x492 MINMAXINFO maxSize=0,0 maxpos=0,0 mintrack=792,1040 maxtrack=0,0)\n</pre> Out[3]: In\u00a0[4]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[4]: In\u00a0[5]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[5]: In\u00a0[6]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[6]: In\u00a0[7]: Copied! <pre>import pandas as pd\n\nraw_data = pd.read_csv(r'./data\\measure_props_Morphology.csv')\ndisplay(raw_data.shape)\nraw_data.head()\n</pre> import pandas as pd  raw_data = pd.read_csv(r'./data\\measure_props_Morphology.csv') display(raw_data.shape) raw_data.head() <pre>(1263, 12)</pre> Out[7]: id date HIC well scene label area intensity_max-DAPI Class row column chelation media 0 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 1 0.600632 0.0 H 9 100uM DFO NGM 1 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 2 0.246413 0.0 H 9 100uM DFO NGM 2 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 3 3.203368 0.0 H 9 100uM DFO NGM 3 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 4 0.308016 0.0 H 9 100uM DFO NGM 4 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 5 269.283163 1.0 H 9 100uM DFO NGM In\u00a0[8]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[8]: In\u00a0[9]: Copied! <pre>grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv')\ndisplay(grouped_data.shape)\ngrouped_data.head()\n</pre> grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv') display(grouped_data.shape) grouped_data.head() <pre>(25, 2)</pre> Out[9]: id label_count 0 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 16 1 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 14 2 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 40 3 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 20 4 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 14 In\u00a0[10]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[10]: In\u00a0[12]: Copied! <pre>grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv')\ndisplay(grouped_data.shape)\ngrouped_data\n</pre> grouped_data = pd.read_csv(r'./data\\measure_props_Morphology_grouped.csv') display(grouped_data.shape) grouped_data <pre>(47, 8)</pre> Out[12]: id date HIC well scene intensity_max-DAPI Class label_count area_mean 0 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 0.0 15 9.641934 1 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 H9 P1-H9 1.0 1 269.283163 2 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 B9 P8-B9 0.0 12 1.036988 3 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 B9 P8-B9 1.0 2 461.962697 4 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 C9 P8-C9 0.0 39 0.576938 5 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 C9 P8-C9 1.0 1 297.451244 6 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 A9 P4-A9 0.0 18 3.002302 7 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 A9 P4-A9 1.0 2 446.762097 8 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 D9 P8-D9 0.0 12 6.541494 9 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 D9 P8-D9 1.0 2 439.747028 10 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P4-E9 0.0 27 1.536659 11 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P4-E9 1.0 2 438.938486 12 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P3-E9 0.0 8 10.378221 13 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 E9 P3-E9 1.0 2 414.428097 14 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 G9 P8-G9 0.0 55 0.816803 15 2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 24 G9 P8-G9 1.0 2 407.266720 16 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 H9 P20-H9 0.0 34 1.123353 17 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 H9 P20-H9 1.0 2 360.717772 18 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P6-C9 0.0 34 5.815165 19 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P6-C9 1.0 3 355.055407 20 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P7-C9 0.0 16 4.552864 21 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 C9 P7-C9 1.0 2 503.483281 22 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P6-D9 0.0 59 0.548948 23 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P6-D9 1.0 4 404.764088 24 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P10-D9 0.0 54 0.568119 25 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 D9 P10-D9 1.0 2 439.947239 26 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 E9 P7-E9 0.0 52 1.061767 27 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 E9 P7-E9 1.0 4 573.364456 28 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 F9 P11-F9 0.0 201 13.183400 29 2024-08-07 25x 48HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 48 F9 P11-F9 1.0 2 824.220550 30 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 H9 P4-H9 0.0 44 0.557229 31 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 H9 P4-H9 1.0 1 517.975443 32 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P6-B9 0.0 68 2.446237 33 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P6-B9 1.0 1 656.428725 34 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P8-B9 0.0 64 0.430741 35 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P8-B9 1.0 1 602.941711 36 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P7-B9 0.0 73 0.641138 37 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 B9 P7-B9 1.0 1 1369.917450 38 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 A9 P3-A9 0.0 48 1.359763 39 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 D9 P7-D9 0.0 26 31.638595 40 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 D9 P7-D9 1.0 1 443.882146 41 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 E9 P2-E9 0.0 7 1.095658 42 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 E9 P2-E9 1.0 2 446.831401 43 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 F9 P13-F9 0.0 36 0.533039 44 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 F9 P13-F9 1.0 1 736.743949 45 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 G9 P9-G9 0.0 56 5.597644 46 2024-08-07 25x 72HIC NCOA4 647 FT 568 PHALL 48... 2024-08-07 72 G9 P9-G9 1.0 2 789.691934"},{"location":"examples/measure/measure_widget/#measure-widget","title":"Measure Widget\u00b6","text":"<p>This page describes how to generate data outputs from measuring label images. Currently, labels are measured with <code>scikit-image.regionprops</code> and exported to a <code>.csv</code> file (which can be opened in any spreadsheet application or stats program). In addition, the user can specify two different sets of metadata to add additional information: 1) <code>ID Regex</code> which will parse information currently from the filename and the scene information; an example will be shown in <code>Example ID String</code>. 2) <code>Tx Map</code> can be used to add information based on a multi-well plate map. The <code>ID</code> mapped to is any column that can be created by <code>ID Regex</code> or the <code>Scene</code> information.</p> <p>In some ways, this widget is knowingly complex, however, it is certainly intended that a more advanced user can provide the proper <code>ID Regex</code> and <code>Tx Map</code> for a user for the experiments, and in the end create a summarized dataset. While the measure widget initially spits out a raw data file which will contain more rows than most datasets you are familiar with, since it is in 'long' format. In other words, each row represents a single object.</p> <p>Thus, to summarize your data on any measure of summary that you would like, use the <code>Grouping</code> tab and select the unique identifiers to summarize by. You will then select a column to <code>Count</code> which will tell you the number of labels in that group. Optionally, you can add <code>Aggregation Columns</code> to summarize all selected columns by the selected aggregation functions. For example, you may wish to know the <code>mean area</code> of all objects in your groups.</p>"},{"location":"examples/measure/measure_widget/#example-folder","title":"Example folder\u00b6","text":"<p>The only required directory is the <code>label directory</code> whereby the objects that you want to measure are found. You should also select/make an <code>output directory</code> so that you know where your file is saved.</p> <p>Once you select the <code>label directory</code>, label names will populate both the <code>label image</code> and <code>intensity images</code>. The only required selection is a <code>label image</code> once this is done, you can hit the <code>Measure</code> button and will get the most minimal dataset possible. If you would like to measure multiple <code>labels</code> at the same time, then select multiple labels and it will iterate through each label channel in the images.</p> <p>However, you can also add other intensity images (by loading an image or region directory, the reasoning for these namings will come in future tutorials) and select them in the widget to be measured against. Then, in <code>Region Props</code> tab you can select additional properties to measure.</p> <p>In this example I want to measure the <code>intensity max</code> of the corresponding <code>Labels: DAPI Class</code> because this will give me the 'type' of DAPI that is inside each <code>Morphology</code> object. This is because the background is 0, live is 1, and dead is 2. So, we can later filter by the 'DAPI Class' of each morphology object. In other words, intensity images don't have to be raw intensity values, but other labels can be used.</p>"},{"location":"examples/measure/measure_widget/#id-regex","title":"ID Regex\u00b6","text":"<p>In this example, one such ID string is: <code>'2024-08-07 25x 24HIC NCOA4 647 FT 568 PHALL 488 DAPI OBL_107_106_P1-H9.ome__0__Image:0'</code> From here, I can extract multiple different bits of information, which is why saving interesting metadata into filenames can be useful. This needs to be a dictionary, where each key represents a column, and the value for that key is the regex (regular expression) pattern used to extract that information. The only quirk (besides regex) is that there must be at least 1 'group' aka a pattern surrounded by parenetheses. This pattern surrounded by parentheses is what will be saved into the column. As such, there can be extra regex that isn't kept, but can be used to locate the pattern.</p> <pre><code>{\n    'scene': r'(P\\d{1,3}-\\w+).ome',\n    'well': r'-(\\w+).ome',\n    'HIC': r'(\\d{1,3})HIC',\n    'date': r'(\\d{4}-\\d{2}-\\d{2})',\n}\n</code></pre>"},{"location":"examples/measure/measure_widget/#tx-map","title":"Tx Map\u00b6","text":"<p>This section uses <code>napari_ndev:PlateMapper</code>. It is currently only set up to be used with typical culture plate dimensions, but will hopefully be updated in the future to be flexible to arbitrary patterns, so that a <code>Treatment ID</code> can include something like slide or section information that can then be mapped to treatments or positions of some kind. First, press the <code>Update Treatment ID Choices</code> to read possibilities from the <code>ID Regex</code> container. In the <code>treatment ID</code>, select the name of the column with the ID in it, which will usually be obtained from <code>ID Regex</code>, for this example it is 'well'.</p> <p>Then, select the number of wells for your plate, to automatically make a plate in the typical layout. For example, a 96-well plate would automatically map a A-H (8 row) plate with 12 columns.</p> <p>For now, you provide lists of strings with ranges representing wells on a plate. For <code>PlateMapper</code> provide a dictionary, where each key represents a column header, and then the value-dictionary has a key which is what will get mapped to the matching well-value. For example:</p> <pre><code>{\n  'chelation':{\n    'Control': ['B1:C12'],\n    '50uM DFP': ['D1:E12'],\n    '100uM DFP': ['F1:G12'],\n    '100uM DFO': ['A1:A12', 'H1:H12'],\n  },\n  'media':{\n    'NGM': ['A1:H12'],\n  }\n}\n</code></pre>"},{"location":"examples/measure/measure_widget/#finally-measure","title":"Finally, Measure\u00b6","text":"<p>At any point once minimal selections were made, you could click the <code>Measure</code> button and it will measure all the labels in batch, and save the results to the output directory.</p>"},{"location":"examples/measure/measure_widget/#grouping-data","title":"Grouping Data!\u00b6","text":"<p>After acquiring your dataset, you may be interested in processing it further with the <code>Grouping</code> tab. This will reduce it from many rows, to much fewer. This example before has 1263 rows and 12 columns.</p>"},{"location":"examples/measure/measure_widget/#using-the-grouping-tab","title":"Using the Grouping Tab\u00b6","text":"<p>Load in your raw data of interest, and it will populate all the possible column names. Minimally, select grouping columns and the count column. For example, if I want to group by every 'id' (i.e. filename, with scene info) I would be able to leave the default values.</p>"},{"location":"examples/measure/measure_widget/#advanced-grouping","title":"Advanced grouping\u00b6","text":"<p>However, you will note that now only the 'id' and 'label_count' columns are present. If I instead wanted to keep all that careful metadata I extracted earlier, I would also want to select other grouping data, such as id, date, HIC, well, and scene, and 'intensity_max-DAPI Class' which represents the type of cell present.</p> <p>And I could also select a column to aggregate, such as getting the 'mean' of the 'area' for each of these groups. Remember, if you keep the 'id' then minimally each file will get summarized. To have a more general summary (which would not typically be recommended), do not use 'id'.</p>"},{"location":"examples/measure/measure_widget/#interpreting-the-results","title":"Interpreting the results\u00b6","text":"<p>Now, you should be able to place this easily into your stats program of choice (mine is using Python!). Note how we have shown in the first image that there are 15 labels with a DAPI class of zero, meaning that this label does not contain a nucleus and there is 1 label with a DAPI Class of 1 (meaning that it is alive, based on a previous classifier employed with APOC Widget). This also shows for example that the <code>area_mean</code> is larger for an alive cell, compared to whatever debris there must be that doesn't have a nucleus.</p> <p>This is also useful for grouping your data to double check that the results intuitively make sense. You should also make sure to check through your labels. You can try <code>napari-ndev:ImageOverview</code> for that. It will be added to the widgets soon, to quickly have overview .png files to scroll through on any system.</p>"},{"location":"examples/utilities/image_utilities/","title":"Image Utilities","text":"In\u00a0[1]: Copied! <pre>import pathlib\n\nimport napari\nfrom napari.utils import nbscreenshot\n\nparent = pathlib.Path.cwd().parent\nrel_path = 'images/cropped_neuron.ome.tiff'\n\nviewer = napari.Viewer()\nviewer.window.resize(1500, 800) # w x h\nviewer.window.add_plugin_dock_widget('napari-ndev', 'Image Utilities')\nviewer.open(parent / rel_path, plugin='napari-bioio')\n\nnbscreenshot(viewer)\n</pre> import pathlib  import napari from napari.utils import nbscreenshot  parent = pathlib.Path.cwd().parent rel_path = 'images/cropped_neuron.ome.tiff'  viewer = napari.Viewer() viewer.window.resize(1500, 800) # w x h viewer.window.add_plugin_dock_widget('napari-ndev', 'Image Utilities') viewer.open(parent / rel_path, plugin='napari-bioio')  nbscreenshot(viewer) Out[1]: In\u00a0[2]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[2]: In\u00a0[3]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[3]: In\u00a0[4]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[4]:"},{"location":"examples/utilities/image_utilities/#image-utilities","title":"Image Utilities\u00b6","text":"<p>This example will describe how to manage metadata, crop, and annotate images with the Image Utilities widget. The widget can be opened from <code>Plugins --&gt; nDev --&gt; Image Utilities</code>. To crop layers in the viewer, open <code>Plugins --&gt; crop region (napari_crop)</code>. Below, we load napari and open the Image Utilities Widget and load in a large image originally saved with the widget from a multi-scene CZI file. Note that currently no metadata populates the widget because the file was not selected with <code>Select Files</code>. Instead, the image was opened with the <code>napari-bioio</code> plugin; however, the metadata is saved and could normally be accessed from <code>viewer.layers[n].metadata['bioimage']</code>.</p> <p>To access metadata from any image in the viewer, press the <code>Selected Layer</code> button in the <code>Update Metadata from:</code> box.</p>"},{"location":"examples/utilities/image_utilities/#update-metadata-from-layer","title":"Update Metadata from layer\u00b6","text":"<p>Now both Channel Name(s) and the Scale is shown</p>"},{"location":"examples/utilities/image_utilities/#updating-metadata-automatically-with-widget-file-selection","title":"Updating Metadata Automatically with Widget File Selection\u00b6","text":"<p>Select one or multiple files which could be opened into the viewer, but these files do not have to be in order to be saved.</p> <p>To turn off auto metadata update on file selection uncheck <code>Update Metadata</code>. You may open the image (which will attempt to use <code>napari-aicsimageio</code>, if it exists, otherwise a different compatible reader) or <code>Select Next</code> and it will iterate to the next alpha-numerically sorted filename(s) matching the current number that are open.</p>"},{"location":"examples/utilities/image_utilities/#concatenating-files-and-saving-layers","title":"Concatenating Files and Saving Layers\u00b6","text":"<p><code>Concatenate Files</code> checkbox below allows saving of image data as OME-TIFF without empty channels. This could be useful if your microscope saves images as RGB with empty channels. Alternatively, if <code>Concatenate Layers</code> is checked then it will combine any layers selected in the left panel <code>layer list</code> of napari. Having both checked will stack the select file path with any select viewer layers, which could be useful if you wanted to process images and then combine with the original.</p> <p>All metadata is passed from the widget to <code>bioio.writers.OmeTiffWriter</code> to keep metadata and is used by all other widgets of the plugin.</p>"},{"location":"examples/utilities/image_utilities/#quick-annotation","title":"Quick Annotation\u00b6","text":"<p>Both the Shapes and Labels layers can be quickly drawn on to your image to annotate in whatever way suits your needs. Then, when the layer you want is selected hit the button in the widget to save your image, layer, or shape (which will be converted to a scaled label). Each 'Shape' will also get a corresponding label, allowing multi-ROI consistency across images.</p>"},{"location":"examples/utilities/image_utilities/#utilizing-shapes-for-future-annotations","title":"Utilizing Shapes for future annotations\u00b6","text":"<p>In order to re-use Shapes for future annotations (akin to an ImageJ/FIJI ROI), go to <code>File -&gt; Save Selected Layer</code> and save the Shapes layer as a .CSV. When you load this .csv back into napari it will always load with a scale of (1.0,1.0,1.0) and you will thus need to select the shapes layer and <code>Scale Layer(s)</code> using the widget to re-size your annotation to the expected size.</p>"},{"location":"examples/workflow/workflow_napari-assistant/","title":"Generating workflows with napari","text":"In\u00a0[1]: Copied! <pre>import napari\nfrom napari.utils import nbscreenshot\n\nviewer = napari.Viewer()\nviewer.window.resize(1000, 700) # w x h\nviewer.window.add_plugin_dock_widget('napari-assistant')\nviewer.open_sample('napari', 'human_mitosis')\nnbscreenshot(viewer)\n</pre> import napari from napari.utils import nbscreenshot  viewer = napari.Viewer() viewer.window.resize(1000, 700) # w x h viewer.window.add_plugin_dock_widget('napari-assistant') viewer.open_sample('napari', 'human_mitosis') nbscreenshot(viewer) Out[1]: <pre>2024-09-15 23:13:22.581 | INFO     | napari_assistant._gui._category_widget:call_op:178 - gaussian_blur (clesperanto)(..., 1.0, 1.0, 0.0)\n2024-09-15 23:13:25.405 | INFO     | napari_assistant._gui._category_widget:call_op:178 - median_sphere (clesperanto)(..., 1.0, 1.0, 0.0)\n2024-09-15 23:13:26.324 | INFO     | napari_assistant._gui._category_widget:call_op:178 - top_hat_box (clesperanto)(..., 10.0, 10.0, 0.0)\n2024-09-15 23:13:27.501 | INFO     | napari_assistant._gui._category_widget:call_op:178 - voronoi_otsu_labeling (clesperanto)(..., 2.0, 2.0)\n</pre> In\u00a0[2]: Copied! <pre>nbscreenshot(viewer)\n</pre> nbscreenshot(viewer) Out[2]:"},{"location":"examples/workflow/workflow_napari-assistant/#generating-workflows-with-napari","title":"Generating workflows with napari\u00b6","text":"<p>This page describes how to generate custom workflows using napari using the calculator-like interface from <code>napari-assistant</code>. In many ways, this should be reminiscent of using the <code>Macro Recorder</code> in FIJI/ImageJ, but you will hopefully find it has more flexibility and advantages. Ultimately, our goal is to easily reproduce image processing steps with a <code>napari-workflows</code> <code>.yaml</code> file and utilize it for batch processing with <code>napari-ndev:Workflow Widget</code>.</p>"},{"location":"examples/workflow/workflow_napari-assistant/#napari-assistant","title":"napari-assistant\u00b6","text":"<p>In order to generate workflows with napari, you may like to <code>pip install napari-ndev[extra-plugins]</code> to install the napari-assistant and other cooperating plugins. You can then access the assistant via the <code>Plugins menu -&gt; Assistant (clesperanto)</code></p> <p>A thorough tutorial on how to use napari-assistant, including video, can be found here. The assistant is quite flexible and both functions and parameters are modifiable on-the-fly, but can be overall quirky at times.</p>"},{"location":"examples/workflow/workflow_napari-assistant/#apply-processing-steps","title":"Apply processing steps\u00b6","text":"<p>With the napari-assistant, I've selected the 'nuclei' layer and do a few processing steps to label the image. This is flexible for 3D images as well, because napari-workflow will save the 2D or 3D parameters as necessary.</p>"},{"location":"examples/workflow/workflow_napari-assistant/#save-the-workflow-file","title":"Save the workflow file\u00b6","text":"<p>Using the 2nd from the lower right button, <code>save and load workflows</code> -&gt; export workflow to file. I have named this <code>viewer-segment-nuclei-sample.yaml</code> into the resources folder in the docs library, but you should save it wherever you want to keep it in your project.</p>"},{"location":"examples/workflow/workflow_scripting/","title":"Scripting a Workflow","text":"In\u00a0[\u00a0]: Copied! <pre>import napari_segment_blobs_and_things_with_membranes as nsbatwm\nimport numpy as np\nimport stackview\nfrom napari_workflows import Workflow\nfrom napari_workflows._io_yaml_v1 import load_workflow, save_workflow\n\nfrom napari_ndev import nImage\n</pre> import napari_segment_blobs_and_things_with_membranes as nsbatwm import numpy as np import stackview from napari_workflows import Workflow from napari_workflows._io_yaml_v1 import load_workflow, save_workflow  from napari_ndev import nImage  In\u00a0[\u00a0]: Copied! <pre>wf = Workflow()\n\nwf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1)\nwf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb')\nwf.set('membrane-label', nsbatwm.label, 'membrane-threshold')\n\nwf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1)\nwf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb')\nwf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')\n\nsave_workflow('cpu_workflow-2roots-2leafs.yaml', wf)\n</pre> wf = Workflow()  wf.set('membrane-gb', nsbatwm.gaussian_blur, 'membrane', sigma=1) wf.set('membrane-threshold', nsbatwm.threshold_otsu, 'membrane-gb') wf.set('membrane-label', nsbatwm.label, 'membrane-threshold')  wf.set('nucleus-gb', nsbatwm.gaussian_blur, 'nucleus', sigma=1) wf.set('nucleus-threshold', nsbatwm.threshold_otsu, 'nucleus-gb') wf.set('nucleus-label', nsbatwm.label, 'nucleus-threshold')  save_workflow('cpu_workflow-2roots-2leafs.yaml', wf)  In\u00a0[\u00a0]: Copied! <pre>wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')\n\nimg = nImage(r'images\\cells3d2ch.tiff')\nmembrane = img.get_image_data('TCZYX', C=0)\nmembrane = np.squeeze(membrane)\n\nnuclei = img.get_image_data('TCZYX', C=1)\nnuclei = np.squeeze(nuclei)\n\nwf.set('membrane', membrane)\nwf.set('nucleus', nuclei)\nmembrane_label = wf.get('nucleus-label')\n\nstackview.imshow(membrane_label)\n</pre> wf = load_workflow('cpu_workflow-2roots-2leafs.yaml')  img = nImage(r'images\\cells3d2ch.tiff') membrane = img.get_image_data('TCZYX', C=0) membrane = np.squeeze(membrane)  nuclei = img.get_image_data('TCZYX', C=1) nuclei = np.squeeze(nuclei)  wf.set('membrane', membrane) wf.set('nucleus', nuclei) membrane_label = wf.get('nucleus-label')  stackview.imshow(membrane_label)"},{"location":"examples/workflow/workflow_scripting/#scripting-a-workflow","title":"Scripting a Workflow\u00b6","text":""},{"location":"examples/workflow/workflow_widget/","title":"Workflow Widget","text":""},{"location":"examples/workflow/workflow_widget/#workflow-widget","title":"Workflow Widget\u00b6","text":"<p>The napari-ndev Workflow widgets</p>"},{"location":"tutorial/00_setup/","title":"1) Tutorial Setup","text":""},{"location":"tutorial/00_setup/#setup-for-tutorial","title":"Setup for Tutorial","text":""},{"location":"tutorial/00_setup/#installation-of-napari-and-napari-ndev","title":"Installation of napari and napari-ndev","text":"<p>You have two options to download <code>napari</code> and <code>napari-ndev</code>. For users unfamiliar with using the command line and python, I would recommend following the instructions to install from UI at Beginner Setup.</p> <p>If you are familiar with python, then I would recommend creating a new environment and to do a fresh installation with <code>napari-ndev[all]</code>. Further details available in Installation.</p>"},{"location":"tutorial/00_setup/#download-tutorial-images-and-files","title":"Download Tutorial Images and Files","text":""},{"location":"tutorial/00_setup/#cellpainting-images","title":"CellPainting Images","text":"<p>Download Images for Example Pipeline Then, extract the files in the ZIP folder.</p> <p>The images come from the Broad Bioimage Benchmark Collection. Investigate the link for the description of the images.</p> <p>Scale: 0.656um/pixel</p> <p>Channels:</p> <ol> <li>Hoescht 33342 (nuclei)</li> <li>con A (endoplasmic reticulum)</li> <li>SYTO 14 (nucleic acids: nucleoli, cytoplasmic RNA)</li> <li>WGA + phalloidin (plasma membrane, golgi, and actin)</li> <li>MitoTracker Deep Red (mitochondria)</li> </ol> <p></p>"},{"location":"tutorial/00_setup/#primaryneuron-images","title":"PrimaryNeuron Images","text":"<p>Download Images for Easy Machine Learning Tutorial</p> <p>These images come from my own work at the University of Minnesota in the Thomas Bastian lab. The primary neurons are derived from embryonic mouse brains, and grown for a few days in a dish. The goal is to study morphology and iron homeostasis as the neurons develop over time in conditions of iron deficiency. The images available in the tutorial are extracted from multi-scene CZI files (each original file has over 100 scenes) using the <code>Image Utilities</code> widget. Metadata from the CZI files was correct, so the widget automatically passes this downstream without any user input.</p> <p>Scale: 0.1241um/pixel</p> <p>Channels:</p> <ol> <li>AF647 - NCOA4 / nuclear coactivator 4 (a protein known to target ferritin for degradation)</li> <li>AF568 - Ferritin (the iron storage protein)</li> <li>AF488 - Phalloidin (stains actin filaments)</li> <li>DAPI (nuclei)</li> <li>Oblique (brightfield; not always present, which is ok)</li> </ol> <p></p>"},{"location":"tutorial/00_setup/#neuralprogenitor-images","title":"NeuralProgenitor Images","text":"<p>Download Images for Building a Pipeline Tutorial</p> <p>These images come from the Zhe Chen lab at the University of Minnesota. These come from a microscope that very poorly saves the images: the images are forced to be saved as RGB (dspite having only one channel in each image) and improper scaling metadata. The images available in this tutorial have already been concatenated and the metadata applied using the <code>Image Utilities</code>.</p> <p>Pax6 - Green; Tbr2 - Magenta</p> <p>Scale: 0.7548um/pixel</p> <p>Channels:</p> <ol> <li>PAX6 (a nuclear transcription factor identifying radial glia)</li> <li>PAX6-2 (a duplicate of PAX6, due to the way the microscope saves images)</li> <li>TBR2 (a nuclear transcription factor identifying intermediate progenitor cells)</li> </ol> <p></p>"},{"location":"tutorial/01_example_pipeline/","title":"2) Example Pipeline","text":""},{"location":"tutorial/01_example_pipeline/#example-pipeline-tutorial","title":"Example Pipeline Tutorial","text":"<p>The goal of this example pipeline is to get the user familiar with working with <code>napari-ndev</code> for batch processing and reproducibility (view <code>Image Utilities</code> and <code>Workflow Widget</code>). In addition, this example pipeline thoroughly explains the <code>Measure Widget</code>, since this is a shared use across many pipelines.</p> <p>This Example Pipeline does not cover how <code>napari-ndev</code> is used for high-throughput annotations, the machine learning tools (<code>APOC Widget</code>), and designing your own workflows. This information will instead be covered in the interactive tutorials that follow.</p>"},{"location":"tutorial/01_example_pipeline/#image-utilities","title":"Image Utilities","text":"<p>We are going to start with the <code>Image Utilities</code> widget in order to concatenate the CellPainting images. This will show a common use of the Image Utilities plugin, wherein various file formats can be managed and saved in to a common OME-TIFF format, including channel names and physical pixel scaling.</p> <p></p> <ol> <li><code>Choose Directory</code> selects where images will be saved.</li> <li><code>Select files</code> individual or multiple files can be selected. Select the first 5 images (representing the 5 channels of 1 image).</li> <li> <p><code>Metadata</code> dropdown. We will add in names to save the channels with, according to information that is useful. This could be the fluorophore (e.g. Hoescht 33342) or other identifying information (e.g. nuclei).</p> <ol> <li><code>Channel Name(s)</code>: copy and paste <code>['H33342', 'conA', 'SYTO14', 'WGA_Phall', 'MitoTDR']</code>. The format you want to use is a list <code>[]</code> of strings <code>'a','b','etc.'</code></li> <li><code>Scale, ZYX</code>. Set Y and X to <code>0.656</code>. Z will be ignored since images are 2D.</li> </ol> </li> <li> <p><code>Batch Concat.</code> Pressing this button will iterate through all files in the folder, selecting them in groups of 5 (i.e. the number of original files selected) and then saving them with the above parameters.</p> </li> </ol>"},{"location":"tutorial/01_example_pipeline/#investigate-the-images","title":"Investigate the images","text":"<p>If you want to investigate the raw images press <code>Open File(s)</code> this will open the original images with their known scale <code>(1,1,1)</code>. Each image will open as grayscale, and will not be layered.</p> <p>Now, investigate your concatenated images. Go to <code>Select Files</code> and find the folder <code>ConcatenatedImages</code> inside the <code>Choose Directory</code> previously chosen. Select the first image and <code>Open File(s)</code>. This time, the images will be open to the scale we set <code>(0,0.656,0.656)</code> and with a default layering and pseudo-coloring. This is how all images get passed down throughout the plugin.</p>"},{"location":"tutorial/01_example_pipeline/#example-workflow","title":"Example workflow","text":"<p>Once images are in a format that is helpful for analysis, we can proceed with other widgets. This does mean that some images do not need to be processed with the <code>Image Utilities</code> Widget; for example, some microscopes properly incorporate scale and channel names into the image metadata. For this tutorial, we are going to use the <code>Workflow Widget</code> to pre-process, segment, and label features of the image with a pre-made custom workflow file (see <code>cellpainting\\scripting_workflow.ipynb</code> to see how). The intent of the <code>Workflow Widget</code> is to easily reproduce This custom workflow was designed initially with the <code>napari-assistant</code> which will be explored further in the following tutorial sections.</p> <p>The goal for this workflow is to segment the nucleus, cell area (based on a voronoi tessellation of the nuclei), cytoplasm (cell area - nucleus), and the nucleoli. We will later measure the properties of these objects using the <code>Measure Widget</code>.</p> <p></p>"},{"location":"tutorial/01_example_pipeline/#using-the-workflow-widget-for-batch-processing","title":"Using the Workflow Widget for Batch Processing","text":"<ol> <li><code>Image Directory</code> choose the <code>ConcatenatedImages</code> found in the previous parent folder.\\</li> <li><code>Result Directory</code> create a folder to save the output images into.</li> <li><code>Workflow File</code> navigate to <code>scripted_cellpainting_workflow.yaml</code></li> </ol> <p>Now, you will now see the UI automatically update to show the <code>roots</code> (input images of the Workflow file). Furthermore, these <code>roots</code> will be populated by the channel names of the images in the chosen directory. In this workflow there are three root images required: (1) <code>Root 0: cyto_membrane</code> is <code>WGA_Phall</code>, (2) <code>Root 1: nuclei</code> is <code>H33342</code>, and (3) <code>Root 2: nucleoli</code> is <code>SYTO14</code>.</p> <p></p> <p>Next, switch to the <code>Tasks</code> tab. In this tab, the <code>leaves</code> or workflow tasks that sit at the terminals of task tree are automatically selected. However, we are also interested in visualizing the nuclei. So, hold control or command on your keyboard and also click <code>nuclei-labels</code> to add this task to the batch workflow. If all workflow tasks you are interested in are represented as <code>leaves</code> than you can even skip this tab!</p> <p></p> <p>Finally, press <code>Batch Workflow</code>. The <code>Image Directory</code> will be iterated through with the workflow. The Progress Bar will show updates and a log file will be saved to show the input parameters and progress of the batch processing, including any possible errors.</p>"},{"location":"tutorial/01_example_pipeline/#workflow-notes","title":"Workflow notes","text":"<p>Just as we selected an additional task for the workflow, any number of tasks can be acquired from the workflow and if <code>Keep Original Images</code> is checked, these will also be saved in the resulting batch processed images. As such, the workflow widget can also be used to easily visualize intermediate steps of the Workflow to investigate how something was achieved and share that information. Below, napari is showing every original channel and every task in this workflow as a grid in napari; all of this is saved into one single file.</p> <p></p> <p>Coming Soon: the ability to use layers in the workflow as roots to do single image Workflows and adding them into napari immediately!</p>"},{"location":"tutorial/01_example_pipeline/#measure-widget","title":"Measure Widget","text":"<p>The <code>Measure Widget</code> provides the ability to measure images in batch, group important information, and even utilize metadata to map sample treatments and conditions. This widget is the newest addition the <code>napari-ndev</code>, in part because it has taken me a long time to conceptualize how to make image measurements accessible in batch, so I am particularly looking for usage feedback. For detailed usage instructions see the <code>Measure Widget</code> Example.</p>"},{"location":"tutorial/01_example_pipeline/#how-measuring-in-python-generally-works","title":"How measuring in Python generally works","text":"<p>It is often most helpful to represent a segmented image as 'labels'. Labels (including the <code>Labels Layer</code> in napari) have a pseudocolor scheme where each label (i.e. object) has a specific value, and that value is represented by a color. When these labels are then measured, each label object is measured independently and represented in one row. With few objects of interest in low-throughput processes, this can make sense, but, a label image with 100 objects will result in a spreadsheet with 100 rows. Accordingly, even measuring 10 images with 100 objects each leads to 1000 rows. To many scientists, these are both small object numbers and small image numbers, so you can imagine how quickly and easily datasets can be in the hundreds of thousands or millions of rows.</p> <p>Furthermore, many many properties of images can be labeled, from area (which is scaled properly throughout this plugin to real units), to perimeter, to solidity, to sphericity. Thus, measuring label properties in Python generally requires knowledge of python to make sense of this long multi-variate data. Especially when it comes to grouping data by treatments or doing counts or other aggregating functions on any measurement of the labels.</p> <p>The <code>Measure Widget</code> seeks to address the most common usability cases for high-throughput analyses by providing human readable outputs. Furthermore, treatment metadata mapping can easily be shared from a more advanced researcher to a novice, for reproducibility of more involved analyses.</p>"},{"location":"tutorial/01_example_pipeline/#initial-batch-measurement-with-the-widget","title":"Initial Batch Measurement with the Widget","text":"<ol> <li><code>Label Directory</code>: Select the directory containing the Labels you desire to measure -- in this case choose the directory from the <code>Workflow Widget</code>. This image file can contain any number of labels (or non-labels, but those should not be measured). Channels will populate both <code>Label Image</code> select and <code>Intensity Images</code>.</li> <li><code>Image Directory</code>: An Optional directory -- choose the <code>ConcatenatedImages</code> directory to populate the original channel images to the <code>Intensity Images</code> select box.</li> <li><code>Region Directory</code>: Another Optional directory intended for 'ROI'/Region of Interest labels -- not used for this pipeline.</li> <li><code>Label image</code>: Using multi-selection, select <code>cell-labels</code>, <code>cyto-labels</code>, and <code>nuclei-labels</code>. We will measure each object in each image.</li> <li><code>Intensity images</code>: Using multi-selection, select <code>nucleoli-labels</code> (to measure the number of nucleoli inside the label), <code>conA</code> and <code>mitoTDR</code> (to measure the underlying intensity of the channel on the label).</li> <li><code>Region Props</code>. This is a list of the measurements for each label. For this example, at least select <code>label</code>, <code>area</code>, <code>intensity_mean</code> and <code>solidity</code>. <code>label</code> is the identity, and is recommended to always be checked. Otherwise you can measure shape features like area, eccentricity, and solidity or you can measure intensity features like the mean, max, min, etc. Note, that measuring something like the <code>intensity max</code> of an intensity image that represents an ROI serves as a means to identify if it is inside (i.e. the value of the ROI) or outside (i.e. 0) the region.</li> <li>At this point, you could hit the Measure button and it will measure all label channels in each image in batch. However, for this example we also want to add some identification and treatment data to the output. This example data comes from wells with no treatment, so we will generate some ourselves to explain the concept, but this should be straightforward enough to apply to your own data. To use the <code>ID Regex</code> and <code>Tx Map</code> tags we use dictionaries of key: value pairs where the key becomes the column name, and the value contains the regular expression to search for.</li> <li><code>ID Regex</code> tab. This dictionary extracts information from the filename with regular expression patterns. These data all come from <code>plate1</code> but if we had multiple plates we could extract the plate number with the following regex <code>r'(plate\\d{1,2})-'</code> whatever is inside the <code>()</code> is considered the 'group' that gets returned. In this case we can provide the dictionary to return the identifying number of the plate and the well position. We specifically need the well position in order to map it to the treatment map. Copy and paste this into <code>ID Regex</code></li> </ol> <pre><code>{\n    'plate': r'plate(\\d{1,3})_',\n    'well': r'_(\\w+?)_site',\n    'site': r'_site(\\d{1,3})_',\n}\n</code></pre> <ol> <li><code>Tx Map</code> tab. This dictionary maps well positions to an overall platemap. This time, the key remains the column identification, but then another dictionary is used to map the treatments inside, see below for example. The platemap is expected to be of standard configuration, but can include wells that are not imaged. First press 'Update Treatment ID Choices' to use the previous regex for Well ID. Select <code>well</code> for <code>Treatment ID</code> and <code>384</code> for <code>Number of Wells</code>. We are going to pretend the platemap has the following treatments:</li> </ol> <pre><code>{\n    'media': {\n        'HBSS': ['A1:C24'],\n        'DMEM': ['D1:F24'],\n    },\n    'treatment': {\n        'control': ['A12:P14'],\n        'drug': ['A15:P18'],\n    }\n}\n</code></pre> <ol> <li>Press the <code>Measure</code> button! We have all the options set to richly annotate our data with identifying info and treatments... in batch!</li> </ol>"},{"location":"tutorial/01_example_pipeline/#grouping-the-data","title":"Grouping the data","text":"<p>Navigate to the <code>Output Directory</code> and find the <code>measure_props...csv</code> for your data! You can see each measure for each label, but it's hard to read interpret this way.</p> label_name id site well plate label area intensity_mean-nucleoli-labels intensity_mean-conA intensity_mean-MitoTDR solidity row column media treatment cell-labels plate1_A14_site1_Ch1__0__plate1_A14_site1_Ch1 1 A14 1 1 1469.167104 0.7454598711189221 256.04100761570004 295.11511423550087 0.7832071576049552 A 14 HBSS control cell-labels plate1_A14_site1_Ch1__0__plate1_A14_site1_Ch1 1 A14 1 2 505.6448000000001 0.089361702 407.0757446808511 389.1506382978723 0.9767248545303407 A 14 HBSS control cell-labels plate1_A14_site1_Ch1__0__plate1_A14_site1_Ch1 1 A14 1 3 336.092416 1.2586427656850192 233.87580025608196 326.2509603072983 0.9455205811138013 A 14 HBSS control <p>Instead, we want to group the data by useful metrics. Navigate to the <code>Grouping</code> tab. Select the output <code>measure_props...csv</code> for <code>Measured Data Path</code>; the selection is interpreted to fill the remaining information in the tab. If we include the <code>id</code> name in our grouping column, then it will summarize each individual image. If you then also select other identifying information, like site, well, plate, etc. then this information will be kept in the summarized file. Ultimately, data will be grouped by the most fine-grained group (in this case, each image, aka the <code>id</code>). So, if you wanted to just know differences between treatments you could do group only by <code>treatment</code>; caution this hides your raw data and just reduces the information to the aggregate function.</p> <p>For this pipeline, we are going to group by: id, label_name (which label channel it is), site, well, plate, media, and treatment. This will summarize the data by <code>id</code> at the finest (each file), but preserve all that metadata. Then, we keep <code>Count Column</code> set to <code>label</code> so that it counts the number of each object in the image. Finally, we are going to aggregate other measured features. Select <code>Aggregation Columns</code>: <code>intensity_mean-conA</code> (to measure the intensity of ER) and <code>intensity_mean_MitoTDR</code> (mitochondria), and <code>area</code> (to compare the size of each object). Then observe how the there are multiple <code>Aggregation Functions</code> that by default is set to <code>mean</code>.</p> <p>Next, <code>check</code> <code>Pivot Wider</code>. This will place each individual label channel in the columns, rather than replicating in rows. This is generally more human-readable and familiar for non-coding statistical work.</p> <p>Finally, press <code>Group Measurements</code> button! You now have the output dataset.</p> <p></p>"},{"location":"tutorial/01_example_pipeline/#make-observations","title":"Make observations","text":"<p>One of the best parts of summarizing your data is quickly checking for quality control. Investigate <code>measure_props...grouped.csv</code></p> <ol> <li>Do we get the same number of rows that we would expect? (hint, it should be the number of images, with how we grouped)</li> <li>Are there the same number of nuclei as cytoplasms in each image? Should there be?</li> <li>Is the intensity of a certain marker localized more to the cytoplasm or the nucleus?</li> <li>Is the are of the whole cell larger than the cytoplasm and nucleus alone? Does nucleus + cytoplasm = cell?</li> </ol> id site well plate media treatment label_count label_count.1 label_count.2 area_mean area_mean.1 area_mean.2 intensity_mean-MitoTDR_mean intensity_mean-MitoTDR_mean.1 intensity_mean-MitoTDR_mean.2 intensity_mean-conA_mean intensity_mean-conA_mean.1 intensity_mean-conA_mean.2 nan nan nan nan nan nan cell-labels cyto-labels nuclei-labels cell-labels cyto-labels nuclei-labels cell-labels cyto-labels nuclei-labels cell-labels cyto-labels nuclei-labels plate1_A14_site1_Ch1__0__plate1_A14_site1_Ch1 1 A14 1 HBSS control 79.0 79.0 79.0 1458.3978094177216 1214.6478728101267 243.74993660759498 325.2266947462635 307.7767026467916 412.45047953549573 283.3011895008876 264.05000585134076 377.55476585283094 plate1_A14_site2_Ch1__0__plate1_A14_site2_Ch1 2 A14 1 HBSS control 92.0 92.0 92.0 1270.5623624347827 1015.8361933913045 254.74487930434788 335.0570967957602 319.5738507170695 405.50202331367353 273.7174073017615 256.90458122232934 349.3471722687742 plate1_B13_site1_Ch1__0__plate1_B13_site1_Ch1 1 B13 1 HBSS control 59.0 59.0 59.0 1805.06988040678 1502.4123834576274 302.6574969491526 308.182553594441 295.40835758750995 377.9935857420644 292.5031657524073 274.4186976700165 391.6966321932782 plate1_B13_site2_Ch1__0__plate1_B13_site2_Ch1 2 B13 1 HBSS control 71.0 71.0 71.0 1558.5194041690143 1291.1595267605635 267.3598774084507 299.17016394582697 285.23325714705294 363.05445180651634 305.7340276405519 284.01603790001866 406.23380996542903 plate1_C12_site1_Ch1__0__plate1_C12_site1_Ch1 1 C12 1 HBSS control 127.0 127.0 127.0 1203.229621417323 944.5570237480316 258.67259766929135 343.52778951543183 329.7049438466621 398.5256715321834 283.1283666399538 270.7264526431119 333.90274822634825 plate1_C12_site2_Ch1__0__plate1_C12_site2_Ch1 2 C12 1 HBSS control 124.0 124.0 124.0 1166.5923096774195 921.3840805161292 245.20822916129035 348.5899736336976 331.9816108022042 415.9173276097387 287.77845139732943 273.9409912708669 343.3100275440203 plate1_D16_site1_Ch1__0__plate1_D16_site1_Ch1 1 D16 1 DMEM drug 137.0 137.0 137.0 1136.5299405547446 848.7231084379563 287.80683211678837 324.09437073563026 314.2939434267824 361.2811199284404 341.1003129872079 326.6836244548794 397.2258103183944 plate1_D16_site2_Ch1__0__plate1_D16_site2_Ch1 2 D16 1 DMEM drug 126.0 126.0 126.0 1220.6002488888892 932.7191263492065 287.88112253968256 305.43130665340715 298.09709415581307 335.4623238823955 334.3002097571851 323.0418712295005 381.9689568813829 plate1_E18_site1_Ch1__0__plate1_E18_site1_Ch1 1 E18 1 DMEM drug 147.0 147.0 147.0 1054.613018122449 800.8962803809525 253.71673774149664 345.9989260804927 335.50803523526207 383.15517282809606 296.09051609563323 283.99028924506246 339.21053128779465 plate1_E18_site2_Ch1__0__plate1_E18_site2_Ch1 2 E18 1 DMEM drug 174.0 173.0 174.0 894.9381222988507 649.1033999537573 249.56520165517242 351.5135374204032 347.28641992275476 370.0639647086021 282.8140508927973 276.74482673528496 304.67453165821416"},{"location":"tutorial/02_easy_ML/","title":"3) Easy Machine Learning","text":""},{"location":"tutorial/02_easy_ML/#easy-machine-learning","title":"Easy Machine Learning","text":"<p>The goal of this tutorial is to get a user familiar with generating annotations, workflows, and machine learning classifiers. Unlike the Example Pipeline Tutorial, this tutorial just provides raw images and hints on how to progress.</p> <p>If you investigate the <code>primaryneurons</code> images you'll notice that there variable interesting morphologies that are not easy to segment by traditional intensity based segmentation. Machine Learning fills this gap (you'll see!) that Deep Learning has yet to sort out.</p> <p>You might also be surprised when looking at some of the images that I would not recommend traditional intensity-based segmentation methods for NCOA4 and Ferritin (but would, and do, use it for DAPI). Instead, I would endorse using Machine Learning based segmentation because it is less sensitive to intensity (which is expected to be different between neurons and treatment group) and more sensitive to 'Features' of the images, which includes intensity, size, blobness, ridgeness, edgeness, etc.</p> <p>Machine Learning classifiers are trained using <code>accelerated-pixel-and-object-classifiers</code> (APOC) under the hood; the examples in the <code>apoc</code> repository are excellent!</p> <p>The <code>APOC Widget</code> can be used to Segment Objects, Classify Pixels, and Classify Objects. Furthermore, the widget can visualize custom feature sets and be applied in the viewer or in batch.</p> <p>To train Machine Learning classifiers, you need to provide some sample, sparse annotation that the classifier can evaluate as the class of pixel you are interested. A typical convention is to use label 1 for background, and subsequent labels with an increasing number. This is different from Deep Learning that requires complete and accurate annotations. In comparison, Machine Learning is much more lenient.</p> <p>Overall, new Machine Learning classifiers can be evaluated within seconds and batch training can be accomplished in minutes... with great results!</p> <p>The skills practiced in this will be used on relatively small, 2D images; however, things are intended to generally transfer to both 3D and higher dimensional datasets.</p> <p>Coming very soon object classification (and not just segmentation) to the <code>APOC Widget</code></p>"},{"location":"tutorial/02_easy_ML/#sparse-annotation-with-image-utilities","title":"Sparse annotation with Image Utilities","text":"<p>One strength of <code>napari-ndev</code> is the ability to quickly annotate images and save them, while maintaining helpful metadata to pair the images up for future processing. In <code>napari</code> annotations can be made using <code>labels</code> or <code>shapes</code>. Shapes has a current weakness in that it cannot save <code>images</code>, so <code>napari-ndev</code> converts shapes to <code>labels</code> so that they match the image format. For this tutorial, we want to use the <code>labels</code> feature to 'draw' on annotations.</p> <ol> <li>Load in one of the primary neuron images in <code>ExtractedScenes</code> using the <code>Image Utilities</code> widget.</li> <li>Add a Labels layer by clicking the <code>tag</code> icon (the third button above the layer list)</li> <li>Click the <code>Paintbrush</code> button in the <code>layer controls</code>.</li> <li>Click and drag on the image to draw annotations.</li> <li>Draw background labels with the original label (1)</li> <li>Draw signal labels, trying to label 1-10% of the signal in the image, and with a variety of features of the target signal.</li> <li>Press <code>Save selected Layers</code> to save the annotation for future use! It will save into a <code>Labels</code> folder in the directory.</li> </ol> <p></p>"},{"location":"tutorial/02_easy_ML/#generating-a-machine-learning-classifier","title":"Generating a Machine Learning Classifier","text":"<ol> <li>Open the <code>APOC Widget</code></li> <li>Select a classifier file with the first button. Unfortunately, you will need to right click in your file explorer, create a new file (I usually create a .txt) and then rename it to something like <code>classifier.cl</code>. Your operarting system will prompt you that you are changing the extension of the file which could break the file, but this is ok since it is a brand new file. Select this file and hit the open button.</li> <li>Use the default ObjectSegmenter. The number of <code>forests</code> is the number of total iterations of the classifier and the number of <code>trees</code> is the number of decisions that the Random Forest Classifier will make. These defaults are ok, but for more specific classifier, I would increase these values.</li> <li>You can select a pre-made feature set OR do a custom feature set. (See below)</li> <li>For now, select from the <code>feature_set</code> dropdown: <code>object_size_1_to_5_px</code></li> </ol>"},{"location":"tutorial/02_easy_ML/#trainingpredicting-using-the-viewer","title":"Training/Predicting using the viewer","text":"<p>We can train and predict with machine learning classifiers on individual images in the viewer. This is useful for initially determining a useful feature set prior to training in batch.</p> <ol> <li>Switch to the <code>Viewer</code> tab</li> <li>Select the channels that you want to use for training. For morphology, you want to select at least AF488 (phalloidin), but it may also be useful to select other signals that fill the cell. Play around!</li> <li>Press the <code>Train classifier on select layers using label</code> button. In a few seconds your classifier should be finished training!</li> <li><code>Predict using classifier on selected layers</code> button to add the results immediately to the viewer.</li> </ol> <p>As you can see, there is likely some errors that need to be corrected for:</p> <p></p>"},{"location":"tutorial/02_easy_ML/#generation-of-a-feature-set-with-apoc-widget","title":"Generation of a Feature Set with APOC Widget","text":"<p>We now want to tune up the feature set. Check out the <code>features</code> of the originally selected feature set. If you reselect the classifier file (after selecting any other arbitrary file) a new popup will appear with a table displaying the value of each feature.</p> <p>To visualize the feature set:</p> <ol> <li>Go to the <code>Custom Feature Set</code> tab. The feature set you have selected will automatically generate the <code>custom feature string</code> used.</li> <li>Select the image layer you want to visualize (in this case AF488)</li> <li>Press <code>Apply to Selected Image</code></li> <li>Either turn on/off layers to visualize. Or switch napari to <code>grid</code> mode.</li> </ol> <p></p> <p>Optionally, switch between the different feature sets to try them out. Notice how different a large pixel set is compared to a small one. Let's attempt to generate a custom feature set.</p> <ol> <li>Switch to <code>custom</code> in the <code>feature set</code> dropdown.</li> <li>In each feature you think could be interesting add values that you think might be useful, separated by commas. For example, Gaussian blur might be <code>1,2,3</code>. Look up the different features if you aren't sure what their use is!</li> <li>Press <code>Generate Feature String</code>. This will populate it for this tab, and also above in the <code>Feature String</code> used by the classifier. Neat!</li> <li>Visualize the feature set.</li> <li>Try this new feature set on the image in the viewer. You may wish to create a new classifier file (to preserve progress). If you wish to 'overwrite' the current classifier for ease of use, uncheck <code>Continue Training?</code> at the top. When this is checked, it can be used to iterate over the classifier for a 'batch-like' training experience on a previously used classifier (be cautious with this, but it is generally a helpful default value).</li> </ol>"},{"location":"tutorial/02_easy_ML/#trainingpredicting-in-batch","title":"Training/Predicting in batch","text":"<ol> <li>Now, go back and annotate and save the labels of the other file.</li> <li>Use the <code>Batch</code> tab</li> <li>Select the <code>Image Directory</code></li> <li>Select the channels to be used for training, can be multiple</li> <li>Select the <code>Label Directory</code></li> <li>Train!</li> <li>Predict!</li> </ol>"},{"location":"tutorial/03_build_pipeline/","title":"4) Build Your Own Pipeline","text":""},{"location":"tutorial/03_build_pipeline/#build-your-own-workflow","title":"Build your own Workflow","text":"<p>The goal of this tutorial is to get a user familiar with generating ROI annotations and building your own workflows. Unlike the Example Pipeline Tutorial, this tutorial just provides raw images and hints on how to progress.</p> <p>For this workflow, we will be using the <code>neuralprogenitors</code> images. Our goal is to segment the PAX6 and TBR2 channels. We also specifically want to make an ROI that is 200 microns wide on each image, and bin a specific region of the brand (the specifics beyond the scope and necessity of this tutorial). Later, we will use these labels to count only the ones inside the region of interest.</p> <p>The skills practiced in this tutorial will be used on relatively small, 2D images; however, things are intended to generally transfer to both 3D and higher dimensional datasets.</p> <p></p>"},{"location":"tutorial/03_build_pipeline/#annotating-regions-of-interest-with-image-utilities","title":"Annotating regions of interest with Image Utilities","text":"<ol> <li>Load in one of the neural progenitor images from <code>ConcatenatedImages</code> using the <code>Image Utilities</code> widget.</li> <li>Navigate in the toolbar to <code>View</code> -&gt; <code>Scale Bar</code> -&gt; <code>Scale Bar Visible</code>. Now there should be a scale bar in the bottom right</li> <li>Add a Shapes layer by clicking the <code>polygon</code> icon (the second button above the layer list)</li> <li>Click the <code>Rectangle</code> button in the <code>layer controls</code>.</li> <li>Click and drag on the image to draw a rectangle that has a 200um width.</li> <li>Select button number 5 (highlighted in blue in the screenshot) to select the shape.</li> <li>Move the shape by dragging</li> <li>Rotate the shape into an area of interest.</li> <li>Finally, with the <code>Shapes</code> layer highlighted. Click the <code>Save Selected Layers</code> button in the <code>Image Utilities Widget</code></li> </ol>"},{"location":"tutorial/03_build_pipeline/#using-the-napari-assistant-to-generate-a-workflow","title":"Using the napari-assistant to generate a workflow","text":"<ol> <li>Open the <code>napari-assistant</code> by navigating in the toolbar to <code>Plugins</code> -&gt; <code>Assistant (napari-assistant)</code></li> <li>Select the image you want to process.</li> <li>Play around with the assistant buttons that seem interesting. Play around! They are sort of logically ordered left to right, top to bottom. The label layer I have in the image is not quality segmentation. Check the goal image above.</li> <li>You can modify parameters and functions on the fly, including in previously used functions by clicking on that specific layer.</li> <li>If you need help reaching the goal (of quality segmentation of the nuclei), try out some of the hints.</li> <li>When you are satisfied with what the workflow. Click the <code>Save and load ...</code> button -&gt; <code>Export workflow to file</code> and save the .yaml file produced.</li> </ol>"},{"location":"tutorial/03_build_pipeline/#hints","title":"Hints","text":"How to label <p>You may find the functions in the <code>Label</code> button to be quite useful.</p> A very useful label function <p>Check out the voronoi_otsu_labeling function. Read the link for more info.</p> Pre-processing the images to reduce background <p>Try playing with functions in <code>remove noise</code> and <code>remove background</code> to remove some of the variability in background intensity and off-target fluorescence prior to labeling. This will make labeling more consister.</p> Cleaning up the labels <p>Perhaps you have criteria for what labels you want to keep. Check out <code>Process Labels</code> button for cleaning up things like small or large labels, or labels on the edges.</p> OK, I give up, just give me the answer <p>Something like the following should work well.</p> <ol> <li>median_sphere (pyclesperanto) with radii of 1</li> <li>top_hat_sphere (pyclesperanto) with radii of 10 (roughly the diameter of the objects)</li> <li>voronoi_otsu_label (pyclesperanto) with spot and outline sigmas of 1</li> <li>exclude_small_labels (pyclesperanto) that are smaller than 10 pixels</li> </ol>"},{"location":"tutorial/03_build_pipeline/#applying-your-workflow-in-batch-with-the-workflow-widget","title":"Applying your workflow in batch with the Workflow Widget","text":"<p>Consider the instructions for Using the Workflow Widget for Batch Processing and apply it to this workflow.</p>"},{"location":"tutorial/03_build_pipeline/#measuring-your-batch-workflow-output","title":"Measuring your batch workflow output","text":"<p>In additional to how we already learned how to use the <code>Measure Widget</code>, we can also consider additional creative possibility. In this case, we want to only count cells in our region of interest (the shape rectangle that was drawn), so we want to load this in as a <code>Region Directory</code>. Then, we want to ensure that the <code>Shape</code> is added as an <code>Intensity Image</code> and that we measure the <code>intensity_max</code> or <code>intensity_min</code>. The maximum intensity of an object if it touches the region of interest at any point will be 1. The minimum intensity of an object fully inside the ROI will be 1, since all pixels are inside the ROI. So, you can choose how you want to consider objects relative to the ROI.</p> <p>Then, when grouping the data, use the <code>intensity_max/min_Shape</code> as a grouping variable! Then, all labels with a value of 1 or 0 will be counted separately. This can be extended to multiple regions of interest, because each shape has it's own value (not immediately obvious yet in napari). We have used this to label multiple brain regions consistently in whole brain section analyses.</p> <p>Future addition: The ability to simply filter objects in the Measure Widget. This can for example be used to exclude all labels that are outside the region of interest (having a intensity value of 0 relative to the ROI), instead of having to group.</p>"},{"location":"tutorial/03_build_pipeline/#notes-on-multi-dimensional-data","title":"Notes on multi-dimensional data","text":"<p>Overall, most of the plugin should be able to handle datasets that have time, multi-channel, and 3D data. Try exploring the <code>Lund Timelapse (100MB)</code> sample data from <code>Pyclesperanto</code> in napari.</p>"},{"location":"tutorial/cellpainting/scripting_workflow/","title":"Scripting workflow","text":"In\u00a0[1]: Copied! <pre>import pyclesperanto_prototype as cle\nimport stackview\nfrom napari_workflows import Workflow\nfrom napari_workflows._io_yaml_v1 import save_workflow\n\nfrom napari_ndev import morphology, nImage\n</pre> import pyclesperanto_prototype as cle import stackview from napari_workflows import Workflow from napari_workflows._io_yaml_v1 import save_workflow  from napari_ndev import morphology, nImage  In\u00a0[2]: Copied! <pre>wf = Workflow()\n\n# label nuclei\nwf.set('nuclei-labels', cle.voronoi_otsu_labeling, 'nuclei', spot_sigma=5, outline_sigma=1)\n# voronoi diagram\nwf.set('nuclei-voronoi', cle.extend_labeling_via_voronoi, 'nuclei-labels')\n\n# label nucleoli\nwf.set('nucleoli-med', cle.median_sphere, 'nucleoli', radius_x=1, radius_y=1)\nwf.set('nucleoli-th', cle.top_hat_sphere, 'nucleoli-med', radius_x=5, radius_y=5)\nwf.set('nucleoli-labels', cle.voronoi_otsu_labeling, 'nucleoli-th', spot_sigma=1, outline_sigma=1)\n\n# label cytoplasm\nwf.set('cyto-med', cle.median_sphere, 'cyto-membrane', radius_x=1, radius_y=1)\nwf.set('cyto-thresh', cle.greater_constant, 'cyto-med', constant=200)\nwf.set('cyto-no-nuclei', cle.logical_xor, 'cyto-thresh', 'nuclei-labels')\n\n# voronoi, full cells\nwf.set('cell-labels-float', cle.multiply_images, 'nuclei-voronoi', 'cyto-thresh')\nwf.set('cell-labels', morphology.convert_float_to_int, 'cell-labels-float')\n\n# voronoi, only with cytoplasm\nwf.set('cyto-labels-float', cle.multiply_images, 'nuclei-voronoi', 'cyto-no-nuclei')\nwf.set('cyto-labels', morphology.convert_float_to_int, 'cyto-labels-float')\n\nsave_workflow('scripted_cellpainting_workflow.yaml', wf)\n</pre> wf = Workflow()  # label nuclei wf.set('nuclei-labels', cle.voronoi_otsu_labeling, 'nuclei', spot_sigma=5, outline_sigma=1) # voronoi diagram wf.set('nuclei-voronoi', cle.extend_labeling_via_voronoi, 'nuclei-labels')  # label nucleoli wf.set('nucleoli-med', cle.median_sphere, 'nucleoli', radius_x=1, radius_y=1) wf.set('nucleoli-th', cle.top_hat_sphere, 'nucleoli-med', radius_x=5, radius_y=5) wf.set('nucleoli-labels', cle.voronoi_otsu_labeling, 'nucleoli-th', spot_sigma=1, outline_sigma=1)  # label cytoplasm wf.set('cyto-med', cle.median_sphere, 'cyto-membrane', radius_x=1, radius_y=1) wf.set('cyto-thresh', cle.greater_constant, 'cyto-med', constant=200) wf.set('cyto-no-nuclei', cle.logical_xor, 'cyto-thresh', 'nuclei-labels')  # voronoi, full cells wf.set('cell-labels-float', cle.multiply_images, 'nuclei-voronoi', 'cyto-thresh') wf.set('cell-labels', morphology.convert_float_to_int, 'cell-labels-float')  # voronoi, only with cytoplasm wf.set('cyto-labels-float', cle.multiply_images, 'nuclei-voronoi', 'cyto-no-nuclei') wf.set('cyto-labels', morphology.convert_float_to_int, 'cyto-labels-float')  save_workflow('scripted_cellpainting_workflow.yaml', wf)  In\u00a0[3]: Copied! <pre>img = nImage(r'ConcatenatedImages/plate1_A14_site1_Ch1.tiff')\n\nnuclei = img.get_image_data('TCZYX', C=0).squeeze()\ncyto_membrane = img.get_image_data('TCZYX', C=3).squeeze()\nnucleoli = img.get_image_data('TCZYX', C=2).squeeze()\n\nwf.set('nuclei', nuclei)\nwf.set('cyto-membrane', cyto_membrane)\nwf.set('nucleoli', nucleoli)\n</pre> img = nImage(r'ConcatenatedImages/plate1_A14_site1_Ch1.tiff')  nuclei = img.get_image_data('TCZYX', C=0).squeeze() cyto_membrane = img.get_image_data('TCZYX', C=3).squeeze() nucleoli = img.get_image_data('TCZYX', C=2).squeeze()  wf.set('nuclei', nuclei) wf.set('cyto-membrane', cyto_membrane) wf.set('nucleoli', nucleoli) In\u00a0[4]: Copied! <pre>tasks = [\n    'nuclei-labels',\n    'nuclei-voronoi',\n    'nucleoli-labels',\n    'cell-labels',\n    'cyto-labels',\n]\n\nfor task in tasks:\n    display(task)\n    label_image = wf.get(task)\n    display(label_image.dtype)\n    stackview.imshow(label_image, labels=True)\n</pre> tasks = [     'nuclei-labels',     'nuclei-voronoi',     'nucleoli-labels',     'cell-labels',     'cyto-labels', ]  for task in tasks:     display(task)     label_image = wf.get(task)     display(label_image.dtype)     stackview.imshow(label_image, labels=True) <pre>'nuclei-labels'</pre> <pre>dtype('uint32')</pre> <pre>'nuclei-voronoi'</pre> <pre>dtype('uint32')</pre> <pre>'nucleoli-labels'</pre> <pre>dtype('uint32')</pre> <pre>'cell-labels'</pre> <pre>dtype('uint32')</pre> <pre>'cyto-labels'</pre> <pre>dtype('uint32')</pre> In\u00a0[5]: Copied! <pre>wf.get('nuclei-labels')\n</pre> wf.get('nuclei-labels') Out[5]: cle._ image shape(520,\u00a0696) dtypeuint32 size1.4 MB min0.0max79.0"}]}